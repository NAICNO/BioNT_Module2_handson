

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Applied ML for Biological Data - Hands-on sessions documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
      <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
      <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
      <link rel="stylesheet" type="text/css" href="_static/sphinx_lesson.css" />
      <link rel="stylesheet" type="text/css" href="_static/term_role_formatting.css" />
      <link rel="stylesheet" type="text/css" href="_static/sphinx_rtd_theme_ext_color_contrast.css" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js"></script>
      <script src="_static/doctools.js"></script>
      <script src="_static/sphinx_highlight.js"></script>
      <script src="_static/clipboard.min.js"></script>
      <script src="_static/copybutton.js"></script>
      <script src="_static/minipres.js"></script>
      <script>let toggleHintShow = 'Click to show';</script>
      <script>let toggleHintHide = 'Click to hide';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="_static/togglebutton.js"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="#" class="icon icon-home">
            Applied ML for Biological Data - Hands-on sessions
          </a>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Sessions descriptions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="#document-1.PCA_n_Clustering">Unsupervised Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-2.Logistic_regression">Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-3.ML_workflow">Complete Machine Learning Workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-4.DeepVariant">DeepVariant: Deep-learning tool</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Jupyter Notebooks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="#document-1.Notebook_PCA_n_Clustering_session">Unsupervised Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-2.Notebook_Logistic_regression">Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-3.Notebook_ML_workflow">Complete ML workflow</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Q &amp; A sessions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="#document-1.PCA_n_clustering_QnA">Unsupervised Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-2.Logistic_regression_QnA">Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-3.ML_workflow_QnA">Complete Machine Learning Workflow</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">Applied ML for Biological Data - Hands-on sessions</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="#" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Applied ML for Biological Data - Hands-on sessions  documentation</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/coderefinery/content/blob/main/content/index" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="applied-machine-learning-for-biological-data-hands-on-sessions">
<h1>Applied Machine Learning for Biological Data Hands-on sessions<a class="headerlink" href="#applied-machine-learning-for-biological-data-hands-on-sessions" title="Link to this heading"></a></h1>
<div class="admonition-prerequisites prerequisites admonition" id="prerequisites-0">
<p class="admonition-title">Prerequisites</p>
<ul class="simple">
<li><p><a class="reference external" href="https://coderefinery.github.io/intermediate-python-ml/#">NumPy and Pandas fundamentals for handling biological datasets</a></p></li>
</ul>
</div>
<section id="who-is-the-hands-on-sessions-for">
<h2>Who is the hands-on sessions for?<a class="headerlink" href="#who-is-the-hands-on-sessions-for" title="Link to this heading"></a></h2>
</section>
<section id="about-the-hands-on-sessions">
<h2>About the hands-on sessions<a class="headerlink" href="#about-the-hands-on-sessions" title="Link to this heading"></a></h2>
</section>
<section id="overall-schedule">
<h2>Overall schedule<a class="headerlink" href="#overall-schedule" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p>PCA and clustering in cancer genomics</p></li>
<li><p>Logistic regression in cancer genomics</p></li>
<li><p>ML workflow with biological data</p></li>
<li><p>Deep-learning-based variant calling via DeepVariant</p></li>
<li><p>Accelerated Genomics workflows with Parabricks</p></li>
</ul>
<div class="toctree-wrapper compound">
<span id="document-1.PCA_n_Clustering"></span><section id="unsupervised-learning">
<h3>Unsupervised Learning<a class="headerlink" href="#unsupervised-learning" title="Link to this heading"></a></h3>
<section id="principal-component-analysis-pca-and-k-means-clustering">
<h4>Principal component analysis (PCA) and K-means clustering<a class="headerlink" href="#principal-component-analysis-pca-and-k-means-clustering" title="Link to this heading"></a></h4>
<div class="admonition-prerequisites prerequisites admonition" id="prerequisites-0">
<p class="admonition-title">Prerequisites</p>
<ul class="simple">
<li><p>BioNT Applied Machine Learning for Biological Data</p>
<ul>
<li><p>Module 1: Python Numpy and Pandas</p></li>
</ul>
</li>
</ul>
<p><em>Participants should gain skills introduced in above mentioned Lessons or equivalent skills.</em></p>
</div>
<div class="admonition-time exercise important admonition" id="exercise-0">
<p class="admonition-title">Time</p>
<p>2 hours and 30 minutes</p>
</div>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<p class="rubric" id="objectives">Objectives</p>
<ul class="simple">
<li><p>Demonstrate the use of unsupervised learning for drug sensitivity analysis.</p></li>
<li><p>Example workflow of PCA and K-means clustering with test dataset (drug sensitivity patterns across patients) for patient stratification</p></li>
</ul>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p class="rubric" id="ml-use-case">ML use-case</p>
<ul class="simple">
<li><p>Drug sensitivity scores: 50 drugs and 25 patients</p></li>
<li><p>Unsupervised learning (PCA and clustering) analysis will</p>
<ol class="arabic simple">
<li><p>Transform the drug sensitivity data (high-dimensional) into a dataset (lower-dimensional) that capture the most significant variance and patterns</p></li>
<li><p>Group patients into distinct strata based on similarities in their overall drug sensitivity patterns</p></li>
</ol>
</li>
</ul>
</div>
</section>
<section id="dataset">
<h4>Dataset<a class="headerlink" href="#dataset" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>Imputed Drug Sensitivities:</p>
<ul>
<li><p>This data was imputed for TCGA-BRCA patients based on a model trained on cancer cell line gene expression and corresponding in vitro drug response measurements</p></li>
</ul>
</li>
<li><p>Source: <a class="reference external" href="https://www.nature.com/articles/s41698-023-00491-9">Cancer drug sensitivity prediction from routine histology images</a></p></li>
</ul>
<p><em><a class="reference download internal" download="" href="_downloads/d10b2868b0538b6d8e941c3b4de06a4c/BRCA_Drug_sensitivity_test_data.csv"><span class="xref download myst">download test dataset</span></a></em></p>
</section>
<section id="notebook">
<h4>Notebook<a class="headerlink" href="#notebook" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/NAICNO/BioNT_Module2_handson/blob/main/content/1.Notebook_PCA_n_Clustering_session.ipynb">Download the notebook</a></p></li>
</ul>
<p><img alt="alt text" src="_images/image.png" /></p>
</section>
</section>
<span id="document-2.Logistic_regression"></span><section id="classification">
<h3>Classification<a class="headerlink" href="#classification" title="Link to this heading"></a></h3>
<section id="logistic-regression">
<h4>Logistic regression<a class="headerlink" href="#logistic-regression" title="Link to this heading"></a></h4>
<div class="admonition-prerequisites prerequisites admonition" id="prerequisites-0">
<p class="admonition-title">Prerequisites</p>
<ul class="simple">
<li><p>BioNT Applied Machine Learning for Biological Data</p>
<ul>
<li><p>Module 1: Python Numpy and Pandas</p></li>
</ul>
</li>
</ul>
<p><em>Participants should gain skills introduced in above mentioned Lessons or equivalent skills.</em></p>
</div>
<div class="admonition-time exercise important admonition" id="exercise-0">
<p class="admonition-title">Time</p>
<p>1 hours</p>
</div>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<p class="rubric" id="objectives">Objectives</p>
<ul class="simple">
<li><p>Demonstrate the use of classification for cancer dataset</p></li>
<li><p>Example Logistic regression analysis with Glioma test dataset for Glioma sub-type classification</p></li>
</ul>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p class="rubric" id="ml-use-case">ML use-case</p>
<ul class="simple">
<li><p>Gliomas - most common primary tumors of the brain</p></li>
<li><p>Glioma categories</p>
<ul>
<li><p>Low grade gliomas (LGG) - Slower growing gliomas</p></li>
<li><p>Glioblastoma Multiforme (GBM) - Most aggressive gliomas type</p></li>
</ul>
</li>
<li><p>Glioma classification (grading) depend on the histological/imaging criteria, but clinical and molecular/mutation factors are also very crucial for accurately diagnose glioma patients.</p></li>
<li><p>Logistic regression based analysis tries to use most frequently mutated 20 genes and 3 clinical features to classify/ grade gliomas</p></li>
</ul>
</div>
</section>
<section id="dataset">
<h4>Dataset<a class="headerlink" href="#dataset" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p><a class="reference download internal" download="" href="_downloads/041231c291c25343976f8b70db54f238/TCGA_InfoWithGrade_scaled.csv"><span class="xref download myst">Download dataset: TCGA_InfoWithGrade_scaled.csv</span></a></p></li>
<li><p>Features:</p>
<ul>
<li><p>Most frequently mutated 20 genes and</p></li>
<li><p>2 clinical features: gender and age at diagnosis</p></li>
</ul>
</li>
<li><p>Target variable (i.e, dependant variable or response variables): Glioma grade class information</p>
<ul>
<li><p>0 = “LGG”</p></li>
<li><p>1 = “GBM”</p></li>
</ul>
</li>
</ul>
<section id="source">
<h5>Source<a class="headerlink" href="#source" title="Link to this heading"></a></h5>
<ul class="simple">
<li><p><a class="reference external" href="https://archive.ics.uci.edu/dataset/759/glioma+grading+clinical+and+mutation+features+dataset">UCI Machine Learning Repository - Glioma Grading Clinical and Mutation Features</a></p></li>
</ul>
</section>
</section>
<section id="notebook">
<h4>Notebook<a class="headerlink" href="#notebook" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/NAICNO/BioNT_Module2_handson/blob/main/content/2.Notebook_Logistic_regression.ipynb">Download the notebook</a></p></li>
</ul>
<p><img alt="alt text" src="_images/image-1.png" /></p>
</section>
</section>
<span id="document-3.ML_workflow"></span><section id="complete-machine-learning-workflow">
<h3>Complete Machine Learning Workflow<a class="headerlink" href="#complete-machine-learning-workflow" title="Link to this heading"></a></h3>
<section id="machine-learning-workflow">
<h4>Machine Learning Workflow<a class="headerlink" href="#machine-learning-workflow" title="Link to this heading"></a></h4>
<div class="admonition-prerequisites prerequisites admonition" id="prerequisites-0">
<p class="admonition-title">Prerequisites</p>
<ul class="simple">
<li><p>BioNT Applied Machine Learning for Biological Data</p>
<ul>
<li><p>Module 1: Python Numpy and Pandas</p></li>
<li><p>Module 2: Classification: Logistic regression; Tree-based methods; Matrices for classification evaluation</p></li>
</ul>
</li>
</ul>
<p><em>Participants should gain skills introduced in above mentioned Lessons or equivalent skills.</em></p>
</div>
<div class="admonition-time exercise important admonition" id="exercise-0">
<p class="admonition-title">Time</p>
<p>2 hours</p>
</div>
</section>
<section id="objectives">
<h4>Objectives<a class="headerlink" href="#objectives" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>Demonstrate the use of complete classification workflow for cancer dataset (expand on previous hands-on session)</p></li>
<li><p>Example workflow of Logistic regression with Glioma test dataset for Glioma sub-type classification</p></li>
</ul>
<div class="docutils">
<p class="rubric" id="ml-use-case">ML use-case</p>
<ul class="simple">
<li><p>ML use-case as described in <a class="reference internal" href="#document-2.Logistic_regression"><span class="std std-doc">Classification hands-on session</span></a></p></li>
<li><p>Example Logistic regression workflow tries to use most frequently mutated 20 genes and 3 clinical features to classify/ grade gliomas</p></li>
<li><p>Demonstrate following key techniques</p>
<ul>
<li><p>Data exploration and handing missing data</p></li>
<li><p>Scaling</p></li>
<li><p>Cross-validation</p></li>
<li><p>Hyper-parameter tuning with GridSearch</p></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="dataset">
<h4>Dataset<a class="headerlink" href="#dataset" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p><a class="reference download internal" download="" href="_downloads/d072ac9ebbb200e56a8125b33b887657/TCGA_InfoWithGrade.csv"><span class="xref download myst">Download dataset: TCGA_InfoWithGrade.csv</span></a></p></li>
<li><p>Dataset as described in <a class="reference internal" href="#document-2.Logistic_regression"><span class="std std-doc">Classification hands-on session</span></a></p>
<ul>
<li><p>Features:</p>
<ul>
<li><p>Most frequently mutated 20 genes and</p></li>
<li><p>3 clinical features: gender, age at diagnosis, race</p></li>
</ul>
</li>
<li><p>Target variable (i.e, dependant variable or response variables): Glioma grade class information</p>
<ul>
<li><p>0 = “LGG”</p></li>
<li><p>1 = “GBM”</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Several Additional columns and rows with null values are spiked into the original dataset for demonstration purpose</p></li>
</ul>
<section id="source">
<h5>Source<a class="headerlink" href="#source" title="Link to this heading"></a></h5>
<ul class="simple">
<li><p><a class="reference external" href="https://archive.ics.uci.edu/dataset/759/glioma+grading+clinical+and+mutation+features+dataset">UCI Machine Learning Repository - Glioma Grading Clinical and Mutation Features</a></p></li>
</ul>
</section>
</section>
<section id="notebook">
<h4>Notebook<a class="headerlink" href="#notebook" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/NAICNO/BioNT_Module2_handson/blob/main/content/3.Notebook_ML_workflow.ipynb">Download the notebook</a></p></li>
</ul>
</section>
</section>
<span id="document-4.DeepVariant"></span><section id="deepvariant-deep-learning-tool">
<h3>DeepVariant: Deep-learning tool<a class="headerlink" href="#deepvariant-deep-learning-tool" title="Link to this heading"></a></h3>
<div class="admonition-time exercise important admonition" id="exercise-0">
<p class="admonition-title">Time</p>
<ul class="simple">
<li><p>Lecture: 20 minutes</p></li>
<li><p>Exercise: 10 mins</p></li>
<li><p>hands-on: 30 mins</p></li>
</ul>
</div>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>We will introduce two such tools used in variant calling and functional effect prediction</p>
<ul>
<li><p>DeepVariant: Live session</p></li>
<li><p>AlphaMissense (Additional notes, not intended to cover in live session)</p></li>
</ul>
</li>
</ul>
</div>
<section id="variant-calling">
<h4>Variant calling<a class="headerlink" href="#variant-calling" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>Variant calling is the process of identifying of variants from sequence data</p>
<ul>
<li><p>Compare the sequence data from an individual to a reference genome to identify differences</p></li>
</ul>
</li>
</ul>
<p><img alt="alt text" src="_images/image-2.png" /></p>
<p><a class="reference external" href="https://www.genome.gov/about-genomics/educational-resources/fact-sheets/human-genomic-variation"><em>Source</em></a></p>
<section id="data-preprocessing-steps-for-variant-calling">
<h5>Data preprocessing steps for variant calling<a class="headerlink" href="#data-preprocessing-steps-for-variant-calling" title="Link to this heading"></a></h5>
<ul class="simple">
<li><p>Will be discussed in detail on Day-5 sessions</p></li>
</ul>
</section>
<section id="main-input-for-variant-calling">
<h5>Main input for variant calling<a class="headerlink" href="#main-input-for-variant-calling" title="Link to this heading"></a></h5>
<ul class="simple">
<li><p>Alignment file used can be think of as a dataset representing sequence reads that are aligned to a reference genome - i.e., sequence reads are pileup along the reference genome</p></li>
</ul>
<p><img alt="alt text" src="_images/image-3.png" /></p>
<p><a class="reference external" href="https://campuspress.yale.edu/knightlab/ruddle/plotreads/"><em>Source</em></a></p>
</section>
</section>
<section id="standard-variant-calling-tools">
<h4>Standard variant calling tools<a class="headerlink" href="#standard-variant-calling-tools" title="Link to this heading"></a></h4>
<p>Standard variant calling tools are based on statistical models and various QC parameters</p>
<ul class="simple">
<li><p>These tools first analyze alignment files to detect read-positions that differ from reference</p></li>
<li><p>Apply statistical methods combining various information (nucleotide and QC parameters) of these read-positions to identify genomic variants</p></li>
</ul>
<p><img alt="alt text" src="_images/image-4.png" /></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1">#Run Haplotype Caller</span>
$<span class="w"> </span>gatk<span class="w"> </span>HaplotypeCaller<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--java-options<span class="w"> </span>-Xmx30g<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--input<span class="w"> </span><span class="si">${</span><span class="nv">INPUT_BAM</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output<span class="w"> </span><span class="si">${</span><span class="nv">OUT_VCF</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--reference<span class="w"> </span><span class="si">${</span><span class="nv">REFERENCE</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--native-pair-hmm-threads<span class="w"> </span><span class="si">${</span><span class="nv">CPU</span><span class="si">}</span>
</pre></div>
</div>
</section>
<section id="deep-learning-based-variant-caller-deepvariant">
<h4>Deep learning based variant caller - DeepVariant<a class="headerlink" href="#deep-learning-based-variant-caller-deepvariant" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>Various visualization techniques have been used to validate regions of alignment files with variants (e.g., Pileup-images)</p></li>
</ul>
<p><img alt="alt text" src="_images/image-5.png" /></p>
<ul class="simple">
<li><p>DeepVariant leverages this concept of pileup-images to visualize not only the bases, but other features that are important for variant calling</p>
<ul>
<li><p>DeepVariant generates sets of images for candidate variant positions representing range of features</p></li>
<li><p>Stack of pileup images each representing</p>
<ul>
<li><p>Base calling quality</p></li>
<li><p>Mapping quality</p></li>
<li><p>Metadata on where position is reference or not</p></li>
<li><p>etc…</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Availability of these images transform variant calling a image classification problem</p></li>
<li><p>DeepVariant use deep-learning model to classify these images and predict variants with high precision</p></li>
</ul>
<p><img alt="alt text" src="_images/image-6.png" /></p>
</section>
<section id="deepvariant-vs-traditional-variant-callers">
<h4>DeepVariant vs traditional variant callers<a class="headerlink" href="#deepvariant-vs-traditional-variant-callers" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>DeepVariant showed higher Precision and sensitivity scores compared traditional callers (Ref: <a class="reference external" href="https://www.nature.com/articles/nbt.4235">Original DeepVariant</a> paper and <a class="reference external" href="https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-022-08365-3/tables/3">Independent studies</a>)</p></li>
</ul>
<div class="admonition-precision-vs-recall-plot solution important dropdown admonition" id="solution-0">
<p class="admonition-title">Precision vs Recall plot</p>
<p><img alt="alt text" src="_images/image-10.png" /></p>
</div>
<ul class="simple">
<li><p>High accuracy of DeepVariant compared to traditional callers:</p>
<ul>
<li><p>DeepVariant won 2020 PrecisionFDA Truth Challenge V2 for all Benchmark Regions across Multiple sequencing Technologies</p></li>
<li><p>DeepVariant - best SNP Performance in 2016 PrecisionFDA Truth Challenge</p></li>
<li><p>DeepVariant makes a great difference especially for low coverage samples</p></li>
<li><p><a class="reference external" href="https://github.com/google/deepvariant">References are linked in DeepVariant GitHub repo</a></p></li>
</ul>
</li>
</ul>
<div class="admonition-exercise exercise important admonition" id="exercise-1">
<p class="admonition-title">Exercise</p>
<ul class="simple">
<li><p>Why DeepVariants (deep-learning based) could outperform traditional variant callers?</p></li>
</ul>
</div>
<section id="deepvariant-model-training-and-evaluation">
<h5>DeepVariant model training and evaluation<a class="headerlink" href="#deepvariant-model-training-and-evaluation" title="Link to this heading"></a></h5>
<ul class="simple">
<li><p>This training dataset consist of 100s of millions of samples from multiple genomes, sequencers, and preparation methods</p></li>
<li><p>This help minimize the bias in the model towards a specific sequencing platform or technology</p></li>
</ul>
<div class="admonition-deepvariant-training-data solution important dropdown admonition" id="solution-1">
<p class="admonition-title">DeepVariant training data</p>
<p><img alt="alt text" src="_images/image-11.png" />
<a class="reference external" href="https://github.com/google/deepvariant/blob/r1.9/docs/deepvariant-details-training-data.md">Ref: DeepVariant training data</a></p>
</div>
<ul class="simple">
<li><p>Model is evaluated using unseen data from [precisionFDA Truth Challenge](https://precision.fda.gov/challenges/truth/results</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p class="rubric" id="hands-on-deepvariant-run">Hands-on: DeepVariant run</p>
<ul class="simple">
<li><p>Log into VM following instructions given in previous session</p></li>
</ul>
<div class="admonition-run-inside-the-vm instructor-note admonition" id="instructor-note-1">
<p class="admonition-title">Run inside the VM</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Move to home directory</span>
<span class="nb">cd</span><span class="w"> </span><span class="nv">$HOME</span>

<span class="c1"># Check your current working directory (you&#39;ll see e.g., /home/biont*)</span>
<span class="nb">pwd</span>

<span class="c1"># Run docker interactive mode</span>
docker<span class="w"> </span>run<span class="w"> </span><span class="se">\</span>
-it<span class="w"> </span><span class="se">\</span>
--rm<span class="w"> </span><span class="se">\</span>
--gpus<span class="w"> </span>all<span class="w"> </span><span class="se">\</span>
-v<span class="w"> </span>/data:/data<span class="w"> </span><span class="se">\</span>
-v<span class="w"> </span><span class="nv">$PWD</span>:<span class="nv">$PWD</span><span class="w"> </span><span class="se">\</span>
-w<span class="w"> </span><span class="nv">$PWD</span><span class="w"> </span><span class="se">\</span>
nvcr.io/nvidia/clara/clara-parabricks:4.3.0-1<span class="w"> </span>bash
</pre></div>
</div>
<div class="admonition-now-you-are-inside-the-docker-container instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Now you are inside the docker container</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set path variable (i.e, copy following lines)</span>

<span class="nv">FASTA</span><span class="o">=</span><span class="s2">&quot;/data/ngs/ref/Homo_sapiens_assembly38.fasta&quot;</span>
<span class="nv">KNOWN_SITES</span><span class="o">=</span><span class="s2">&quot;/data/ngs/ref/Homo_sapiens_assembly38.known_indels.vcf.gz&quot;</span>
<span class="nv">BAM</span><span class="o">=</span>/data/ngs/BAM/dw_sample.bam

<span class="c1"># Run DV command &amp; generate deepvariant.vcf output file (i.e, copy following lines)</span>
pbrun<span class="w"> </span>deepvariant<span class="w"> </span>--ref<span class="w"> </span><span class="si">${</span><span class="nv">FASTA</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
--in-bam<span class="w"> </span><span class="si">${</span><span class="nv">BAM</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
--num-gpus<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
--logfile<span class="w"> </span>dv.log<span class="w"> </span><span class="se">\</span>
--out-variants<span class="w"> </span>deepvariant.vcf

<span class="c1">## You can exit the docker with `exit` command</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="docutils">
</div>
<ul class="simple">
<li><p>Inspect the DeepVariant output <code class="docutils literal notranslate"><span class="pre">deepvariant.vcf</span></code></p></li>
</ul>
<div class="admonition-alphamissense instructor-note admonition" id="instructor-note-2">
<p class="admonition-title">AlphaMissense</p>
<details>
<summary>AlphaMissense notes:</summary>
<ul class="simple">
<li><p>One of the main goals of variant calling is to evaluating the clinical significance of detected variants</p></li>
<li><p>Can we use ML to evaluate the clinical significance of variants?</p></li>
</ul>
<p class="rubric" id="pathogenicity-prediction-predicting-damaging-effects-of-variants">Pathogenicity prediction (predicting damaging effects) of variants</p>
<ul class="simple">
<li><p>Pathogenicity prediction is the process of determining the clinical significance of a variant</p>
<ul>
<li><p>Pathogenic variants are those that cause a disease</p></li>
<li><p>Benign variants are those that do not cause or are not associated with a disease</p></li>
</ul>
</li>
<li><p>Current methods developed to reach above goal rely on combining following two fields</p>
<ul>
<li><p>knowledge of genetics and the biological processes - evolutionary conservation, protein structure, etc</p></li>
<li><p>statistical methods</p></li>
</ul>
</li>
<li><p>For instance, variants that are</p></li>
<li><p>common in the population are less likely to have damaging effects (benign)</p></li>
<li><p>rare and run in families with disease are more likely to be pathogenic</p></li>
<li><p>highly conserved across species are more likely to be pathogenic</p></li>
<li><p>affecting (altering) the structure of proteins critical for cellular functions are more likely to be pathogenic</p></li>
</ul>
<p class="rubric" id="main-challenge">Main challenge</p>
<ul class="simple">
<li><p>Over the years, scientists have identified a long list of disease associated genes</p></li>
<li><p>A large number of variants in these genes alters the protein sequence (amino acid sequence), but exact impact of on the protein structure is still unknown. Thus, association with the disease is also unknown</p>
<ul>
<li><p>Such variants are known variants with uncertain significance</p></li>
<li><p>According to a recent study a <strong>large majority of such variants (that alter protein sequence - missense) are with uncertain significance</strong> - <a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7334197">source</a></p></li>
<li><p>Differentiating pathogenic and bening such variants is a challenging task</p></li>
</ul>
</li>
</ul>
<p class="rubric" id="deep-learning-based-solution-alphamissense">Deep-learning based solution - AlphaMissense</p>
<ul class="simple">
<li><p>Deep-learning model predicting the (missense) variant pathogenicity</p></li>
<li><p>Ref: https://www.science.org/doi/10.1126/science.adg7492</p></li>
</ul>
<p><img alt="alt text" src="_images/image-7.png" />
<code class="docutils literal notranslate"><span class="pre">Source:</span> <span class="pre">&lt;https://www.science.org/doi/10.1126/science.adg7492&gt;</span></code>__</p>
<p><strong>Main steps</strong>:</p>
<ol class="arabic">
<li><p>Collecting and processing a large dataset of missense variants along with annotations indicating their pathogenicity (disease-causing or benign)</p></li>
<li><p>Convert variant info and amino acid sequences into representations suitable for deep learning models</p>
<ul class="simple">
<li><p>Transform raw data into new features that can better represent the underlying patterns and relationships</p></li>
</ul>
<p><img alt="alt text" src="_images/image-8.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">Source:</span> <span class="pre">&lt;https://www.science.org/doi/10.1126/science.adg7492&gt;</span></code>__</p>
</li>
<li><p>Fine-tune AlphaFold deep-learning model that predicts protein structure to predict variant pathogenicity</p></li>
<li><p>Assess the accuracy and generalizability of variant pathogenicity prediction using independent datasets</p></li>
</ol>
<p class="rubric" id="alphamissense-model-training">AlphaMissense model training</p>
<ul class="simple">
<li><p>Training data:</p>
<ul>
<li><p>Bening: missense variants frequently observed in human and primate populations</p></li>
<li><p>Pathogenic: missense variants absent from human and primate populations</p></li>
</ul>
</li>
<li><p>Validation data:</p>
<ul>
<li><p>Tune model parameters</p></li>
<li><p>Held-out data</p>
<ul>
<li><p>Pathogenic missense variants in various databases</p></li>
<li><p>Bening variants from population-databases</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Test data:</p>
<ul>
<li><p>Evaluate the model’s performance on unseen data</p></li>
<li><p>Held-out data</p></li>
<li><p>Pathogenic missense variants in ClinVar</p></li>
<li><p>Bening variants from population-databases</p></li>
</ul>
</li>
</ul>
<p class="rubric" id="model-evaluation">Model evaluation</p>
<ul class="simple">
<li><p>Model evaluation ensures that the model’s performance is not biased by the training data and that it can generalize to new and unseen variants</p></li>
<li><p>Predict the pathogenicity of each variant in the independent dataset (variants not included in the training dataset)</p></li>
<li><p>AlphaMissense model is evaluated using multiple clinical benchmark datasets</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">ClinVar</span></code> test set,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">De</span> <span class="pre">novo</span> <span class="pre">variants</span></code> from rare disease patients,</p></li>
</ul>
</li>
</ul>
<p><img alt="alt text" src="_images/image-9.png" />
<code class="docutils literal notranslate"><span class="pre">Source:</span> <span class="pre">&lt;https://www.science.org/doi/10.1126/science.adg7492&gt;</span></code>__</p>
<p class="rubric" id="applications">Applications</p>
<ul class="simple">
<li><p>AlphaMissense findings coupled with downstream functional experiments improve the current understanding of clinically actionable genes and variants</p></li>
<li><p>Improve the diagnostic yield of rare genetic diseases</p></li>
</ul>
</details>
</div>
</section>
</section>
</section>
</div>
<div class="toctree-wrapper compound">
<span id="document-1.Notebook_PCA_n_Clustering_session"></span><section id="unsupervised-learning">
<h3>Unsupervised Learning<a class="headerlink" href="#unsupervised-learning" title="Link to this heading"></a></h3>
<section id="principal-component-analysis-pca-and-k-means-clustering">
<h4>Principal component analysis (PCA) and K-means clustering<a class="headerlink" href="#principal-component-analysis-pca-and-k-means-clustering" title="Link to this heading"></a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">silhouette_score</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="data-preparation">
<h4>Data Preparation<a class="headerlink" href="#data-preparation" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>Clean the dataset by handling missing values</p></li>
<li><p>Scale/normalize the data</p></li>
<li><p>Check for outliers</p></li>
<li><p>Separate metadata from drug sensitivity values</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span><span class="w"> </span>curl<span class="w"> </span>https://naicno.github.io/BioNT_Module2_handson/_downloads/d10b2868b0538b6d8e941c3b4de06a4c/BRCA_Drug_sensitivity_test_data.csv<span class="w"> </span>-o<span class="w"> </span>BRCA_Drug_sensitivity_test_data.csv
<span class="o">!</span><span class="w"> </span>ls<span class="w"> </span>-lh<span class="w"> </span>BRCA_Drug_sensitivity_test_data.csv
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100 18108  100 18108    0     0   113k      0 --:--:-- --:--:-- --:--:--  113k
100 18108  100 18108    0     0   113k      0 --:--:-- --:--:-- --:--:--  113k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-rw-r--r-- 1 runner docker 18K Jun 10 13:52 BRCA_Drug_sensitivity_test_data.csv
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;BRCA_Drug_sensitivity_test_data.csv&#39;</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Patient ID</th>
      <th>bendamustine</th>
      <th>ML320</th>
      <th>BRD-K14844214</th>
      <th>leptomycin B</th>
      <th>Compound 23 citrate</th>
      <th>BRD4132</th>
      <th>dabrafenib</th>
      <th>necrosulfonamide</th>
      <th>PF-543</th>
      <th>...</th>
      <th>Compound 1541A</th>
      <th>pevonedistat</th>
      <th>ISOX</th>
      <th>tosedostat</th>
      <th>AT13387</th>
      <th>BRD-A02303741</th>
      <th>BRD-K99006945</th>
      <th>GSK525762A</th>
      <th>necrostatin-7</th>
      <th>nakiterpiosin</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>TCGA-D8-A1JU</td>
      <td>14.821152</td>
      <td>14.286200</td>
      <td>14.608184</td>
      <td>4.960653</td>
      <td>13.530885</td>
      <td>13.202820</td>
      <td>13.879099</td>
      <td>12.839373</td>
      <td>14.103941</td>
      <td>...</td>
      <td>14.778758</td>
      <td>12.541663</td>
      <td>12.113460</td>
      <td>12.364817</td>
      <td>8.913646</td>
      <td>14.860838</td>
      <td>13.170200</td>
      <td>13.116395</td>
      <td>14.548597</td>
      <td>11.835573</td>
    </tr>
    <tr>
      <th>1</th>
      <td>TCGA-AC-A3QQ</td>
      <td>14.304843</td>
      <td>14.333355</td>
      <td>14.960661</td>
      <td>3.552977</td>
      <td>13.122806</td>
      <td>13.129905</td>
      <td>13.911525</td>
      <td>12.124210</td>
      <td>14.127482</td>
      <td>...</td>
      <td>15.108698</td>
      <td>10.936052</td>
      <td>11.802052</td>
      <td>11.893495</td>
      <td>8.326862</td>
      <td>15.265313</td>
      <td>15.341146</td>
      <td>13.509974</td>
      <td>14.311074</td>
      <td>10.772699</td>
    </tr>
    <tr>
      <th>2</th>
      <td>TCGA-C8-A12Q</td>
      <td>14.658052</td>
      <td>14.649223</td>
      <td>14.547810</td>
      <td>3.467945</td>
      <td>13.438683</td>
      <td>13.441228</td>
      <td>13.823993</td>
      <td>12.935296</td>
      <td>14.052508</td>
      <td>...</td>
      <td>15.012134</td>
      <td>12.837987</td>
      <td>11.944058</td>
      <td>11.694113</td>
      <td>8.622052</td>
      <td>15.205567</td>
      <td>14.039701</td>
      <td>13.252381</td>
      <td>14.496764</td>
      <td>11.387851</td>
    </tr>
    <tr>
      <th>3</th>
      <td>TCGA-AR-A1AY</td>
      <td>14.342911</td>
      <td>13.657840</td>
      <td>14.426898</td>
      <td>1.800027</td>
      <td>13.242654</td>
      <td>13.094447</td>
      <td>13.531232</td>
      <td>11.987928</td>
      <td>14.046877</td>
      <td>...</td>
      <td>14.811534</td>
      <td>11.098317</td>
      <td>11.480102</td>
      <td>11.379716</td>
      <td>8.080488</td>
      <td>14.906361</td>
      <td>13.462326</td>
      <td>13.030773</td>
      <td>14.466555</td>
      <td>9.665608</td>
    </tr>
    <tr>
      <th>4</th>
      <td>TCGA-A8-A0A2</td>
      <td>14.655920</td>
      <td>14.323148</td>
      <td>14.527811</td>
      <td>4.491210</td>
      <td>13.293485</td>
      <td>13.054068</td>
      <td>13.807173</td>
      <td>12.446720</td>
      <td>14.012040</td>
      <td>...</td>
      <td>14.816099</td>
      <td>12.075367</td>
      <td>11.878005</td>
      <td>11.800027</td>
      <td>8.595326</td>
      <td>14.988143</td>
      <td>14.074985</td>
      <td>12.959710</td>
      <td>14.435152</td>
      <td>11.143563</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 51 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset shape: </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Patient IDs: </span><span class="si">{</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;Patient ID&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span><span class="si">}</span><span class="s2"> unique values&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Features: </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s2"> drug sensitivity measurements&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Dataset shape: (25, 51)
Patient IDs: 25 unique values
Features: 50 drug sensitivity measurements
</pre></div>
</div>
</div>
</div>
<section id="dimensionality-of-the-datasets">
<h5>Dimensionality of the datasets<a class="headerlink" href="#dimensionality-of-the-datasets" title="Link to this heading"></a></h5>
<p><strong>Notes: High-dimensional data</strong></p>
<ul class="simple">
<li><p>High-dimensional data refers to datasets where the number of features or attributes (dimensions, denoted as p) is significantly large</p></li>
<li><p>In such datasets, each observation can be thought of as residing in a high-dimensional space</p></li>
<li><p>The definition of “high-dimensional” data can vary depending on the context, the field of study, and the specific analysis being performed.</p></li>
</ul>
<p><em><strong>Dataset with 51 columns (drug compounds) and 25 rows (patients):</strong></em></p>
<ul class="simple">
<li><p>Contains more features (50 drug sensitivity scores) than samples (25 patients)</p></li>
<li><p><em>Difficulty in Visualization:</em> Identifying patterns visually becomes impossible</p></li>
<li><p><em>Sparsity:</em> With 50 features but only 25 samples, data points are scattered across a vast 50-dimensional space</p></li>
<li><p><em>Distance metrics become less meaningful:</em> In high dimensions, the difference between the nearest and farthest neighbors becomes less significant - nearly all points appear similar-distances from each other</p></li>
<li><p><em>Overfitting risk:</em> model has many potential combinations of features to consider, but limited examples to learn from, it has a large capacity to fit even noise in the limited training examples leading to overfitting and poor performance</p></li>
</ul>
</section>
<section id="clean-the-dataset-by-handling-missing-values">
<h5>Clean the dataset by handling missing values<a class="headerlink" href="#clean-the-dataset-by-handling-missing-values" title="Link to this heading"></a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check for missing values</span>
<span class="n">data</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.int64(0)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check data types</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Data types:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Datatypes of first 10 columns:&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">dtypes</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Different datatypes in the dataframe:&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Patient ID&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data types:
Datatypes of first 10 columns: Patient ID              object
bendamustine           float64
ML320                  float64
BRD-K14844214          float64
leptomycin B           float64
Compound 23 citrate    float64
BRD4132                float64
dabrafenib             float64
necrosulfonamide       float64
PF-543                 float64
dtype: object
Different datatypes in the dataframe: [dtype(&#39;float64&#39;)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Basic statistics for drug sensitivity values</span>
<span class="n">data</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>unique</th>
      <th>top</th>
      <th>freq</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>myricetin</th>
      <td>25.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>15.126359</td>
      <td>0.043691</td>
      <td>15.053067</td>
      <td>15.095327</td>
      <td>15.120994</td>
      <td>15.151308</td>
      <td>15.219127</td>
    </tr>
    <tr>
      <th>BRD-A02303741</th>
      <td>25.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>15.058701</td>
      <td>0.163287</td>
      <td>14.70386</td>
      <td>14.96314</td>
      <td>15.036734</td>
      <td>15.205567</td>
      <td>15.398952</td>
    </tr>
    <tr>
      <th>Compound 1541A</th>
      <td>25.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>14.907687</td>
      <td>0.136504</td>
      <td>14.724434</td>
      <td>14.811534</td>
      <td>14.879828</td>
      <td>14.981904</td>
      <td>15.318321</td>
    </tr>
    <tr>
      <th>carboplatin</th>
      <td>25.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>14.711186</td>
      <td>0.135093</td>
      <td>14.459443</td>
      <td>14.623642</td>
      <td>14.671899</td>
      <td>14.799047</td>
      <td>14.999075</td>
    </tr>
    <tr>
      <th>BRD-K27188169</th>
      <td>25.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>14.624495</td>
      <td>0.086419</td>
      <td>14.428273</td>
      <td>14.601246</td>
      <td>14.623367</td>
      <td>14.67901</td>
      <td>14.801653</td>
    </tr>
    <tr>
      <th>BRD-K14844214</th>
      <td>25.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>14.610919</td>
      <td>0.1589</td>
      <td>14.393664</td>
      <td>14.519765</td>
      <td>14.597586</td>
      <td>14.681205</td>
      <td>15.019018</td>
    </tr>
    <tr>
      <th>pifithrin-mu</th>
      <td>25.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>14.589748</td>
      <td>0.267786</td>
      <td>14.076076</td>
      <td>14.384124</td>
      <td>14.600936</td>
      <td>14.790655</td>
      <td>15.095189</td>
    </tr>
    <tr>
      <th>RO4929097</th>
      <td>25.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>14.559876</td>
      <td>0.181499</td>
      <td>13.979993</td>
      <td>14.480718</td>
      <td>14.59874</td>
      <td>14.66368</td>
      <td>14.924847</td>
    </tr>
    <tr>
      <th>RG-108</th>
      <td>25.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>14.447688</td>
      <td>0.218108</td>
      <td>13.95736</td>
      <td>14.283119</td>
      <td>14.4542</td>
      <td>14.592225</td>
      <td>14.81662</td>
    </tr>
    <tr>
      <th>bendamustine</th>
      <td>25.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>14.447378</td>
      <td>0.341383</td>
      <td>13.492308</td>
      <td>14.304843</td>
      <td>14.46329</td>
      <td>14.658052</td>
      <td>15.100501</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">tail</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>unique</th>
      <th>top</th>
      <th>freq</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>nakiterpiosin</th>
      <td>25.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>10.90167</td>
      <td>0.831147</td>
      <td>8.701056</td>
      <td>10.381886</td>
      <td>11.26099</td>
      <td>11.37343</td>
      <td>11.92009</td>
    </tr>
    <tr>
      <th>YM-155</th>
      <td>25.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>10.166452</td>
      <td>0.883099</td>
      <td>7.774662</td>
      <td>9.441895</td>
      <td>10.42738</td>
      <td>10.774703</td>
      <td>11.398507</td>
    </tr>
    <tr>
      <th>NVP-BEZ235</th>
      <td>25.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>9.83664</td>
      <td>0.38227</td>
      <td>8.935818</td>
      <td>9.616815</td>
      <td>9.876253</td>
      <td>10.104948</td>
      <td>10.476573</td>
    </tr>
    <tr>
      <th>belinostat</th>
      <td>25.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>9.719361</td>
      <td>0.630235</td>
      <td>8.049804</td>
      <td>9.406909</td>
      <td>9.762903</td>
      <td>9.957621</td>
      <td>11.005536</td>
    </tr>
    <tr>
      <th>pluripotin</th>
      <td>25.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>9.469802</td>
      <td>0.687683</td>
      <td>7.503132</td>
      <td>9.085914</td>
      <td>9.568229</td>
      <td>9.910524</td>
      <td>10.704892</td>
    </tr>
    <tr>
      <th>MLN2238</th>
      <td>25.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>8.930093</td>
      <td>0.741736</td>
      <td>7.218104</td>
      <td>8.485371</td>
      <td>9.008484</td>
      <td>9.357212</td>
      <td>10.017931</td>
    </tr>
    <tr>
      <th>KX2-391</th>
      <td>25.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>8.798709</td>
      <td>1.396529</td>
      <td>5.071334</td>
      <td>7.925459</td>
      <td>9.349282</td>
      <td>9.607232</td>
      <td>10.796027</td>
    </tr>
    <tr>
      <th>AT13387</th>
      <td>25.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>8.378987</td>
      <td>0.764056</td>
      <td>6.576897</td>
      <td>8.046521</td>
      <td>8.281312</td>
      <td>8.913646</td>
      <td>9.612334</td>
    </tr>
    <tr>
      <th>leptomycin B</th>
      <td>25.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>3.473396</td>
      <td>1.242517</td>
      <td>0.864948</td>
      <td>2.824049</td>
      <td>3.549045</td>
      <td>4.49121</td>
      <td>5.194158</td>
    </tr>
    <tr>
      <th>Patient ID</th>
      <td>25</td>
      <td>25</td>
      <td>TCGA-D8-A1JU</td>
      <td>1</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Step 2: Exploratory Data Analysis</span>
<span class="k">def</span><span class="w"> </span><span class="nf">perform_eda</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Exploratory Data Analysis ===&quot;</span><span class="p">)</span>
    <span class="c1"># Separate metadata from drug sensitivity values</span>
    <span class="n">drug_data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Patient ID&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Distribution of drug sensitivity values</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">drug_data</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of Drug Sensitivity Values&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Sensitivity Value&#39;</span><span class="p">)</span>
    
    <span class="c1"># Boxplot of drug sensitivity values (first 10 drugs)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">drug_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">10</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Boxplot of First 10 Drugs&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">drug_data</span>
 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">drug_data</span> <span class="o">=</span> <span class="n">perform_eda</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=== Exploratory Data Analysis ===
</pre></div>
</div>
<img alt="_images/f625cf5f35c1cc46b3951a3b581a7de7562252810bcb221afa8ef1b829e2fce3.png" src="_images/f625cf5f35c1cc46b3951a3b581a7de7562252810bcb221afa8ef1b829e2fce3.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">drug_data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bendamustine</th>
      <th>ML320</th>
      <th>BRD-K14844214</th>
      <th>leptomycin B</th>
      <th>Compound 23 citrate</th>
      <th>BRD4132</th>
      <th>dabrafenib</th>
      <th>necrosulfonamide</th>
      <th>PF-543</th>
      <th>KX2-391</th>
      <th>...</th>
      <th>Compound 1541A</th>
      <th>pevonedistat</th>
      <th>ISOX</th>
      <th>tosedostat</th>
      <th>AT13387</th>
      <th>BRD-A02303741</th>
      <th>BRD-K99006945</th>
      <th>GSK525762A</th>
      <th>necrostatin-7</th>
      <th>nakiterpiosin</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>14.821152</td>
      <td>14.286200</td>
      <td>14.608184</td>
      <td>4.960653</td>
      <td>13.530885</td>
      <td>13.202820</td>
      <td>13.879099</td>
      <td>12.839373</td>
      <td>14.103941</td>
      <td>10.796027</td>
      <td>...</td>
      <td>14.778758</td>
      <td>12.541663</td>
      <td>12.113460</td>
      <td>12.364817</td>
      <td>8.913646</td>
      <td>14.860838</td>
      <td>13.170200</td>
      <td>13.116395</td>
      <td>14.548597</td>
      <td>11.835573</td>
    </tr>
    <tr>
      <th>1</th>
      <td>14.304843</td>
      <td>14.333355</td>
      <td>14.960661</td>
      <td>3.552977</td>
      <td>13.122806</td>
      <td>13.129905</td>
      <td>13.911525</td>
      <td>12.124210</td>
      <td>14.127482</td>
      <td>8.489440</td>
      <td>...</td>
      <td>15.108698</td>
      <td>10.936052</td>
      <td>11.802052</td>
      <td>11.893495</td>
      <td>8.326862</td>
      <td>15.265313</td>
      <td>15.341146</td>
      <td>13.509974</td>
      <td>14.311074</td>
      <td>10.772699</td>
    </tr>
    <tr>
      <th>2</th>
      <td>14.658052</td>
      <td>14.649223</td>
      <td>14.547810</td>
      <td>3.467945</td>
      <td>13.438683</td>
      <td>13.441228</td>
      <td>13.823993</td>
      <td>12.935296</td>
      <td>14.052508</td>
      <td>9.349282</td>
      <td>...</td>
      <td>15.012134</td>
      <td>12.837987</td>
      <td>11.944058</td>
      <td>11.694113</td>
      <td>8.622052</td>
      <td>15.205567</td>
      <td>14.039701</td>
      <td>13.252381</td>
      <td>14.496764</td>
      <td>11.387851</td>
    </tr>
    <tr>
      <th>3</th>
      <td>14.342911</td>
      <td>13.657840</td>
      <td>14.426898</td>
      <td>1.800027</td>
      <td>13.242654</td>
      <td>13.094447</td>
      <td>13.531232</td>
      <td>11.987928</td>
      <td>14.046877</td>
      <td>7.385516</td>
      <td>...</td>
      <td>14.811534</td>
      <td>11.098317</td>
      <td>11.480102</td>
      <td>11.379716</td>
      <td>8.080488</td>
      <td>14.906361</td>
      <td>13.462326</td>
      <td>13.030773</td>
      <td>14.466555</td>
      <td>9.665608</td>
    </tr>
    <tr>
      <th>4</th>
      <td>14.655920</td>
      <td>14.323148</td>
      <td>14.527811</td>
      <td>4.491210</td>
      <td>13.293485</td>
      <td>13.054068</td>
      <td>13.807173</td>
      <td>12.446720</td>
      <td>14.012040</td>
      <td>9.540638</td>
      <td>...</td>
      <td>14.816099</td>
      <td>12.075367</td>
      <td>11.878005</td>
      <td>11.800027</td>
      <td>8.595326</td>
      <td>14.988143</td>
      <td>14.074985</td>
      <td>12.959710</td>
      <td>14.435152</td>
      <td>11.143563</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 50 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">drug_data</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/0b2e89e686c2a1c801a0d73182520d92f7f236436a095b645a46a48333ed1525.png" src="_images/0b2e89e686c2a1c801a0d73182520d92f7f236436a095b645a46a48333ed1525.png" />
</div>
</div>
<section id="variance-plots">
<h6>Variance plots<a class="headerlink" href="#variance-plots" title="Link to this heading"></a></h6>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">variances</span> <span class="o">=</span> <span class="n">drug_data</span><span class="o">.</span><span class="n">var</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">variances</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">variances</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Variance Across Columns&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Variance&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/657a95d374dc9c19d317f03850231025848bb9fdada4d05751a2838f9042a92c.png" src="_images/657a95d374dc9c19d317f03850231025848bb9fdada4d05751a2838f9042a92c.png" />
</div>
</div>
</section>
</section>
<section id="normalize-the-data-standardization">
<h5>Normalize the data (Standardization)<a class="headerlink" href="#normalize-the-data-standardization" title="Link to this heading"></a></h5>
<p><strong>PCA is sensitive to the variances of the original features</strong>, therefore data normalization before applying PCA is crucial</p>
<ul class="simple">
<li><p>PCA works by identifying the directions (principal components) that capture the maximum variance in the data.</p></li>
<li><p>Variables with larger variances can dominate the principal components</p>
<ul>
<li><p>This means the principal components might primarily reflect the variability of the features with the largest ranges</p></li>
<li><p>principal components do not capture the underlying relationships in the data</p></li>
</ul>
</li>
<li><p>Drugs with inherently higher variability in their sensitivity scores would disproportionately influence the principal components, potentially masking the contributions and relationships involving drugs with lower score variability.</p></li>
</ul>
<p>PCA looks for directions of maximum variance, standardization ensures that each feature contributes more equally to the determination of the principal components</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create the scaler and standardize the data</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">drug_data</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">drug_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Type of drug_data:&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">drug_data</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of drug_data:&quot;</span><span class="p">,</span> <span class="n">drug_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;First 5 rows and columns of drug_data:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">drug_data</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span> <span class="p">:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Type of drug_data: &lt;class &#39;numpy.ndarray&#39;&gt;
Shape of drug_data: (25, 50)
First 5 rows and columns of drug_data:
 [[ 1.11745915 -0.14919196 -0.01756464  1.22165355  0.70067562]
 [-0.4261314  -0.02638244  2.24640919  0.06536914 -0.66625469]
 [ 0.62984536  0.7962644  -0.40535119 -0.00447747  0.3918278 ]
 [-0.3123208  -1.78569382 -1.18197636 -1.3745291  -0.26480228]
 [ 0.62347222 -0.0529662  -0.5338052   0.83604629 -0.09453399]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">drug_data</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c64144c71820efdae9ded4c74865638435e542cfa81d0a4b1b9eb56a1b247d7a.png" src="_images/c64144c71820efdae9ded4c74865638435e542cfa81d0a4b1b9eb56a1b247d7a.png" />
</div>
</div>
</section>
</section>
<section id="pca-implementation">
<h4>PCA Implementation<a class="headerlink" href="#pca-implementation" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>Apply PCA transformation</p></li>
<li><p>Calculate explained variance</p></li>
</ul>
<section id="apply-pca-transformation">
<h5>Apply PCA transformation<a class="headerlink" href="#apply-pca-transformation" title="Link to this heading"></a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create the PCA instance and fit and transform the data with pca</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">()</span>
<span class="n">pc</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">drug_data</span><span class="p">)</span>

<span class="c1">## `fit()` in PCA:</span>
<span class="c1"># Calculates the principal components (eigenvectors) and their explained variances</span>
<span class="c1"># Determines the transformation matrix based on your data</span>
<span class="c1"># Stores these components internally in the PCA object</span>
<span class="c1"># Does not actually transform your data</span>

<span class="c1">## `transform()` in PCA:</span>
<span class="c1"># Projects your data onto the principal components using the previously calculated transformation matrix</span>
<span class="c1"># Actually reduces the dimensionality of your data</span>
<span class="c1"># Example: pca.transform(X_test) projects test data onto the same components learned from training data</span>

<span class="c1">## `fit_transform()` in PCA:</span>
<span class="c1"># Combines both operations: calculates principal components and then projects your data</span>
<span class="c1"># Equivalent to calling fit() followed by transform()</span>
<span class="c1"># More efficient than calling them separately</span>
<span class="c1"># Example: pca.fit_transform(X_train) learns components from training data and immediately projects it</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Type of pc:&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">pc</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of pc:&quot;</span><span class="p">,</span> <span class="n">pc</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;First 5 rows and columns of pc:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">pc</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span> <span class="p">:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Type of pc: &lt;class &#39;numpy.ndarray&#39;&gt;
Shape of pc: (25, 25)
First 5 rows and columns of pc:
 [[ 3.64790724  3.78552267  1.33659718 -0.20864174 -2.17346721]
 [ 0.32125071 -5.9898321   4.18994535 -0.20697045  0.17194817]
 [ 3.83231009  1.28508967 -0.47749898 -2.19393142  3.98217509]
 [-5.63359232  3.69098317 -3.47828106 -0.8034397   0.44613498]
 [ 0.17402269  1.51797501  0.16606953  2.91234111  0.42116796]]
</pre></div>
</div>
</div>
</div>
<p><strong>Note:</strong></p>
<ul class="simple">
<li><p>Original <code class="docutils literal notranslate"><span class="pre">drug_data</span></code> had 25 rows (observations), so <code class="docutils literal notranslate"><span class="pre">pc</span></code> also had 25 rows representing patients</p></li>
<li><p>We didn’t specify the number of components (<code class="docutils literal notranslate"><span class="pre">n_components</span></code>) when creating the PCA object (<code class="docutils literal notranslate"><span class="pre">pca</span> <span class="pre">=</span> <span class="pre">PCA()</span></code>), scikit-learn defaults to calculating <code class="docutils literal notranslate"><span class="pre">min(n_samples,</span> <span class="pre">n_features)</span></code> components. Original dataset had 50 features, PCA still only computes 25 components because the maximum number of meaningful principal components is limited by the number of samples (you can’t find more independent directions of variance than you have data points).</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">fit_transform</span></code> method did two things:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">fit</span></code>: It analyzed drug_data to find the 25 principal component directions (axes) based on the variance and correlations between your original features.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">transform</span></code>: It then projected your original 25 samples from their original feature space (with 50 dimensions) onto this new coordinate system defined by the 25 principal components</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pc_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">pc</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;PC_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">pc</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">)])</span>
<span class="n">pc_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PC_1</th>
      <th>PC_2</th>
      <th>PC_3</th>
      <th>PC_4</th>
      <th>PC_5</th>
      <th>PC_6</th>
      <th>PC_7</th>
      <th>PC_8</th>
      <th>PC_9</th>
      <th>PC_10</th>
      <th>...</th>
      <th>PC_16</th>
      <th>PC_17</th>
      <th>PC_18</th>
      <th>PC_19</th>
      <th>PC_20</th>
      <th>PC_21</th>
      <th>PC_22</th>
      <th>PC_23</th>
      <th>PC_24</th>
      <th>PC_25</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3.647907</td>
      <td>3.785523</td>
      <td>1.336597</td>
      <td>-0.208642</td>
      <td>-2.173467</td>
      <td>-0.159574</td>
      <td>-0.201224</td>
      <td>-0.175144</td>
      <td>-0.442335</td>
      <td>0.125566</td>
      <td>...</td>
      <td>0.015509</td>
      <td>0.053778</td>
      <td>-0.106066</td>
      <td>-0.353473</td>
      <td>-0.059685</td>
      <td>-0.655202</td>
      <td>0.315228</td>
      <td>-0.239004</td>
      <td>0.257046</td>
      <td>1.959170e-16</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.321251</td>
      <td>-5.989832</td>
      <td>4.189945</td>
      <td>-0.206970</td>
      <td>0.171948</td>
      <td>0.960831</td>
      <td>-0.520194</td>
      <td>1.106246</td>
      <td>-0.674214</td>
      <td>-0.811364</td>
      <td>...</td>
      <td>-0.724327</td>
      <td>-0.503311</td>
      <td>0.348717</td>
      <td>-0.460284</td>
      <td>-0.166123</td>
      <td>0.121399</td>
      <td>0.262114</td>
      <td>0.042369</td>
      <td>-0.096848</td>
      <td>1.959170e-16</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3.832310</td>
      <td>1.285090</td>
      <td>-0.477499</td>
      <td>-2.193931</td>
      <td>3.982175</td>
      <td>-0.967499</td>
      <td>-0.351455</td>
      <td>0.389307</td>
      <td>0.007497</td>
      <td>0.070364</td>
      <td>...</td>
      <td>0.080597</td>
      <td>-0.748926</td>
      <td>-0.429462</td>
      <td>-0.277130</td>
      <td>-0.028362</td>
      <td>0.054581</td>
      <td>0.009554</td>
      <td>0.045150</td>
      <td>0.040776</td>
      <td>1.959170e-16</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-5.633592</td>
      <td>3.690983</td>
      <td>-3.478281</td>
      <td>-0.803440</td>
      <td>0.446135</td>
      <td>0.610747</td>
      <td>-2.052404</td>
      <td>0.316239</td>
      <td>-1.076850</td>
      <td>-1.359736</td>
      <td>...</td>
      <td>0.029642</td>
      <td>0.142202</td>
      <td>0.806519</td>
      <td>0.175962</td>
      <td>-0.013190</td>
      <td>-0.119514</td>
      <td>-0.072060</td>
      <td>0.053852</td>
      <td>0.077116</td>
      <td>1.959170e-16</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.174023</td>
      <td>1.517975</td>
      <td>0.166070</td>
      <td>2.912341</td>
      <td>0.421168</td>
      <td>-0.887175</td>
      <td>-1.127990</td>
      <td>-1.452414</td>
      <td>-1.104615</td>
      <td>-0.970554</td>
      <td>...</td>
      <td>0.832998</td>
      <td>-0.053671</td>
      <td>-0.443638</td>
      <td>-0.031360</td>
      <td>-0.348642</td>
      <td>0.422218</td>
      <td>0.010565</td>
      <td>-0.405376</td>
      <td>-0.039028</td>
      <td>1.959170e-16</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 25 columns</p>
</div></div></div>
</div>
<section id="pca-context">
<h6>PCA context<a class="headerlink" href="#pca-context" title="Link to this heading"></a></h6>
<ul class="simple">
<li><p>PCA aims to summarize a large set of correlated variables with a smaller number of representative variables</p></li>
<li><p>The goal is to find a low-dimensional representation of the data that retains as much of the original variation as possible</p></li>
<li><p>Why focus on maximizing variance?</p>
<ul>
<li><p>By capturing most of the variation in the first few uncorrelated PCs, PCA allows you to summarize a large set of potentially correlated variables with a smaller number of representative variables</p></li>
<li><p>This process can be viewed as identifying directions in the original feature space along which the data vary the most, or finding low-dimensional linear surfaces that are closest to the observations</p></li>
<li><p>This is valuable for dimension reduction and compression, especially when dealing with many attributes that might be redundant</p></li>
</ul>
</li>
<li><p>By transforming the original correlated variables into a set of uncorrelated principal components, PCA effectively removes redundancy in the data</p>
<ul>
<li><p>PCA transforms the original correlated variables into a new set of uncorrelated variables (the principal components), ordered by how much variance they explain. This allows you to potentially use a smaller subset of these new, uncorrelated components to represent the data while retaining most of the original variability</p></li>
</ul>
</li>
<li><p><strong>The first principal component</strong> is defined as the linear combination of the original features that has the largest sample variance</p></li>
<li><p><strong>Subsequent principal components</strong> are then found such that they have the maximal variance out of all linear combinations that are uncorrelated with the preceding principal components</p>
<ul>
<li><p>For example, the second principal component must be uncorrelated with the first, the third with the first two, and so on</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">drug_data_normalised</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">drug_data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Correlation heatmap</span>
<span class="c1"># plt.figure(figsize=(12, 10))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">drug_data_normalised</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">drug_data_normalised</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span> 
            <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Correlation Heatmap (All Drugs)&#39;</span><span class="p">)</span>

<span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">pc_df</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">pc_df</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span> 
            <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Correlation Heatmap (PCA Components)&#39;</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/db72dccdbc8a9915ceb381195ba82aaec2f1ed948f70ba530bba1296f2b5fdcd.png" src="_images/db72dccdbc8a9915ceb381195ba82aaec2f1ed948f70ba530bba1296f2b5fdcd.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="n">drug_data_normalised</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;box&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Drug Sensitivity Boxplot&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_xticklabels</span><span class="p">(),</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>  <span class="c1"># Rotate x-labels for axes[0]</span>
<span class="n">pc_df</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;box&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;PCA Components Boxplot&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c8977976b111bc0454129f42e5ec07b651fe355df44b2898f29f24e31f22b2a7.png" src="_images/c8977976b111bc0454129f42e5ec07b651fe355df44b2898f29f24e31f22b2a7.png" />
</div>
</div>
<p><em><strong>Note:</strong></em></p>
<ul class="simple">
<li><p>PCA successfully achieved its goal of decorrelating our dataset</p></li>
<li><p>Decorrelation:</p>
<ul>
<li><p>The variance originally shared between features (correlated features) in the original dataset has been reorganized and captured along these new, independent PC axes</p></li>
</ul>
</li>
<li><p>Correlated variables inherently contain overlapping information (shared variation)</p></li>
<li><p>When variables are correlated, it means their values tend to change together to some degree</p>
<ul>
<li><p>This implies that they are capturing some of the same underlying patterns or variance in the data</p></li>
<li><p>Dealing with a large set of correlated variables suggests there might be redundancy</p></li>
<li><p>The correlation structure can be thought of as arising from shared underlying sources or latent variables.</p></li>
</ul>
</li>
<li><p>PCA transforms these into uncorrelated components</p>
<ul>
<li><p>The process of Principal Component Analysis explicitly finds a new set of variables - principal components (PCs), which are linear combinations of the original features</p></li>
<li><p>A key property of these principal components is that they are uncorrelated with each other</p></li>
<li><p>The second principal component is defined as having maximal variance out of all linear combinations that are uncorrelated with the first principal component, and this extends to subsequent components</p></li>
</ul>
</li>
<li><p>Decorrelation ensures each PC captures a distinct aspect of variability:</p>
<ul>
<li><p>Because each subsequent principal component is constrained to be uncorrelated with the ones already found, it is forced to capture variation in a direction that is distinct from the directions represented by the earlier components</p></li>
<li><p>The first PC captures the most variance. The second PC captures the most variance that is not captured by the first PC (due to the uncorrelated constraint), and so on.</p></li>
<li><p>This ensures that each PC adds new, non-overlapping information about the data’s variability, allowing the first few components to collectively explain a “sizable amount of the variation” and provide a lower-dimensional representation that retains “as much of the information as possible”</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pc_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PC_1</th>
      <th>PC_2</th>
      <th>PC_3</th>
      <th>PC_4</th>
      <th>PC_5</th>
      <th>PC_6</th>
      <th>PC_7</th>
      <th>PC_8</th>
      <th>PC_9</th>
      <th>PC_10</th>
      <th>...</th>
      <th>PC_16</th>
      <th>PC_17</th>
      <th>PC_18</th>
      <th>PC_19</th>
      <th>PC_20</th>
      <th>PC_21</th>
      <th>PC_22</th>
      <th>PC_23</th>
      <th>PC_24</th>
      <th>PC_25</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3.647907</td>
      <td>3.785523</td>
      <td>1.336597</td>
      <td>-0.208642</td>
      <td>-2.173467</td>
      <td>-0.159574</td>
      <td>-0.201224</td>
      <td>-0.175144</td>
      <td>-0.442335</td>
      <td>0.125566</td>
      <td>...</td>
      <td>0.015509</td>
      <td>0.053778</td>
      <td>-0.106066</td>
      <td>-0.353473</td>
      <td>-0.059685</td>
      <td>-0.655202</td>
      <td>0.315228</td>
      <td>-0.239004</td>
      <td>0.257046</td>
      <td>1.959170e-16</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.321251</td>
      <td>-5.989832</td>
      <td>4.189945</td>
      <td>-0.206970</td>
      <td>0.171948</td>
      <td>0.960831</td>
      <td>-0.520194</td>
      <td>1.106246</td>
      <td>-0.674214</td>
      <td>-0.811364</td>
      <td>...</td>
      <td>-0.724327</td>
      <td>-0.503311</td>
      <td>0.348717</td>
      <td>-0.460284</td>
      <td>-0.166123</td>
      <td>0.121399</td>
      <td>0.262114</td>
      <td>0.042369</td>
      <td>-0.096848</td>
      <td>1.959170e-16</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3.832310</td>
      <td>1.285090</td>
      <td>-0.477499</td>
      <td>-2.193931</td>
      <td>3.982175</td>
      <td>-0.967499</td>
      <td>-0.351455</td>
      <td>0.389307</td>
      <td>0.007497</td>
      <td>0.070364</td>
      <td>...</td>
      <td>0.080597</td>
      <td>-0.748926</td>
      <td>-0.429462</td>
      <td>-0.277130</td>
      <td>-0.028362</td>
      <td>0.054581</td>
      <td>0.009554</td>
      <td>0.045150</td>
      <td>0.040776</td>
      <td>1.959170e-16</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-5.633592</td>
      <td>3.690983</td>
      <td>-3.478281</td>
      <td>-0.803440</td>
      <td>0.446135</td>
      <td>0.610747</td>
      <td>-2.052404</td>
      <td>0.316239</td>
      <td>-1.076850</td>
      <td>-1.359736</td>
      <td>...</td>
      <td>0.029642</td>
      <td>0.142202</td>
      <td>0.806519</td>
      <td>0.175962</td>
      <td>-0.013190</td>
      <td>-0.119514</td>
      <td>-0.072060</td>
      <td>0.053852</td>
      <td>0.077116</td>
      <td>1.959170e-16</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.174023</td>
      <td>1.517975</td>
      <td>0.166070</td>
      <td>2.912341</td>
      <td>0.421168</td>
      <td>-0.887175</td>
      <td>-1.127990</td>
      <td>-1.452414</td>
      <td>-1.104615</td>
      <td>-0.970554</td>
      <td>...</td>
      <td>0.832998</td>
      <td>-0.053671</td>
      <td>-0.443638</td>
      <td>-0.031360</td>
      <td>-0.348642</td>
      <td>0.422218</td>
      <td>0.010565</td>
      <td>-0.405376</td>
      <td>-0.039028</td>
      <td>1.959170e-16</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 25 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate cumulative variance = cumulative proportion of variance explained by the principal components</span>
<span class="n">variances</span> <span class="o">=</span> <span class="n">pc_df</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">cumulative_variance</span> <span class="o">=</span> <span class="n">variances</span><span class="o">.</span><span class="n">cumsum</span><span class="p">()</span> <span class="o">/</span> <span class="n">variances</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="c1"># Plot cumulative variance</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">cumulative_variance</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">cumulative_variance</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Cumulative Variance Explained by Principal Components&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Principal Components&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Cumulative Variance Explained&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/aa390baf64a7a0cac1f4fb2d5aa36871e963041e3f705469542fcbccd55b5388.png" src="_images/aa390baf64a7a0cac1f4fb2d5aa36871e963041e3f705469542fcbccd55b5388.png" />
</div>
</div>
</section>
</section>
<section id="explained-variance">
<h5>Explained variance:<a class="headerlink" href="#explained-variance" title="Link to this heading"></a></h5>
<ul class="simple">
<li><p>PCA seeks a low-dimensional representation of a dataset that captures as much as possible of the variation in the original data</p></li>
<li><p><strong>Variance Explained by a principal component (PC):</strong></p>
<ul>
<li><p>Each PC captures a specific amount of variance (this is also known as variance explained by each PC)</p></li>
<li><p>For a specific PC, say the <code class="docutils literal notranslate"><span class="pre">m-th</span></code> one, its variance explained is essentially the variance of the scores across <code class="docutils literal notranslate"><span class="pre">m-th</span></code> PC, when the data points are projected principal components</p></li>
</ul>
</li>
<li><p><strong>Relationship between PC Variance and Total Variance:</strong></p>
<ul>
<li><p>A key property is that the <em><strong>sum of the variances of all principal components equals the total variance of the original data</strong></em></p></li>
<li><p>This means maximizing the variance of the <code class="docutils literal notranslate"><span class="pre">n</span></code> principal components is equivalent to minimizing the reconstruction error when approximating the data with those <code class="docutils literal notranslate"><span class="pre">n</span></code>  components</p></li>
</ul>
</li>
<li><p><strong>Proportion of Variance Explained - PVE (Explained Variance Ratio):</strong></p>
<ul>
<li><p>The PVE of the <code class="docutils literal notranslate"><span class="pre">mth</span></code> principal component is calculated as the variance of the <code class="docutils literal notranslate"><span class="pre">mth</span></code> principal component divided by the total variance in the original data</p></li>
<li><p>The PVEs for all principal components (up to min(n-1, p)) sum to one</p></li>
</ul>
</li>
<li><p><strong>Cumulative PVE:</strong></p>
<ul>
<li><p>The cumulative PVE of the principal components is simply the sum of the PVEs for those components</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Access the explained variance directly</span>
<span class="n">explained_variance</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Explained variance by component:&quot;</span><span class="p">,</span> <span class="n">explained_variance</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Explained variance by component: [2.06118885e+01 9.46481592e+00 5.66619038e+00 4.25914905e+00
 2.86483250e+00 1.91158440e+00 1.59439385e+00 1.22821102e+00
 9.13563089e-01 8.09987389e-01 5.90796907e-01 4.07254006e-01
 3.73077915e-01 2.98129789e-01 2.48097781e-01 2.31592814e-01
 1.58434105e-01 1.29071221e-01 8.11724160e-02 7.48451289e-02
 6.29952247e-02 5.23843184e-02 3.73057774e-02 1.35597766e-02
 3.99827721e-32]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">explained_variance_ratio</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Explained variance ratio by component:&quot;</span><span class="p">,</span> <span class="n">explained_variance_ratio</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Explained variance ratio by component: [3.95748260e-01 1.81724466e-01 1.08790855e-01 8.17756618e-02
 5.50047841e-02 3.67024205e-02 3.06123619e-02 2.35816516e-02
 1.75404113e-02 1.55517579e-02 1.13433006e-02 7.81927692e-03
 7.16309597e-03 5.72409195e-03 4.76347739e-03 4.44658203e-03
 3.04193482e-03 2.47816745e-03 1.55851039e-03 1.43702647e-03
 1.20950831e-03 1.00577891e-03 7.16270926e-04 2.60347711e-04
 7.67669224e-34]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Option 3: Calculate the cumulative explained variance</span>
<span class="n">cumulative_explained_variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">explained_variance_ratio</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cumulative explained variance:&quot;</span><span class="p">,</span> <span class="n">cumulative_explained_variance</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cumulative explained variance: [0.39574826 0.57747273 0.68626358 0.76803924 0.82304403 0.85974645
 0.89035881 0.91394046 0.93148087 0.94703263 0.95837593 0.96619521
 0.9733583  0.9790824  0.98384587 0.98829246 0.99133439 0.99381256
 0.99537107 0.99680809 0.9980176  0.99902338 0.99973965 1.
 1.        ]
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualize-the-explained-variance">
<h5>Visualize the explained variance<a class="headerlink" href="#visualize-the-explained-variance" title="Link to this heading"></a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualize the explained variance</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">explained_variance_ratio</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">explained_variance_ratio</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Individual explained variance&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">cumulative_explained_variance</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">cumulative_explained_variance</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="s1">&#39;mid&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Cumulative explained variance&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Explained variance ratio&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Principal components&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;95</span><span class="si">% e</span><span class="s1">xplained variance threshold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mf">0.90</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dotted&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;90</span><span class="si">% e</span><span class="s1">xplained variance threshold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3ad4ea091a5a9b2196091c065d01ed8de3b5292c340fecd767ddf82b5b27b201.png" src="_images/3ad4ea091a5a9b2196091c065d01ed8de3b5292c340fecd767ddf82b5b27b201.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">cumulative_explained_variance</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">cumulative_explained_variance</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Cumulative Variance Explained by Principal Components&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Principal Components&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Cumulative Explained Variance&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/d060c8ff8d7786355365430d6d182f1458824c32639dce6b924530db5b6493db.png" src="_images/d060c8ff8d7786355365430d6d182f1458824c32639dce6b924530db5b6493db.png" />
</div>
</div>
</section>
</section>
<section id="determine-optimal-number-of-components">
<h4>Determine optimal number of components<a class="headerlink" href="#determine-optimal-number-of-components" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>Variance Threshold</p></li>
<li><p>Scree Plot (Elbow Method)</p></li>
</ul>
<section id="variance-threshold">
<h5>Variance Threshold<a class="headerlink" href="#variance-threshold" title="Link to this heading"></a></h5>
<ul class="simple">
<li><p>Find number of components that explain at least 95% (or 99%) of variance</p></li>
<li><p>Selects components that collectively explain a predefined percentage (e.g., 95%) of total variance</p></li>
<li><p>Ensures you keep enough information while reducing dimensions</p></li>
<li><p>Provides a clear cutoff criterion that doesn’t require subjective judgment (Automated selection)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_components_95</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">cumulative_explained_variance</span> <span class="o">&gt;=</span> <span class="mf">0.95</span><span class="p">)</span>
<span class="c1"># np.argmax(): This function returns the index of the first occurrence of the maximum value in the array.</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of components for 95% variance: </span><span class="si">{</span><span class="n">n_components_95</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># +1 because index starts at 0</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of components for 95% variance: 11
</pre></div>
</div>
</div>
</div>
</section>
<section id="scree-plot">
<h5>Scree Plot<a class="headerlink" href="#scree-plot" title="Link to this heading"></a></h5>
<ul class="simple">
<li><p>Helps identify the point where additional components yield diminishing returns (Visual identification)</p>
<ul>
<li><p>Balances model complexity against information retention</p></li>
</ul>
</li>
<li><p>The “elbow” often marks where principal components transition from capturing signal to capturing noise (Noise reduction)</p></li>
</ul>
<p><strong>Logic Behind Using a Scree Plot:</strong></p>
<ol class="arabic simple">
<li><p>Understanding Eigenvalues</p></li>
</ol>
<ul class="simple">
<li><p>Eigenvalues are the foundation of scree plots. In PCA, eigenvalues represent the amount of variance captured by each  principal component</p></li>
<li><p>Eigenvalue associated with a specific eigenvector is equal to the variance of the corresponding principal component</p></li>
<li><p>Specifically:</p>
<ul>
<li><p>Each eigenvalue corresponds to one principal component</p></li>
<li><p>The magnitude of an eigenvalue indicates how much variance that component explains</p></li>
<li><p>Eigenvalues are measured in the same units as the original data’s variance (When PCA is performed on the standardized data, eigenvalues are unitless because standardization removes units)</p></li>
<li><p>The sum of all eigenvalues equals the total variance in the dataset</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="3">
<li><p>The Scree Plot Displays Eigenvalues</p></li>
</ol>
<ul class="simple">
<li><p>A scree plot displays the <strong>eigenvalues</strong> (not directly the proportion of variance explained) on the Y-axis for each principal component on the X-axis</p></li>
<li><p>The eigenvalues are plotted in descending order, creating the characteristic “scree” or slope appearance.</p></li>
</ul>
<ol class="arabic simple" start="4">
<li><p>Relationship to Proportion of Variance Explained (PVE):</p></li>
</ol>
<ul class="simple">
<li><p><strong>PVE</strong> for the m-th principal component = (Eigenvalue of m-th component) / (Sum of all eigenvalues)</p></li>
<li><p>Together, all principal components explain 100% of the variance (sum of all PVEs = 1)</p></li>
</ul>
<ol class="arabic simple" start="5">
<li><p>Identifying the “Elbow”</p></li>
</ol>
<ul class="simple">
<li><p>The visual logic involves examining the scree plot and looking for a point where the eigenvalues drop off noticeably</p></li>
<li><p>This sharp drop-off is often referred to as an “elbow” in the plot</p></li>
<li><p>Since eigenvalues directly represent variance amounts, a steep decline indicates that subsequent components capture significantly less variance.</p></li>
</ul>
<ol class="arabic simple" start="6">
<li><p>Interpreting the Elbow</p>
<ul class="simple">
<li><p>The idea is that the components before the elbow have <strong>large eigenvalues</strong> and therefore capture a “sizable amount of the variation,” representing the key dimensions along which the data vary the most</p></li>
<li><p>Components after the elbow have <strong>small eigenvalues</strong> and explain significantly less additional variance, making them less “interesting” or necessary for understanding the main patterns in the data.</p></li>
</ul>
</li>
<li><p>By choosing the number of components up to the elbow, you aim to retain the minimum number of components required to explain a substantial portion of the total variance while achieving dimensionality reduction.</p></li>
</ol>
<p><em>Important Considerations:</em></p>
<ul class="simple">
<li><p>This method of choosing the number of components by inspecting the scree plot is <strong>“ad hoc” and “inherently subjective”</strong></p></li>
<li><p>There isn’t a single, universally accepted objective rule based solely on the scree plot</p></li>
<li><p>The decision often depends on the specific application and the dataset</p></li>
<li><p>In practice, analysts might look at the first few components for interesting patterns and continue examining subsequent ones until no further insights are gained</p></li>
<li><p>Alternative methods include using cumulative proportion of variance explained (e.g., retaining components that explain 80-90% of total variance) or cross-validation approaches</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">explained_variance</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">explained_variance</span><span class="p">,</span> <span class="s1">&#39;o-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Scree Plot&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Principal Component&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Eigenvalue (Variance)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/18e7566391389df74808f023cc93946de2f0c92fff9b6036a34f5b7a6497f16f.png" src="_images/18e7566391389df74808f023cc93946de2f0c92fff9b6036a34f5b7a6497f16f.png" />
</div>
</div>
</section>
</section>
<section id="automated-selection-with-pca">
<h4>Automated Selection with PCA<a class="headerlink" href="#automated-selection-with-pca" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>Instead of manually determining the number of components, you can initialize PCA with a variance threshold:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Automatically select components to explain 90% of variance</span>
<span class="n">optimal_pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mf">0.90</span><span class="p">)</span>  <span class="c1"># Keep enough components to explain 90% of variance</span>
<span class="n">pc_auto</span> <span class="o">=</span> <span class="n">optimal_pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">drug_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of components selected: </span><span class="si">{</span><span class="n">optimal_pca</span><span class="o">.</span><span class="n">n_components_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">optimal_pca_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">pc_auto</span><span class="p">,</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;PC</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pc_auto</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
<span class="p">)</span>
<span class="n">optimal_pca_df</span><span class="p">[</span><span class="s1">&#39;Patient ID&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;Patient ID&quot;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Optimal PCA DataFrame: </span><span class="se">\n</span><span class="si">{</span><span class="n">optimal_pca_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of components selected: 8
Optimal PCA DataFrame: 
        PC1       PC2       PC3       PC4       PC5       PC6       PC7  \
0  3.647907  3.785523  1.336597 -0.208642 -2.173467 -0.159574 -0.201224   
1  0.321251 -5.989832  4.189945 -0.206970  0.171948  0.960831 -0.520194   
2  3.832310  1.285090 -0.477499 -2.193931  3.982175 -0.967499 -0.351455   
3 -5.633592  3.690983 -3.478281 -0.803440  0.446135  0.610747 -2.052404   
4  0.174023  1.517975  0.166070  2.912341  0.421168 -0.887175 -1.127990   

        PC8    Patient ID  
0 -0.175144  TCGA-D8-A1JU  
1  1.106246  TCGA-AC-A3QQ  
2  0.389307  TCGA-C8-A12Q  
3  0.316239  TCGA-AR-A1AY  
4 -1.452414  TCGA-A8-A0A2  
</pre></div>
</div>
</div>
</div>
</section>
<section id="feature-loadings">
<h4>Feature Loadings<a class="headerlink" href="#feature-loadings" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>Feature Loadings are</p>
<ul>
<li><p>the weights that transform original, potentially correlated variables into a new set of principal components</p></li>
<li><p>i.e., contribution of each original feature to each principal component</p></li>
</ul>
</li>
<li><p>Shows which original features most strongly influence each principal component - <strong>Feature influence</strong></p></li>
<li><p>Helps interpret what each principal component represents - <strong>Component interpretation</strong></p></li>
<li><p>Identifies which original features are most important for your dataset’s structure - <strong>Feature selection</strong></p></li>
<li><p>Reveals relationships between features in your high-dimensional space - <strong>Dimensionality insights</strong></p></li>
</ul>
<p><strong>Loading and correlation:</strong></p>
<ul class="simple">
<li><p>Loadings are not correlations themselves - they are the coefficients (weights) in the linear combination that defines the principal component</p></li>
<li><p>In PCA (with standardized data), loadings are proportional to correlations between original variables and PC scores</p></li>
</ul>
<p><strong>Positive Loading (e.g., +0.7):</strong></p>
<ul class="simple">
<li><p>This indicates a positive correlation</p></li>
<li><p>When the score of the principal component increases, the value of the original feature also tends to increase. Conversely, when the PC score decreases, the feature’s value tends to decrease.</p></li>
</ul>
<p><strong>Negative Loading (e.g., -0.6):</strong></p>
<ul class="simple">
<li><p>This indicates a negative correlation</p></li>
<li><p>When the score of the principal component increases, the value of the original feature tends to decrease. Conversely, when the PC score decreases, the feature’s value tends to increase</p></li>
</ul>
<p>High absolute values (positive or negative) indicate strong influence on that component. A loading of 0 means no influence</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">loadings</span> <span class="o">=</span> <span class="n">optimal_pca</span><span class="o">.</span><span class="n">components_</span>

<span class="c1"># Get feature names (assuming you have them in a list or as column names)</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">columns</span>  <span class="c1"># Or your list of feature names</span>

<span class="c1"># Create a DataFrame with the loadings</span>
<span class="n">loadings_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">loadings</span><span class="p">,</span>
    <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">,</span>
    <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;PC_</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">loadings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
<span class="p">)</span>

<span class="n">loadings_df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
Index: 8 entries, PC_1 to PC_8
Data columns (total 50 columns):
 #   Column                          Non-Null Count  Dtype  
---  ------                          --------------  -----  
 0   bendamustine                    8 non-null      float64
 1   ML320                           8 non-null      float64
 2   BRD-K14844214                   8 non-null      float64
 3   leptomycin B                    8 non-null      float64
 4   Compound 23 citrate             8 non-null      float64
 5   BRD4132                         8 non-null      float64
 6   dabrafenib                      8 non-null      float64
 7   necrosulfonamide                8 non-null      float64
 8   PF-543                          8 non-null      float64
 9   KX2-391                         8 non-null      float64
 10  ELCPK                           8 non-null      float64
 11  carboplatin                     8 non-null      float64
 12  SB-525334                       8 non-null      float64
 13  CIL41                           8 non-null      float64
 14  belinostat                      8 non-null      float64
 15  Compound 7d-cis                 8 non-null      float64
 16  lapatinib                       8 non-null      float64
 17  tacrolimus                      8 non-null      float64
 18  pifithrin-mu                    8 non-null      float64
 19  RG-108                          8 non-null      float64
 20  BRD-K97651142                   8 non-null      float64
 21  NVP-BEZ235                      8 non-null      float64
 22  BRD-K01737880                   8 non-null      float64
 23  pluripotin                      8 non-null      float64
 24  GW-405833                       8 non-null      float64
 25  masitinib                       8 non-null      float64
 26  YM-155                          8 non-null      float64
 27  MLN2238                         8 non-null      float64
 28  birinapant                      8 non-null      float64
 29  RAF265                          8 non-null      float64
 30  BRD-K27188169                   8 non-null      float64
 31  PIK-93                          8 non-null      float64
 32  N9-isopropylolomoucine          8 non-null      float64
 33  myricetin                       8 non-null      float64
 34  epigallocatechin-3-monogallate  8 non-null      float64
 35  ceranib-2                       8 non-null      float64
 36  BRD-K66532283                   8 non-null      float64
 37  elocalcitol                     8 non-null      float64
 38  RO4929097                       8 non-null      float64
 39  BRD-K02251932                   8 non-null      float64
 40  Compound 1541A                  8 non-null      float64
 41  pevonedistat                    8 non-null      float64
 42  ISOX                            8 non-null      float64
 43  tosedostat                      8 non-null      float64
 44  AT13387                         8 non-null      float64
 45  BRD-A02303741                   8 non-null      float64
 46  BRD-K99006945                   8 non-null      float64
 47  GSK525762A                      8 non-null      float64
 48  necrostatin-7                   8 non-null      float64
 49  nakiterpiosin                   8 non-null      float64
dtypes: float64(50)
memory usage: 3.2+ KB
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Contribution of each original feature to each principal component&quot;</span><span class="p">)</span>
<span class="n">loadings_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Contribution of each original feature to each principal component
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bendamustine</th>
      <th>ML320</th>
      <th>BRD-K14844214</th>
      <th>leptomycin B</th>
      <th>Compound 23 citrate</th>
      <th>BRD4132</th>
      <th>dabrafenib</th>
      <th>necrosulfonamide</th>
      <th>PF-543</th>
      <th>KX2-391</th>
      <th>...</th>
      <th>Compound 1541A</th>
      <th>pevonedistat</th>
      <th>ISOX</th>
      <th>tosedostat</th>
      <th>AT13387</th>
      <th>BRD-A02303741</th>
      <th>BRD-K99006945</th>
      <th>GSK525762A</th>
      <th>necrostatin-7</th>
      <th>nakiterpiosin</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>PC_1</th>
      <td>0.188893</td>
      <td>0.158907</td>
      <td>-0.014409</td>
      <td>0.184616</td>
      <td>0.188557</td>
      <td>0.148854</td>
      <td>0.169982</td>
      <td>0.195003</td>
      <td>0.114682</td>
      <td>0.186589</td>
      <td>...</td>
      <td>0.013166</td>
      <td>0.186654</td>
      <td>0.211779</td>
      <td>0.153139</td>
      <td>0.186287</td>
      <td>0.091061</td>
      <td>-0.092112</td>
      <td>0.125780</td>
      <td>0.127629</td>
      <td>0.184714</td>
    </tr>
    <tr>
      <th>PC_2</th>
      <td>0.130845</td>
      <td>-0.140145</td>
      <td>-0.233375</td>
      <td>0.073321</td>
      <td>-0.021347</td>
      <td>0.107959</td>
      <td>-0.080697</td>
      <td>-0.013266</td>
      <td>-0.024182</td>
      <td>0.121842</td>
      <td>...</td>
      <td>-0.272325</td>
      <td>0.094608</td>
      <td>0.014560</td>
      <td>0.064277</td>
      <td>0.026162</td>
      <td>-0.255982</td>
      <td>-0.258407</td>
      <td>-0.169401</td>
      <td>0.188433</td>
      <td>0.083508</td>
    </tr>
    <tr>
      <th>PC_3</th>
      <td>-0.021312</td>
      <td>-0.084223</td>
      <td>0.186021</td>
      <td>0.116362</td>
      <td>-0.187231</td>
      <td>0.127776</td>
      <td>-0.129210</td>
      <td>-0.165453</td>
      <td>0.120737</td>
      <td>0.124947</td>
      <td>...</td>
      <td>0.026282</td>
      <td>-0.007923</td>
      <td>-0.035613</td>
      <td>0.082174</td>
      <td>-0.057860</td>
      <td>-0.049318</td>
      <td>0.141969</td>
      <td>-0.145518</td>
      <td>-0.050762</td>
      <td>0.125907</td>
    </tr>
    <tr>
      <th>PC_4</th>
      <td>0.002208</td>
      <td>0.054969</td>
      <td>-0.168718</td>
      <td>0.204135</td>
      <td>0.007250</td>
      <td>-0.127992</td>
      <td>0.012934</td>
      <td>-0.043828</td>
      <td>-0.228499</td>
      <td>0.082702</td>
      <td>...</td>
      <td>-0.175538</td>
      <td>0.146641</td>
      <td>-0.057821</td>
      <td>0.019380</td>
      <td>0.129659</td>
      <td>-0.015643</td>
      <td>0.014241</td>
      <td>0.011453</td>
      <td>-0.116959</td>
      <td>0.151041</td>
    </tr>
    <tr>
      <th>PC_5</th>
      <td>0.032004</td>
      <td>0.169326</td>
      <td>-0.154553</td>
      <td>-0.061343</td>
      <td>-0.063709</td>
      <td>0.255198</td>
      <td>0.039662</td>
      <td>-0.012972</td>
      <td>-0.180148</td>
      <td>-0.060818</td>
      <td>...</td>
      <td>-0.012056</td>
      <td>0.095784</td>
      <td>-0.037420</td>
      <td>-0.213437</td>
      <td>-0.050259</td>
      <td>0.151289</td>
      <td>0.119979</td>
      <td>-0.133028</td>
      <td>-0.047117</td>
      <td>-0.040750</td>
    </tr>
    <tr>
      <th>PC_6</th>
      <td>0.026600</td>
      <td>-0.001502</td>
      <td>-0.203015</td>
      <td>0.044929</td>
      <td>0.140286</td>
      <td>0.042471</td>
      <td>0.153289</td>
      <td>-0.052095</td>
      <td>0.269030</td>
      <td>-0.099810</td>
      <td>...</td>
      <td>-0.158710</td>
      <td>-0.120513</td>
      <td>-0.109148</td>
      <td>0.034131</td>
      <td>0.272596</td>
      <td>0.106136</td>
      <td>-0.022863</td>
      <td>-0.083687</td>
      <td>0.295653</td>
      <td>-0.157441</td>
    </tr>
    <tr>
      <th>PC_7</th>
      <td>0.110011</td>
      <td>0.061453</td>
      <td>-0.006347</td>
      <td>0.049683</td>
      <td>-0.096940</td>
      <td>0.049480</td>
      <td>-0.080599</td>
      <td>0.157775</td>
      <td>-0.281277</td>
      <td>-0.054539</td>
      <td>...</td>
      <td>0.088570</td>
      <td>0.008416</td>
      <td>-0.082869</td>
      <td>0.363718</td>
      <td>-0.125535</td>
      <td>0.122516</td>
      <td>-0.145911</td>
      <td>-0.100268</td>
      <td>0.119357</td>
      <td>0.078340</td>
    </tr>
    <tr>
      <th>PC_8</th>
      <td>-0.007307</td>
      <td>-0.195364</td>
      <td>-0.010461</td>
      <td>0.000593</td>
      <td>0.019415</td>
      <td>0.083812</td>
      <td>0.053971</td>
      <td>-0.126673</td>
      <td>0.113933</td>
      <td>-0.000942</td>
      <td>...</td>
      <td>-0.087146</td>
      <td>0.140472</td>
      <td>-0.021129</td>
      <td>-0.089389</td>
      <td>-0.021654</td>
      <td>0.044740</td>
      <td>-0.014215</td>
      <td>0.338453</td>
      <td>-0.170848</td>
      <td>0.043675</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 50 columns</p>
</div></div></div>
</div>
<section id="visualization-feature-loadings">
<h5>Visualization - Feature Loadings<a class="headerlink" href="#visualization-feature-loadings" title="Link to this heading"></a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a heatmap</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">heatmap</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span>
    <span class="n">loadings_df</span><span class="p">,</span> 
    <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span>
    <span class="n">center</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">annot</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;.2f&quot;</span><span class="p">,</span>
    <span class="n">linewidths</span><span class="o">=</span><span class="mf">.5</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;PCA Feature Loadings&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/555d2bb8e7cda6a8d45b5794c47d8c310f955c830b5c23d98758d4ca28a8bc55.png" src="_images/555d2bb8e7cda6a8d45b5794c47d8c310f955c830b5c23d98758d4ca28a8bc55.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Select top n contributing features for each component</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_top_features</span><span class="p">(</span><span class="n">loadings_df</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">top_features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    
    <span class="k">for</span> <span class="n">pc</span> <span class="ow">in</span> <span class="n">loadings_df</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
        <span class="n">pc_loadings</span> <span class="o">=</span> <span class="n">loadings_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">pc</span><span class="p">]</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">top_features</span><span class="p">[</span><span class="n">pc</span><span class="p">]</span> <span class="o">=</span> <span class="n">pc_loadings</span><span class="o">.</span><span class="n">index</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span>
        
    <span class="k">return</span> <span class="n">top_features</span>

<span class="n">top_features</span> <span class="o">=</span> <span class="n">get_top_features</span><span class="p">(</span><span class="n">loadings_df</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Top contributing features for each principal component:&quot;</span><span class="p">)</span>
<span class="n">top_features</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Top contributing features for each principal component:
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PC_1</th>
      <th>PC_2</th>
      <th>PC_3</th>
      <th>PC_4</th>
      <th>PC_5</th>
      <th>PC_6</th>
      <th>PC_7</th>
      <th>PC_8</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ISOX</td>
      <td>lapatinib</td>
      <td>NVP-BEZ235</td>
      <td>pluripotin</td>
      <td>CIL41</td>
      <td>RO4929097</td>
      <td>birinapant</td>
      <td>SB-525334</td>
    </tr>
    <tr>
      <th>1</th>
      <td>necrosulfonamide</td>
      <td>Compound 1541A</td>
      <td>RO4929097</td>
      <td>N9-isopropylolomoucine</td>
      <td>birinapant</td>
      <td>necrostatin-7</td>
      <td>tosedostat</td>
      <td>GSK525762A</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ceranib-2</td>
      <td>BRD-K99006945</td>
      <td>BRD-K02251932</td>
      <td>SB-525334</td>
      <td>NVP-BEZ235</td>
      <td>AT13387</td>
      <td>BRD-K66532283</td>
      <td>RO4929097</td>
    </tr>
    <tr>
      <th>3</th>
      <td>MLN2238</td>
      <td>BRD-A02303741</td>
      <td>elocalcitol</td>
      <td>PF-543</td>
      <td>BRD4132</td>
      <td>PF-543</td>
      <td>PF-543</td>
      <td>myricetin</td>
    </tr>
    <tr>
      <th>4</th>
      <td>BRD-K66532283</td>
      <td>RAF265</td>
      <td>BRD-K27188169</td>
      <td>birinapant</td>
      <td>RG-108</td>
      <td>tacrolimus</td>
      <td>myricetin</td>
      <td>BRD-K97651142</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Compound 7d-cis</td>
      <td>BRD-K14844214</td>
      <td>YM-155</td>
      <td>masitinib</td>
      <td>lapatinib</td>
      <td>CIL41</td>
      <td>GW-405833</td>
      <td>ML320</td>
    </tr>
    <tr>
      <th>6</th>
      <td>bendamustine</td>
      <td>PIK-93</td>
      <td>BRD-K01737880</td>
      <td>leptomycin B</td>
      <td>tosedostat</td>
      <td>carboplatin</td>
      <td>BRD-K97651142</td>
      <td>epigallocatechin-3-monogallate</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Compound 23 citrate</td>
      <td>carboplatin</td>
      <td>ELCPK</td>
      <td>BRD-K02251932</td>
      <td>RAF265</td>
      <td>BRD-K27188169</td>
      <td>RO4929097</td>
      <td>necrostatin-7</td>
    </tr>
    <tr>
      <th>8</th>
      <td>GW-405833</td>
      <td>BRD-K97651142</td>
      <td>masitinib</td>
      <td>PIK-93</td>
      <td>belinostat</td>
      <td>BRD-K14844214</td>
      <td>RG-108</td>
      <td>N9-isopropylolomoucine</td>
    </tr>
    <tr>
      <th>9</th>
      <td>pevonedistat</td>
      <td>myricetin</td>
      <td>CIL41</td>
      <td>myricetin</td>
      <td>PIK-93</td>
      <td>elocalcitol</td>
      <td>necrosulfonamide</td>
      <td>BRD-K01737880</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
</section>
<section id="k-means-cluster-analysis">
<h4>K-means Cluster analysis<a class="headerlink" href="#k-means-cluster-analysis" title="Link to this heading"></a></h4>
<p><strong>Logic - Minimizing Variation:</strong></p>
<ul class="simple">
<li><p>The core logic of K-means is to find a partition that minimizes the within-cluster variation.</p></li>
<li><p>The algorithm aims to partition the observations into K clusters such that the total within-cluster variation, summed over all K clusters, is minimized.</p></li>
<li><p>The objective being minimized is the sum of squared distances between each point and the centroid of its assigned cluster</p></li>
</ul>
<section id="inertia-within-cluster-sum-of-squares">
<h5>Inertia (within-cluster sum-of-squares)<a class="headerlink" href="#inertia-within-cluster-sum-of-squares" title="Link to this heading"></a></h5>
<ul class="simple">
<li><p>Inertia is a mathematical measure that quantifies how tightly grouped the data points are within their assigned clusters</p></li>
<li><p>Definition: Inertia is the total within-cluster sum of squares. It is a measure of how internally coherent the clusters are</p></li>
<li><p>K-means clustering uses an iterative optimization strategy to minimize inertia</p></li>
<li><p>Inertia always decreases or stays the same, never increases</p></li>
<li><p>The rate of decrease typically follows a curve that looks like this:</p>
<ul>
<li><p>Rapid decrease initially (adding the first few clusters)</p></li>
<li><p>Gradually diminishing returns as K continues to increase</p></li>
<li><p>Eventually, minimal improvements with additional clusters</p></li>
</ul>
</li>
</ul>
<p><strong>Why This Happens?</strong></p>
<ul class="simple">
<li><p>With more clusters, each data point can be assigned to a centroid that’s closer to it</p></li>
<li><p>When K=1: Maximum inertia (all points compared to global mean)</p></li>
<li><p>When K=n (number of data points): Zero inertia (each point is its own cluster)</p></li>
<li><p>The first few clusters capture the major structure in the data, while additional clusters only capture finer details (<em>Diminishing returns</em>)</p></li>
</ul>
<section id="the-elbow-method">
<h6>The Elbow Method<a class="headerlink" href="#the-elbow-method" title="Link to this heading"></a></h6>
<p>This behavior forms the basis of the popular “elbow method” for determining the optimal number of clusters:</p>
<ol class="arabic simple">
<li><p>Plot inertia against K (for K=1,2,3…)</p></li>
<li><p>Look for the “elbow point” where the curve bends sharply</p></li>
<li><p>This point represents where adding more clusters stops providing significant reduction in inertia</p></li>
</ol>
<p><strong>Important Considerations:</strong></p>
<ol class="arabic simple">
<li><p>Inertia will always decrease as K increases, even if you’re adding meaningless clusters</p></li>
<li><p>This is why we look for the elbow point rather than simply minimizing inertia</p></li>
</ol>
</section>
</section>
<section id="silhouette-score">
<h5>Silhouette Score<a class="headerlink" href="#silhouette-score" title="Link to this heading"></a></h5>
<ul class="simple">
<li><p>Evaluating clustering quality using inertia only raises some limitations</p>
<ul>
<li><p>It measures how similar each point is to its own cluster (cohesion)</p></li>
<li><p>but do not evaluate how different it is from other clusters (separation)</p></li>
</ul>
</li>
<li><p>Silhouette Score is a measure of how similar an object is to its own cluster compared to other clusters</p></li>
<li><p>Measures how similar a data point is to its own cluster (cohesion) compared to other clusters (separation)</p></li>
<li><p>While Inertia is the objective function that the K-means algorithm directly tries to minimize during its iterative process, the Silhouette Score is a measure used to evaluate the quality of the clustering result after the algorithm has finished. It is not part of the K-means algorithm’s iterative assignment and update steps.</p></li>
</ul>
<p><strong>Is each data point placed in the right cluster?</strong></p>
<ul class="simple">
<li><p>How close a point is to other points in its assigned cluster (inertia)</p></li>
<li><p>How close that same point is to points in the nearest neighboring cluster (Silhouette Score)</p></li>
</ul>
</section>
<section id="interpretation-of-silhouette-score">
<h5>Interpretation of Silhouette Score<a class="headerlink" href="#interpretation-of-silhouette-score" title="Link to this heading"></a></h5>
<ul class="simple">
<li><p>The silhouette score ranges from -1 to 1:</p>
<ul>
<li><p>Close to +1: The point is well matched to its own cluster and far from neighboring clusters</p></li>
<li><p>Close to 0: The point lies near the boundary between two clusters</p></li>
<li><p>Close to -1: The point might be assigned to the wrong cluster</p></li>
</ul>
</li>
<li><p>The overall silhouette score of a cluster is simply the average of all individual silhouette scores.</p></li>
</ul>
<section id="finding-optimal-k-using-silhouette">
<h6>Finding Optimal K Using Silhouette<a class="headerlink" href="#finding-optimal-k-using-silhouette" title="Link to this heading"></a></h6>
<p>Unlike inertia which always decreases as K increases, the silhouette score typically:</p>
<ul class="simple">
<li><p>Increases as K approaches the natural number of clusters</p></li>
<li><p>Reaches a maximum at or near the optimal K</p></li>
<li><p>Decreases as K becomes too large</p></li>
<li><p>This makes it particularly useful for determining the optimal number of clusters - you simply choose the K value that maximizes the average silhouette score.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1. Determine optimal number of clusters using the Elbow method</span>

<span class="n">inertia</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">silhouette_scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">k_range</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>  <span class="c1"># Testing from 2 to 10 clusters</span>

<span class="c1"># Exclude the Patient ID column for clustering</span>
<span class="n">pca_data</span> <span class="o">=</span> <span class="n">optimal_pca_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Patient ID&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">k_range</span><span class="p">:</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">pca_data</span><span class="p">)</span>
    <span class="n">inertia</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kmeans</span><span class="o">.</span><span class="n">inertia_</span><span class="p">)</span>
    
    <span class="c1"># Calculate silhouette score (only valid for k &gt;= 2)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>
    <span class="n">silhouette_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">pca_data</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Silhouette score for </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2"> clusters: </span><span class="si">{</span><span class="n">silhouette_scores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Silhouette score for 2 clusters: 0.315860568817066
Silhouette score for 3 clusters: 0.23399486593926483
Silhouette score for 4 clusters: 0.1923227376052971
Silhouette score for 5 clusters: 0.21280378841022102
Silhouette score for 6 clusters: 0.2215781206218201
Silhouette score for 7 clusters: 0.18825389524527888
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Silhouette score for 8 clusters: 0.16503544411475235
Silhouette score for 9 clusters: 0.13979820154212966
Silhouette score for 10 clusters: 0.13772690406314397
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot the Elbow curve</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k_range</span><span class="p">,</span> <span class="n">inertia</span><span class="p">,</span> <span class="s1">&#39;o-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of clusters (k)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Inertia&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Elbow Method for Optimal k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Plot silhouette scores</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k_range</span><span class="p">,</span> <span class="n">silhouette_scores</span><span class="p">,</span> <span class="s1">&#39;o-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of clusters (k)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Silhouette Score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Silhouette Scores for Different k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/2d3fa3dc2d2d4eade73a96b9f6a7b0c94eb5fc17c7af6d709ad9d4b51afa5292.png" src="_images/2d3fa3dc2d2d4eade73a96b9f6a7b0c94eb5fc17c7af6d709ad9d4b51afa5292.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 2. Apply K-means with the optimal k</span>
<span class="n">optimal_k</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># optimal k from the plots</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">optimal_k</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Fit K-means with the optimal number of clusters</span>
<span class="n">clusters</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">pca_data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of clusters: </span><span class="si">{</span><span class="n">optimal_k</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cluster centers:</span><span class="se">\n</span><span class="si">{</span><span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cluster labels for each patient sample: </span><span class="si">{</span><span class="n">clusters</span><span class="o">.</span><span class="n">labels_</span><span class="si">}</span><span class="s2">, shape: </span><span class="si">{</span><span class="n">clusters</span><span class="o">.</span><span class="n">labels_</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of clusters: 3
Cluster centers:
[[ 2.42255496  1.31481132  0.22658619  0.31864774  0.11053081 -0.05490954
  -0.12686288 -0.10959923]
 [-1.34671408 -3.70301852 -0.57098639 -0.42079775 -0.54593247 -0.09185375
   0.23802588  0.04913763]
 [-8.97044194  2.06631993  0.19937064 -0.61137725  0.72118837  0.48887309
   0.0789207   0.43334165]]
Cluster labels for each patient sample: [0 1 0 2 0 1 0 0 0 0 0 1 0 0 0 2 0 1 0 1 0 2 1 1 0], shape: (25,)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 3. Add cluster labels to the dataframe</span>
<span class="n">optimal_pca_df</span><span class="p">[</span><span class="s1">&#39;Cluster&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clusters</span><span class="o">.</span><span class="n">labels_</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;First 5 rows of PCA DataFrame with cluster labels:&quot;</span><span class="p">)</span>
<span class="n">optimal_pca_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>First 5 rows of PCA DataFrame with cluster labels:
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PC1</th>
      <th>PC2</th>
      <th>PC3</th>
      <th>PC4</th>
      <th>PC5</th>
      <th>PC6</th>
      <th>PC7</th>
      <th>PC8</th>
      <th>Patient ID</th>
      <th>Cluster</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3.647907</td>
      <td>3.785523</td>
      <td>1.336597</td>
      <td>-0.208642</td>
      <td>-2.173467</td>
      <td>-0.159574</td>
      <td>-0.201224</td>
      <td>-0.175144</td>
      <td>TCGA-D8-A1JU</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.321251</td>
      <td>-5.989832</td>
      <td>4.189945</td>
      <td>-0.206970</td>
      <td>0.171948</td>
      <td>0.960831</td>
      <td>-0.520194</td>
      <td>1.106246</td>
      <td>TCGA-AC-A3QQ</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3.832310</td>
      <td>1.285090</td>
      <td>-0.477499</td>
      <td>-2.193931</td>
      <td>3.982175</td>
      <td>-0.967499</td>
      <td>-0.351455</td>
      <td>0.389307</td>
      <td>TCGA-C8-A12Q</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-5.633592</td>
      <td>3.690983</td>
      <td>-3.478281</td>
      <td>-0.803440</td>
      <td>0.446135</td>
      <td>0.610747</td>
      <td>-2.052404</td>
      <td>0.316239</td>
      <td>TCGA-AR-A1AY</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.174023</td>
      <td>1.517975</td>
      <td>0.166070</td>
      <td>2.912341</td>
      <td>0.421168</td>
      <td>-0.887175</td>
      <td>-1.127990</td>
      <td>-1.452414</td>
      <td>TCGA-A8-A0A2</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Basic cluster analysis</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cluster distribution:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">optimal_pca_df</span><span class="p">[</span><span class="s1">&#39;Cluster&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cluster distribution:
Cluster
0    15
1     7
2     3
Name: count, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">optimal_pca_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s2">&quot;Cluster&quot;</span><span class="p">,</span> <span class="s2">&quot;Patient ID&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;Counts&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;Counts&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Cluster</th>
      <th>Patient ID</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>TCGA-A8-A07G</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>TCGA-A8-A08Z</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>TCGA-A8-A0A2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>TCGA-AN-A0XW</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>TCGA-BH-A0AU</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0</td>
      <td>TCGA-BH-A0DV</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0</td>
      <td>TCGA-BH-A18K</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0</td>
      <td>TCGA-BH-A1F8</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0</td>
      <td>TCGA-C8-A12Q</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0</td>
      <td>TCGA-D8-A1J8</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0</td>
      <td>TCGA-D8-A1JN</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0</td>
      <td>TCGA-D8-A1JU</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0</td>
      <td>TCGA-EW-A1P1</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0</td>
      <td>TCGA-EW-A3E8</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0</td>
      <td>TCGA-LD-A7W6</td>
    </tr>
    <tr>
      <th>15</th>
      <td>1</td>
      <td>TCGA-A2-A0CX</td>
    </tr>
    <tr>
      <th>16</th>
      <td>1</td>
      <td>TCGA-A2-A0CY</td>
    </tr>
    <tr>
      <th>17</th>
      <td>1</td>
      <td>TCGA-AC-A3QQ</td>
    </tr>
    <tr>
      <th>18</th>
      <td>1</td>
      <td>TCGA-AO-A12F</td>
    </tr>
    <tr>
      <th>19</th>
      <td>1</td>
      <td>TCGA-AR-A1AH</td>
    </tr>
    <tr>
      <th>20</th>
      <td>1</td>
      <td>TCGA-E2-A10C</td>
    </tr>
    <tr>
      <th>21</th>
      <td>1</td>
      <td>TCGA-E2-A1LL</td>
    </tr>
    <tr>
      <th>22</th>
      <td>2</td>
      <td>TCGA-AR-A1AY</td>
    </tr>
    <tr>
      <th>23</th>
      <td>2</td>
      <td>TCGA-EW-A3U0</td>
    </tr>
    <tr>
      <th>24</th>
      <td>2</td>
      <td>TCGA-OL-A5D7</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate mean of each feature for each cluster</span>
<span class="n">cluster_means</span> <span class="o">=</span> <span class="n">optimal_pca_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s2">&quot;Patient ID&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;Cluster&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Cluster centers in PCA space:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cluster_means</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cluster centers in PCA space:
              PC1       PC2       PC3       PC4       PC5       PC6       PC7  \
Cluster                                                                         
0        2.422555  1.314811  0.226586  0.318648  0.110531 -0.054910 -0.126863   
1       -1.346714 -3.703019 -0.570986 -0.420798 -0.545932 -0.091854  0.238026   
2       -8.970442  2.066320  0.199371 -0.611377  0.721188  0.488873  0.078921   

              PC8  
Cluster            
0       -0.109599  
1        0.049138  
2        0.433342  
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 4. Visualize clusters using first two principal components</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">optimal_k</span><span class="p">):</span>
    <span class="n">cluster_points</span> <span class="o">=</span> <span class="n">optimal_pca_df</span><span class="p">[</span><span class="n">optimal_pca_df</span><span class="p">[</span><span class="s1">&#39;Cluster&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">cluster</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="n">cluster_points</span><span class="p">[</span><span class="s1">&#39;PC1&#39;</span><span class="p">],</span> 
        <span class="n">cluster_points</span><span class="p">[</span><span class="s1">&#39;PC2&#39;</span><span class="p">],</span>
        <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Cluster </span><span class="si">{</span><span class="n">cluster</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
        <span class="n">s</span><span class="o">=</span><span class="mi">80</span>
    <span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">cluster_points</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;PC1&#39;</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;PC2&#39;</span><span class="p">],</span> <span class="nb">str</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;Patient ID&#39;</span><span class="p">]),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

<span class="n">centers</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">centers</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> 
    <span class="n">centers</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> 
    <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> 
    <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> 
    <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> 
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Centroids&#39;</span>
<span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Cluster&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">title_fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Principal Component 1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Principal Component 2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Clusters Visualized on First Two Principal Components&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/2fba9c971a763b91dd2cb5559818d5107f42c3c2011f4e3052bf3fbe001a29b1.png" src="_images/2fba9c971a763b91dd2cb5559818d5107f42c3c2011f4e3052bf3fbe001a29b1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">optimal_pca_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PC1</th>
      <th>PC2</th>
      <th>PC3</th>
      <th>PC4</th>
      <th>PC5</th>
      <th>PC6</th>
      <th>PC7</th>
      <th>PC8</th>
      <th>Patient ID</th>
      <th>Cluster</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3.647907</td>
      <td>3.785523</td>
      <td>1.336597</td>
      <td>-0.208642</td>
      <td>-2.173467</td>
      <td>-0.159574</td>
      <td>-0.201224</td>
      <td>-0.175144</td>
      <td>TCGA-D8-A1JU</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.321251</td>
      <td>-5.989832</td>
      <td>4.189945</td>
      <td>-0.206970</td>
      <td>0.171948</td>
      <td>0.960831</td>
      <td>-0.520194</td>
      <td>1.106246</td>
      <td>TCGA-AC-A3QQ</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3.832310</td>
      <td>1.285090</td>
      <td>-0.477499</td>
      <td>-2.193931</td>
      <td>3.982175</td>
      <td>-0.967499</td>
      <td>-0.351455</td>
      <td>0.389307</td>
      <td>TCGA-C8-A12Q</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-5.633592</td>
      <td>3.690983</td>
      <td>-3.478281</td>
      <td>-0.803440</td>
      <td>0.446135</td>
      <td>0.610747</td>
      <td>-2.052404</td>
      <td>0.316239</td>
      <td>TCGA-AR-A1AY</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.174023</td>
      <td>1.517975</td>
      <td>0.166070</td>
      <td>2.912341</td>
      <td>0.421168</td>
      <td>-0.887175</td>
      <td>-1.127990</td>
      <td>-1.452414</td>
      <td>TCGA-A8-A0A2</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">features_to_analyze</span> <span class="o">=</span> <span class="n">optimal_pca_df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;Patient ID&#39;</span><span class="p">,</span> <span class="s1">&#39;Cluster&#39;</span><span class="p">])</span>
<span class="n">features_to_analyze</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;PC1&#39;, &#39;PC2&#39;, &#39;PC3&#39;, &#39;PC4&#39;, &#39;PC5&#39;, &#39;PC6&#39;, &#39;PC7&#39;, &#39;PC8&#39;], dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cluster_stats</span> <span class="o">=</span> <span class="n">optimal_pca_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;Cluster&#39;</span><span class="p">)[[</span><span class="s1">&#39;PC1&#39;</span><span class="p">,</span> <span class="s1">&#39;PC2&#39;</span><span class="p">,</span> <span class="s1">&#39;PC3&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">agg</span><span class="p">([</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="s1">&#39;std&#39;</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Descriptive Statistics for Each Cluster:&quot;</span><span class="p">)</span>
<span class="n">cluster_stats</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Descriptive Statistics for Each Cluster:
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="4" halign="left">PC1</th>
      <th colspan="4" halign="left">PC2</th>
      <th colspan="4" halign="left">PC3</th>
    </tr>
    <tr>
      <th></th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>max</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>max</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>max</th>
    </tr>
    <tr>
      <th>Cluster</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2.422555</td>
      <td>2.669334</td>
      <td>-1.042854</td>
      <td>6.184113</td>
      <td>1.314811</td>
      <td>1.812225</td>
      <td>-2.445795</td>
      <td>3.785523</td>
      <td>0.226586</td>
      <td>1.816583</td>
      <td>-3.150876</td>
      <td>4.187933</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.346714</td>
      <td>2.241274</td>
      <td>-5.334288</td>
      <td>0.359772</td>
      <td>-3.703019</td>
      <td>2.310308</td>
      <td>-7.265999</td>
      <td>-1.123308</td>
      <td>-0.570986</td>
      <td>3.293631</td>
      <td>-5.974913</td>
      <td>4.189945</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-8.970442</td>
      <td>3.365790</td>
      <td>-12.364445</td>
      <td>-5.633592</td>
      <td>2.066320</td>
      <td>2.685685</td>
      <td>-1.033643</td>
      <td>3.690983</td>
      <td>0.199371</td>
      <td>3.280955</td>
      <td>-3.478281</td>
      <td>2.826122</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p><strong>Overall Observations:</strong></p>
<ul class="simple">
<li><p>PC1 and PC2 seem to be more effective at differentiating the clusters based on their mean values than PC3</p></li>
</ul>
<p><strong>PC1 (Captures the most variance in your original data):</strong></p>
<ul class="simple">
<li><p>Separation (mean):</p>
<ul>
<li><p>PC1 strongly differentiates all three clusters based on their mean values</p></li>
<li><p>Cluster 0 has a positive mean (2.423), indicating samples here score high on the trait(s) PC1 represents</p></li>
<li><p>Cluster 1 has a moderately negative mean (-1.347)</p></li>
<li><p>Cluster 2 has a very strongly negative mean (-8.970), indicating samples in this cluster score very low on trait(s) PC1 represents</p></li>
</ul>
</li>
<li><p>Spread (std):</p>
<ul>
<li><p>Cluster 0 has an intermediate spread (std = 2.670)</p></li>
<li><p>Cluster 1 is the most compact (homogeneous) along PC1 (std = 2.241) relative to Cluster 0 and 2</p></li>
<li><p>Cluster 2 is the most spread out (heterogeneous) along PC1 (std = 3.366)</p></li>
</ul>
</li>
</ul>
<p><strong>PC2 (Captures the second most variance):</strong></p>
<ul class="simple">
<li><p>Separation (mean):</p>
<ul>
<li><p>PC2 is also effective at differentiating the clusters, particularly separating Cluster 1 from Clusters 0 and 2.</p></li>
<li><p>Cluster 1 has a strongly negative mean (-3.703).</p></li>
<li><p>Cluster 0 (1.315) and Cluster 2 (2.066) both have positive mean PC2 scores, with Cluster 2’s mean being slightly higher.</p></li>
</ul>
</li>
<li><p>Spread (std):</p>
<ul>
<li><p>Cluster 0 is the most compact along PC2 (std = 1.812).</p></li>
<li><p>Cluster 1 has an intermediate spread (std = 2.310).</p></li>
<li><p>Cluster 2 is the most spread out along PC2 (std = 2.686).</p></li>
</ul>
</li>
</ul>
<p><strong>Cluster 0:</strong></p>
<ul class="simple">
<li><p>Patients in this cluster strongly exhibit the characteristics represented by the positive direction of PC1 and moderately by the positive direction of PC2</p></li>
<li><p>They are quite consistent in their PC2 (and PC3) values</p></li>
</ul>
<p><strong>Cluster 1:</strong></p>
<ul class="simple">
<li><p>Patients are strongly characterized by the negative direction of PC2 and moderately by the negative direction of PC1</p></li>
<li><p>They are quite consistent in their PC1 values (relatively)</p></li>
</ul>
<p><strong>Cluster 2:</strong></p>
<ul class="simple">
<li><p>Patients are strongly characterized by the negative direction of PC1 and strongly by the strongly positive direction of PC2</p></li>
<li><p>They are quite spread-out in their PC1 and PC2 values</p></li>
</ul>
</section>
</section>
</section>
</section>
<span id="document-2.Notebook_Logistic_regression"></span><section id="classification">
<h3>Classification<a class="headerlink" href="#classification" title="Link to this heading"></a></h3>
<section id="logistic-regression">
<h4>Logistic regression<a class="headerlink" href="#logistic-regression" title="Link to this heading"></a></h4>
</section>
<section id="dataset">
<h4>Dataset<a class="headerlink" href="#dataset" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>Features:</p>
<ul>
<li><p>Most frequently mutated 20 genes and</p></li>
<li><p>2 clinical features: gender and age at diagnosis</p></li>
</ul>
</li>
<li><p>Target variable (i.e, dependant variable or response variables): Glioma grade class information</p>
<ul>
<li><p>0 = “LGG”</p></li>
<li><p>1 = “GBM”</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import necessary libraries</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">confusion_matrix</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download the test dataset</span>
<span class="o">!</span><span class="w"> </span>curl<span class="w"> </span>https://naicno.github.io/BioNT_Module2_handson/_downloads/041231c291c25343976f8b70db54f238/TCGA_InfoWithGrade_scaled.csv<span class="w"> </span>-o<span class="w"> </span>TCGA_InfoWithGrade_scaled.csv
<span class="o">!</span><span class="w"> </span>ls<span class="w"> </span>-lh<span class="w"> </span>TCGA_InfoWithGrade_scaled.csv
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 29 53487   29 15640    0     0   100k      0 --:--:-- --:--:-- --:--:--  100k
100 53487  100 53487    0     0   342k      0 --:--:-- --:--:-- --:--:--  341k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-rw-r--r-- 1 runner docker 53K Jun 10 13:52 TCGA_InfoWithGrade_scaled.csv
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a DataFrame from the CSV file</span>
<span class="n">gliomas</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;TCGA_InfoWithGrade_scaled.csv&#39;</span><span class="p">)</span>
<span class="n">gliomas</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 839 entries, 0 to 838
Data columns (total 23 columns):
 #   Column            Non-Null Count  Dtype  
---  ------            --------------  -----  
 0   Grade             839 non-null    int64  
 1   Gender            839 non-null    int64  
 2   Age_at_diagnosis  839 non-null    float64
 3   IDH1              839 non-null    int64  
 4   TP53              839 non-null    int64  
 5   ATRX              839 non-null    int64  
 6   PTEN              839 non-null    int64  
 7   EGFR              839 non-null    int64  
 8   CIC               839 non-null    int64  
 9   MUC16             839 non-null    int64  
 10  PIK3CA            839 non-null    int64  
 11  NF1               839 non-null    int64  
 12  PIK3R1            839 non-null    int64  
 13  FUBP1             839 non-null    int64  
 14  RB1               839 non-null    int64  
 15  NOTCH1            839 non-null    int64  
 16  BCOR              839 non-null    int64  
 17  CSMD3             839 non-null    int64  
 18  SMARCA4           839 non-null    int64  
 19  GRIN2A            839 non-null    int64  
 20  IDH2              839 non-null    int64  
 21  FAT4              839 non-null    int64  
 22  PDGFRA            839 non-null    int64  
dtypes: float64(1), int64(22)
memory usage: 150.9 KB
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Inspect the first few rows of the DataFrame</span>
<span class="n">gliomas</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Grade</th>
      <th>Gender</th>
      <th>Age_at_diagnosis</th>
      <th>IDH1</th>
      <th>TP53</th>
      <th>ATRX</th>
      <th>PTEN</th>
      <th>EGFR</th>
      <th>CIC</th>
      <th>MUC16</th>
      <th>...</th>
      <th>FUBP1</th>
      <th>RB1</th>
      <th>NOTCH1</th>
      <th>BCOR</th>
      <th>CSMD3</th>
      <th>SMARCA4</th>
      <th>GRIN2A</th>
      <th>IDH2</th>
      <th>FAT4</th>
      <th>PDGFRA</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0.023233</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>-0.778400</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>-1.004616</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>1</td>
      <td>-1.156913</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>-1.237841</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 23 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Count the number of samples in each grade (Count observations in target variable)</span>
<span class="n">gliomas</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;Grade&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Grade
0    487
1    352
dtype: int64
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualize-data-distributions">
<h4>Visualize data distributions<a class="headerlink" href="#visualize-data-distributions" title="Link to this heading"></a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot the distribution of data in all columns</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="c1"># Iterate over each column and plot the distribution</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">column</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">gliomas</span><span class="o">.</span><span class="n">columns</span><span class="p">):</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">gliomas</span><span class="p">[</span><span class="n">column</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ce04b5059988403fca974eec342e0635261431d4d174224a3c7361b223b4444a.png" src="_images/ce04b5059988403fca974eec342e0635261431d4d174224a3c7361b223b4444a.png" />
</div>
</div>
<ul class="simple">
<li><p>Scaling binary features would destroy their natural interpretability - coefficients would no longer represent the log-odds change from “absent” (0) to “present” (1)</p></li>
</ul>
<p>Binary features encoded as 0/1 have a natural, meaningful interpretation where the coefficient represents the change in log-odds when the feature goes from absent (0) to present (1). If you scale these features (e.g., to have mean 0 and standard deviation 1), a “0” might become -0.85 and a “1” might become +1.23, making the coefficient interpretation much less intuitive. You’d lose the direct interpretation of “how much does the presence of this feature change the odds?” Additionally, binary features are already on a bounded, comparable scale (0 to 1), unlike continuous features that might range from 0 to 100,000, so scaling for convergence purposes is typically unnecessary.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gliomas</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Grade</th>
      <td>839.0</td>
      <td>4.195471e-01</td>
      <td>0.493779</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>Gender</th>
      <td>839.0</td>
      <td>4.183552e-01</td>
      <td>0.493583</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>Age_at_diagnosis</th>
      <td>839.0</td>
      <td>1.355028e-16</td>
      <td>1.000596</td>
      <td>-2.326863</td>
      <td>-0.820775</td>
      <td>0.039163</td>
      <td>0.756044</td>
      <td>2.444061</td>
    </tr>
    <tr>
      <th>IDH1</th>
      <td>839.0</td>
      <td>4.815256e-01</td>
      <td>0.499957</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>TP53</th>
      <td>839.0</td>
      <td>4.147795e-01</td>
      <td>0.492978</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>ATRX</th>
      <td>839.0</td>
      <td>2.586412e-01</td>
      <td>0.438149</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>PTEN</th>
      <td>839.0</td>
      <td>1.680572e-01</td>
      <td>0.374140</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>EGFR</th>
      <td>839.0</td>
      <td>1.334923e-01</td>
      <td>0.340309</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>CIC</th>
      <td>839.0</td>
      <td>1.323004e-01</td>
      <td>0.339019</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>MUC16</th>
      <td>839.0</td>
      <td>1.168057e-01</td>
      <td>0.321380</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>PIK3CA</th>
      <td>839.0</td>
      <td>8.700834e-02</td>
      <td>0.282015</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>NF1</th>
      <td>839.0</td>
      <td>7.985697e-02</td>
      <td>0.271233</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>PIK3R1</th>
      <td>839.0</td>
      <td>6.436234e-02</td>
      <td>0.245544</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>FUBP1</th>
      <td>839.0</td>
      <td>5.363528e-02</td>
      <td>0.225431</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>RB1</th>
      <td>839.0</td>
      <td>4.767580e-02</td>
      <td>0.213206</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>NOTCH1</th>
      <td>839.0</td>
      <td>4.529201e-02</td>
      <td>0.208068</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>BCOR</th>
      <td>839.0</td>
      <td>3.456496e-02</td>
      <td>0.182784</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>CSMD3</th>
      <td>839.0</td>
      <td>3.218117e-02</td>
      <td>0.176586</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>SMARCA4</th>
      <td>839.0</td>
      <td>3.218117e-02</td>
      <td>0.176586</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>GRIN2A</th>
      <td>839.0</td>
      <td>3.218117e-02</td>
      <td>0.176586</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>IDH2</th>
      <td>839.0</td>
      <td>2.741359e-02</td>
      <td>0.163383</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>FAT4</th>
      <td>839.0</td>
      <td>2.741359e-02</td>
      <td>0.163383</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>PDGFRA</th>
      <td>839.0</td>
      <td>2.622169e-02</td>
      <td>0.159889</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="split-original-dataset">
<h4>Split original dataset<a class="headerlink" href="#split-original-dataset" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">train_test_split</span></code> function from scikit-learn split a dataset into random train and test subsets</p></li>
<li><p>Default behaviour,</p>
<ul>
<li><p>Shuffles the data before splitting</p></li>
<li><p>Does not inherently preserve the distribution of the original dataset when splitting to train and test subsets</p></li>
<li><p>The distribution in train and test subsets the depends on the randomness of the split</p></li>
</ul>
</li>
<li><p>Stratified sampling in <code class="docutils literal notranslate"><span class="pre">train_test_split</span></code> function ensures that the distribution of classes (e.g., LGG and GBM distribution) in original dataset is the same in split-datasets</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">gliomas</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;Grade&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">gliomas</span><span class="p">[</span><span class="s2">&quot;Grade&quot;</span><span class="p">],</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
    <span class="n">stratify</span><span class="o">=</span><span class="n">gliomas</span><span class="p">[</span><span class="s2">&quot;Grade&quot;</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X_train&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X_test&quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;y_train&quot;</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;y_test&quot;</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>X_train (587, 22)
X_test (252, 22)
y_train (587,)
y_test (252,)
</pre></div>
</div>
</div>
</div>
</section>
<section id="train-a-logistic-regression-model">
<h4>Train a logistic regression model<a class="headerlink" href="#train-a-logistic-regression-model" title="Link to this heading"></a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialize the Logistic Regression model</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="c1"># Fit the model</span>
<span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: start;
  justify-content: space-between;
  gap: 0.5em;
}

#sk-container-id-1 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  display: none;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  display: block;
  width: 100%;
  overflow: visible;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}

.estimator-table summary {
    padding: .5rem;
    font-family: monospace;
    cursor: pointer;
}

.estimator-table details[open] {
    padding-left: 0.1rem;
    padding-right: 0.1rem;
    padding-bottom: 0.3rem;
}

.estimator-table .parameters-table {
    margin-left: auto !important;
    margin-right: auto !important;
}

.estimator-table .parameters-table tr:nth-child(odd) {
    background-color: #fff;
}

.estimator-table .parameters-table tr:nth-child(even) {
    background-color: #f6f6f6;
}

.estimator-table .parameters-table tr:hover {
    background-color: #e0e0e0;
}

.estimator-table table td {
    border: 1px solid rgba(106, 105, 104, 0.232);
}

.user-set td {
    color:rgb(255, 94, 0);
    text-align: left;
}

.user-set td.value pre {
    color:rgb(255, 94, 0) !important;
    background-color: transparent !important;
}

.default td {
    color: black;
    text-align: left;
}

.user-set td i,
.default td i {
    color: black;
}

.copy-paste-icon {
    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);
    background-repeat: no-repeat;
    background-size: 14px 14px;
    background-position: 0;
    display: inline-block;
    width: 14px;
    height: 14px;
    cursor: pointer;
}
</style><body><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>LogisticRegression</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html">?<span>Documentation for LogisticRegression</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></div></label><div class="sk-toggleable__content fitted" data-param-prefix="">
        <div class="estimator-table">
            <details>
                <summary>Parameters</summary>
                <table class="parameters-table">
                  <tbody>
                    
        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('penalty',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">penalty&nbsp;</td>
            <td class="value">&#x27;l2&#x27;</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('dual',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">dual&nbsp;</td>
            <td class="value">False</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('tol',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">tol&nbsp;</td>
            <td class="value">0.0001</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('C',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">C&nbsp;</td>
            <td class="value">1.0</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('fit_intercept',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">fit_intercept&nbsp;</td>
            <td class="value">True</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('intercept_scaling',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">intercept_scaling&nbsp;</td>
            <td class="value">1</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('class_weight',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">class_weight&nbsp;</td>
            <td class="value">None</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('random_state',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">random_state&nbsp;</td>
            <td class="value">None</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('solver',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">solver&nbsp;</td>
            <td class="value">&#x27;lbfgs&#x27;</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('max_iter',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">max_iter&nbsp;</td>
            <td class="value">100</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('multi_class',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">multi_class&nbsp;</td>
            <td class="value">&#x27;deprecated&#x27;</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('verbose',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">verbose&nbsp;</td>
            <td class="value">0</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('warm_start',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">warm_start&nbsp;</td>
            <td class="value">False</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('n_jobs',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">n_jobs&nbsp;</td>
            <td class="value">None</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('l1_ratio',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">l1_ratio&nbsp;</td>
            <td class="value">None</td>
        </tr>
    
                  </tbody>
                </table>
            </details>
        </div>
    </div></div></div></div></div><script>function copyToClipboard(text, element) {
    // Get the parameter prefix from the closest toggleable content
    const toggleableContent = element.closest('.sk-toggleable__content');
    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';
    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;

    const originalStyle = element.style;
    const computedStyle = window.getComputedStyle(element);
    const originalWidth = computedStyle.width;
    const originalHTML = element.innerHTML.replace('Copied!', '');

    navigator.clipboard.writeText(fullParamName)
        .then(() => {
            element.style.width = originalWidth;
            element.style.color = 'green';
            element.innerHTML = "Copied!";

            setTimeout(() => {
                element.innerHTML = originalHTML;
                element.style = originalStyle;
            }, 2000);
        })
        .catch(err => {
            console.error('Failed to copy:', err);
            element.style.color = 'red';
            element.innerHTML = "Failed!";
            setTimeout(() => {
                element.innerHTML = originalHTML;
                element.style = originalStyle;
            }, 2000);
        });
    return false;
}

document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {
    const toggleableContent = element.closest('.sk-toggleable__content');
    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';
    const paramName = element.parentElement.nextElementSibling.textContent.trim();
    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;

    element.setAttribute('title', fullParamName);
});
</script></body></div></div>
</div>
<section id="logistic-regression-model">
<h5>Logistic regression model<a class="headerlink" href="#logistic-regression-model" title="Link to this heading"></a></h5>
<ul class="simple">
<li><p>Think of logistic regression as having three distinct layers that work together</p>
<ul>
<li><p>The Raw Model (Linear Predictor)</p></li>
<li><p>The Model Output (Probability)</p></li>
<li><p>The Decision Boundary</p></li>
</ul>
</li>
</ul>
<section id="the-raw-model-linear-predictor">
<h6>The Raw Model (Linear Predictor)<a class="headerlink" href="#the-raw-model-linear-predictor" title="Link to this heading"></a></h6>
<p>$z = β0 + β1x1 + β2x2 + β3*x3$</p>
<p>Where:</p>
<ul class="simple">
<li><p>$z$ is the raw model output</p>
<ul>
<li><p>Unbounded score that could be any real number from -∞ to +∞</p></li>
</ul>
</li>
<li><p>$β0$ is the intercept or bias term</p></li>
<li><p>$β1, β2, β3$ are the coefficients or weights associated with features $x1, x2, x3$ respectively</p></li>
<li><p>$x1, x2, x3$ are the values of the features</p></li>
</ul>
<p>Additional notes:</p>
<ul class="simple">
<li><p>Raw model output of logistic regression is equal to the log-odds</p></li>
<li><p>Why does this matter?</p>
<ul>
<li><p>Improves interpretability: A one-unit increase in a feature increases the log-odds by the corresponding coefficient</p></li>
</ul>
</li>
<li><p>Homework: Explore mathematics relationship between “raw model output” and “log odds”</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot Raw model output histogram </span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X_train</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of Raw model output&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Raw model output&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Count&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;Count&#39;)
</pre></div>
</div>
<img alt="_images/bb16e84c4d4086c5548ca68a18d80c116fa945f41151a273deda17cbce432fa8.png" src="_images/bb16e84c4d4086c5548ca68a18d80c116fa945f41151a273deda17cbce432fa8.png" />
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">decision_function()</span></code> returns the raw linear combination: <code class="docutils literal notranslate"><span class="pre">β₀</span> <span class="pre">+</span> <span class="pre">β₁x₁</span> <span class="pre">+</span> <span class="pre">β₂x₂</span> <span class="pre">+</span> <span class="pre">...</span> <span class="pre">+</span> <span class="pre">βₙxₙ</span></code>. Since this is just a weighted sum of features, it has no mathematical bounds and can theoretically range from -∞ to +∞. The sigmoid function is then applied to transform these logits into probabilities between 0 and 1.</p>
</section>
<section id="the-model-output-probability">
<h6>The Model Output (Probability)<a class="headerlink" href="#the-model-output-probability" title="Link to this heading"></a></h6>
<ul class="simple">
<li><p>Raw score then gets transformed through the sigmoid function</p></li>
<li><p>Sigmoid function: Converts our unbounded raw score into a probability between 0 and 1</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Access prediction probabilities</span>
<span class="n">probabilities</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Probabilities for first 5 test samples:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">probabilities</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Note: Column 0 = P(class=0), Column 1 = P(class=1)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Probabilities for first 5 test samples:
[[0.2877258  0.7122742 ]
 [0.30536037 0.69463963]
 [0.86905511 0.13094489]
 [0.24988542 0.75011458]
 [0.91616818 0.08383182]]

Note: Column 0 = P(class=0), Column 1 = P(class=1)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">predict_proba()</span></code> returns a two-column array where Column 0 = P(class=0) = P(LGG) and Column 1 = P(class=1) = P(GBM) for each test patient. These probabilities sum to 1.0 for each patient</p></li>
<li><p>In medical contexts, probability outputs are crucial because they provide confidence levels (e.g., “85% chance of GBM” vs “51% chance of GBM”) that help clinicians make more informed treatment decisions and determine when additional testing might be needed.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of Model Output (Probabilities)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Probability&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Count&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;Count&#39;)
</pre></div>
</div>
<img alt="_images/1549a4e7dae7ea6b9a784ae11eebd5bc9a1e108b4aa2535d23d9208929bd951d.png" src="_images/1549a4e7dae7ea6b9a784ae11eebd5bc9a1e108b4aa2535d23d9208929bd951d.png" />
</div>
</div>
<ul class="simple">
<li><p>If we’re looking at the probability of class 0:</p>
<ul>
<li><p>Probability near 0.0 = low chance of being class 0 = likely class 1</p></li>
<li><p>Probability near 1.0 = high chance of being class 0 = confident class 0 prediction</p></li>
</ul>
</li>
<li><p>A U-shaped probability distribution is actually desirable in logistic regression, indicating that the model can confidently distinguish between classes. Most predictions are either very likely class 0 (near 0.0) or very likely class 1 (near 1.0), with few ambiguous cases in between.</p></li>
<li><p>Looking at the histogram, there are noticeably more blue bars (class 0 predictions) near probability 0.0 than orange bars (class 1 predictions) near probability 1.0, indicating the model predicts more instances as belonging to class 0.</p></li>
<li><p>The model makes very confident predictions - most probabilities cluster at the extremes (0.0 and 1.0) with very few uncertain predictions in the middle ranges (0.3-0.7).</p></li>
</ul>
</section>
</section>
</section>
<section id="predict-the-glioma-type-of-the-new-dataset">
<h4>Predict the Glioma type of the new dataset<a class="headerlink" href="#predict-the-glioma-type-of-the-new-dataset" title="Link to this heading"></a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predict classes for the test set</span>
<span class="n">predicted_classes</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predicted classes for first 10 samples:&quot;</span><span class="p">,</span> <span class="n">predicted_classes</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted classes for first 10 samples: [1 1 0 1 0 1 1 0 1 0]
</pre></div>
</div>
</div>
</div>
</section>
<section id="examine-and-understand-the-importance-of-features-in-predicting-classes">
<h4>Examine and understand the importance of features in predicting classes<a class="headerlink" href="#examine-and-understand-the-importance-of-features-in-predicting-classes" title="Link to this heading"></a></h4>
<section id="coefficients-of-the-model">
<h5>Coefficients of the model<a class="headerlink" href="#coefficients-of-the-model" title="Link to this heading"></a></h5>
<ul class="simple">
<li><p>Magnitude of the coefficients indicates the relative importance of each feature on predicting positive class (in this case 1 - GBM)</p></li>
<li><p>Larger coefficients imply a stronger influence on the predicted probability</p></li>
<li><p>Interpretation of coefficients assumes that the features are independent of each other</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the list of features</span>
<span class="n">feature_list</span> <span class="o">=</span> <span class="n">gliomas</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of Features&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_list</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Features&quot;</span><span class="p">,</span> <span class="n">feature_list</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of Features 22
Features Index([&#39;Gender&#39;, &#39;Age_at_diagnosis&#39;, &#39;IDH1&#39;, &#39;TP53&#39;, &#39;ATRX&#39;, &#39;PTEN&#39;, &#39;EGFR&#39;,
       &#39;CIC&#39;, &#39;MUC16&#39;, &#39;PIK3CA&#39;, &#39;NF1&#39;, &#39;PIK3R1&#39;, &#39;FUBP1&#39;, &#39;RB1&#39;, &#39;NOTCH1&#39;,
       &#39;BCOR&#39;, &#39;CSMD3&#39;, &#39;SMARCA4&#39;, &#39;GRIN2A&#39;, &#39;IDH2&#39;, &#39;FAT4&#39;, &#39;PDGFRA&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a DataFrame of the coefficients and their corresponding features</span>
<span class="c1"># `.coef_.` attribute of the fitted LogisticRegression model (`lr`) contains the coefficients for each feature</span>
<span class="n">coefficients</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">feature_list</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Coefficient&#39;</span><span class="p">])</span>
<span class="c1"># Sort the coefficients</span>
<span class="n">coefficients</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;Coefficient&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Coefficient</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>GRIN2A</th>
      <td>1.055559</td>
    </tr>
    <tr>
      <th>PIK3R1</th>
      <td>0.947821</td>
    </tr>
    <tr>
      <th>TP53</th>
      <td>0.942698</td>
    </tr>
    <tr>
      <th>PTEN</th>
      <td>0.796895</td>
    </tr>
    <tr>
      <th>Age_at_diagnosis</th>
      <td>0.681210</td>
    </tr>
    <tr>
      <th>MUC16</th>
      <td>0.604221</td>
    </tr>
    <tr>
      <th>PDGFRA</th>
      <td>0.445061</td>
    </tr>
    <tr>
      <th>BCOR</th>
      <td>0.353871</td>
    </tr>
    <tr>
      <th>CSMD3</th>
      <td>0.273685</td>
    </tr>
    <tr>
      <th>RB1</th>
      <td>0.156207</td>
    </tr>
    <tr>
      <th>PIK3CA</th>
      <td>0.059562</td>
    </tr>
    <tr>
      <th>Gender</th>
      <td>0.033025</td>
    </tr>
    <tr>
      <th>FAT4</th>
      <td>-0.007310</td>
    </tr>
    <tr>
      <th>ATRX</th>
      <td>-0.192959</td>
    </tr>
    <tr>
      <th>FUBP1</th>
      <td>-0.410101</td>
    </tr>
    <tr>
      <th>SMARCA4</th>
      <td>-0.414551</td>
    </tr>
    <tr>
      <th>EGFR</th>
      <td>-0.538561</td>
    </tr>
    <tr>
      <th>CIC</th>
      <td>-0.780800</td>
    </tr>
    <tr>
      <th>NF1</th>
      <td>-0.836918</td>
    </tr>
    <tr>
      <th>NOTCH1</th>
      <td>-1.459809</td>
    </tr>
    <tr>
      <th>IDH2</th>
      <td>-1.733926</td>
    </tr>
    <tr>
      <th>IDH1</th>
      <td>-3.287939</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot coefficients for each feature</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Feature Importance&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="s1">&#39;index&#39;</span><span class="p">,</span> <span class="s1">&#39;Coefficient&#39;</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">coefficients</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;Coefficient&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;BarContainer object of 22 artists&gt;
</pre></div>
</div>
<img alt="_images/a6115ab47ce8c5c26bac3337b55170b21c215ca82c9b35e6b1a8d615add4f5c3.png" src="_images/a6115ab47ce8c5c26bac3337b55170b21c215ca82c9b35e6b1a8d615add4f5c3.png" />
</div>
</div>
<ul class="simple">
<li><p>In logistic regression,</p>
<ul>
<li><p>positive coefficients (like GRIN2A ~+1.0) increase the log-odds and therefore the probability of the positive class when the feature value increases</p></li>
<li><p>Negative coefficients (like IDH1 ~-3.0) decrease the log-odds and probability of the positive class</p></li>
</ul>
</li>
<li><p>The direction of the bar indicates whether the feature pushes predictions toward or away from the positive class.</p></li>
</ul>
</section>
</section>
<section id="evaluation-of-the-model-performance">
<h4>Evaluation of the model performance<a class="headerlink" href="#evaluation-of-the-model-performance" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>Confusion matrix</p></li>
</ul>
<section id="confusion-matrix">
<h5>Confusion matrix<a class="headerlink" href="#confusion-matrix" title="Link to this heading"></a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute confusion matrix</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predicted_classes</span><span class="p">)</span>

<span class="c1"># Plot confusion matrix as heatmap</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted Label&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True Label&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Confusion Matrix&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/abe1db1c5083c4c0b0715f6022ba642888b28b607b0616824db11754af40113c.png" src="_images/abe1db1c5083c4c0b0715f6022ba642888b28b607b0616824db11754af40113c.png" />
</div>
</div>
</section>
</section>
</section>
<span id="document-3.Notebook_ML_workflow"></span><section id="complete-ml-workflow">
<h3>Complete ML workflow<a class="headerlink" href="#complete-ml-workflow" title="Link to this heading"></a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">auc</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">classification_report</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">KFold</span>
</pre></div>
</div>
</div>
</div>
<section id="exploratory-analysis">
<h4>Exploratory analysis<a class="headerlink" href="#exploratory-analysis" title="Link to this heading"></a></h4>
<ol class="arabic simple">
<li><p>Understand the Data Structure and Summary</p>
<ol class="arabic simple">
<li><p>Load and Inspect</p></li>
<li><p>Descriptive Statistics</p></li>
</ol>
</li>
<li><p>Analyze the Target Variable</p>
<ol class="arabic simple">
<li><p>Check Data Type (Ensure your target variable is appropriately represented)</p></li>
<li><p>Determine the frequency of each class in your binary target variable</p></li>
</ol>
</li>
<li><p>Analyze features</p>
<ol class="arabic simple">
<li><p>Visualize the distributions of features</p></li>
</ol>
</li>
<li><p>Identify and Handle Missing Values</p></li>
</ol>
<section id="understand-the-data-structure-and-summary">
<h5>Understand the Data Structure and Summary<a class="headerlink" href="#understand-the-data-structure-and-summary" title="Link to this heading"></a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download the test dataset</span>
<span class="o">!</span><span class="w"> </span>curl<span class="w"> </span>https://naicno.github.io/BioNT_Module2_handson/_downloads/d072ac9ebbb200e56a8125b33b887657/TCGA_InfoWithGrade.csv<span class="w"> </span>-o<span class="w"> </span>TCGA_InfoWithGrade.csv
<span class="o">!</span><span class="w"> </span>ls<span class="w"> </span>-lh<span class="w"> </span>TCGA_InfoWithGrade.csv
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0 86432    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
100 86432  100 86432    0     0   462k      0 --:--:-- --:--:-- --:--:--  461k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-rw-r--r-- 1 runner docker 85K Jun 10 13:52 TCGA_InfoWithGrade.csv
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Read the dataset to get the glioma dataframe</span>
<span class="n">gliomas</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;TCGA_InfoWithGrade.csv&#39;</span><span class="p">)</span>
<span class="n">gliomas</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 840 entries, 0 to 839
Data columns (total 26 columns):
 #   Column            Non-Null Count  Dtype  
---  ------            --------------  -----  
 0   Grade             839 non-null    float64
 1   Gender            840 non-null    float64
 2   Age_at_diagnosis  839 non-null    float64
 3   Race              839 non-null    float64
 4   IDH1              839 non-null    float64
 5   TP53              839 non-null    float64
 6   ATRX              839 non-null    float64
 7   PTEN              839 non-null    float64
 8   EGFR              840 non-null    float64
 9   CIC               839 non-null    float64
 10  MUC16             839 non-null    float64
 11  PIK3CA            839 non-null    float64
 12  NF1               839 non-null    float64
 13  PIK3R1            840 non-null    float64
 14  FUBP1             839 non-null    float64
 15  RB1               839 non-null    float64
 16  NOTCH1            840 non-null    float64
 17  BCOR              839 non-null    float64
 18  CSMD3             839 non-null    float64
 19  SMARCA4           839 non-null    float64
 20  GRIN2A            839 non-null    float64
 21  IDH2              840 non-null    float64
 22  FAT4              839 non-null    float64
 23  PDGFRA            840 non-null    float64
 24  ATRX_xNA          630 non-null    float64
 25  IDH1_xNA          168 non-null    float64
dtypes: float64(26)
memory usage: 170.8 KB
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Inspect the first few rows of the DataFrame</span>
<span class="n">gliomas</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Grade</th>
      <th>Gender</th>
      <th>Age_at_diagnosis</th>
      <th>Race</th>
      <th>IDH1</th>
      <th>TP53</th>
      <th>ATRX</th>
      <th>PTEN</th>
      <th>EGFR</th>
      <th>CIC</th>
      <th>...</th>
      <th>NOTCH1</th>
      <th>BCOR</th>
      <th>CSMD3</th>
      <th>SMARCA4</th>
      <th>GRIN2A</th>
      <th>IDH2</th>
      <th>FAT4</th>
      <th>PDGFRA</th>
      <th>ATRX_xNA</th>
      <th>IDH1_xNA</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>51.30</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>38.72</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>35.17</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>32.78</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>31.51</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 26 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Quick summary statistics of the DataFrame</span>
<span class="n">gliomas</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Grade</th>
      <th>Gender</th>
      <th>Age_at_diagnosis</th>
      <th>Race</th>
      <th>IDH1</th>
      <th>TP53</th>
      <th>ATRX</th>
      <th>PTEN</th>
      <th>EGFR</th>
      <th>CIC</th>
      <th>...</th>
      <th>NOTCH1</th>
      <th>BCOR</th>
      <th>CSMD3</th>
      <th>SMARCA4</th>
      <th>GRIN2A</th>
      <th>IDH2</th>
      <th>FAT4</th>
      <th>PDGFRA</th>
      <th>ATRX_xNA</th>
      <th>IDH1_xNA</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>839.000000</td>
      <td>840.000000</td>
      <td>839.000000</td>
      <td>839.000000</td>
      <td>839.000000</td>
      <td>839.000000</td>
      <td>839.000000</td>
      <td>839.000000</td>
      <td>840.000000</td>
      <td>839.000000</td>
      <td>...</td>
      <td>840.000000</td>
      <td>839.000000</td>
      <td>839.000000</td>
      <td>839.000000</td>
      <td>839.000000</td>
      <td>840.000000</td>
      <td>839.000000</td>
      <td>840.000000</td>
      <td>630.000000</td>
      <td>168.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.419547</td>
      <td>0.417857</td>
      <td>50.935411</td>
      <td>0.107271</td>
      <td>0.481526</td>
      <td>0.414779</td>
      <td>0.258641</td>
      <td>0.168057</td>
      <td>0.133333</td>
      <td>0.132300</td>
      <td>...</td>
      <td>0.045238</td>
      <td>0.034565</td>
      <td>0.032181</td>
      <td>0.032181</td>
      <td>0.032181</td>
      <td>0.027381</td>
      <td>0.027414</td>
      <td>0.026190</td>
      <td>0.265079</td>
      <td>0.488095</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.493779</td>
      <td>0.493500</td>
      <td>15.702339</td>
      <td>0.369392</td>
      <td>0.499957</td>
      <td>0.492978</td>
      <td>0.438149</td>
      <td>0.374140</td>
      <td>0.340137</td>
      <td>0.339019</td>
      <td>...</td>
      <td>0.207950</td>
      <td>0.182784</td>
      <td>0.176586</td>
      <td>0.176586</td>
      <td>0.176586</td>
      <td>0.163288</td>
      <td>0.163383</td>
      <td>0.159797</td>
      <td>0.441726</td>
      <td>0.501353</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>14.420000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>38.055000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>51.550000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>62.800000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>89.290000</td>
      <td>3.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>...</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 26 columns</p>
</div></div></div>
</div>
</section>
<section id="analyze-the-target-variable">
<h5>Analyze the Target Variable<a class="headerlink" href="#analyze-the-target-variable" title="Link to this heading"></a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check data types of the target variable &#39;Grade&#39;</span>
<span class="n">gliomas</span><span class="p">[</span><span class="s2">&quot;Grade&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dtype(&#39;float64&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the counts of each grade in the &#39;Grade&#39; column</span>
<span class="n">gliomas</span><span class="p">[</span><span class="s2">&quot;Grade&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Grade
0.0    487
1.0    352
Name: count, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the fractions of each grade in the &#39;Grade&#39; column</span>
<span class="n">gliomas</span><span class="p">[</span><span class="s2">&quot;Grade&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Grade
0.0    0.580453
1.0    0.419547
Name: proportion, dtype: float64
</pre></div>
</div>
</div>
</div>
</section>
<section id="analyze-features">
<h5>Analyze features<a class="headerlink" href="#analyze-features" title="Link to this heading"></a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot the distribution of data in all columns</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="c1"># Iterate over each column and plot the distribution</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">column</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">gliomas</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Grade&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span><span class="p">):</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">gliomas</span><span class="p">[</span><span class="n">column</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c8f52d15e57ec1386ad0ddb06254df13ef40f0641c7b6f28d1c170f8e32b388a.png" src="_images/c8f52d15e57ec1386ad0ddb06254df13ef40f0641c7b6f28d1c170f8e32b388a.png" />
</div>
</div>
</section>
<section id="identify-and-handle-missing-values">
<h5>Identify and Handle Missing Values<a class="headerlink" href="#identify-and-handle-missing-values" title="Link to this heading"></a></h5>
<ul class="simple">
<li><p>Note that np.nan values are inserted into the original dataset specifically to demonstrate techniques that help handel these datasets</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate the % of missing values in each column</span>
<span class="n">gliomas</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">gliomas</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Grade                0.119048
Gender               0.000000
Age_at_diagnosis     0.119048
Race                 0.119048
IDH1                 0.119048
TP53                 0.119048
ATRX                 0.119048
PTEN                 0.119048
EGFR                 0.000000
CIC                  0.119048
MUC16                0.119048
PIK3CA               0.119048
NF1                  0.119048
PIK3R1               0.000000
FUBP1                0.119048
RB1                  0.119048
NOTCH1               0.000000
BCOR                 0.119048
CSMD3                0.119048
SMARCA4              0.119048
GRIN2A               0.119048
IDH2                 0.000000
FAT4                 0.119048
PDGFRA               0.000000
ATRX_xNA            25.000000
IDH1_xNA            80.000000
dtype: float64
</pre></div>
</div>
</div>
</div>
<section id="delete-rows-with-missing-values-in-target-variable">
<h6>Delete rows with missing values in target variable<a class="headerlink" href="#delete-rows-with-missing-values-in-target-variable" title="Link to this heading"></a></h6>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Remove rows with missing values in the &#39;Grade&#39; column</span>
<span class="n">gliomas</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Grade&quot;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># % of missing values in each column</span>
<span class="n">gliomas</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">gliomas</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Grade                0.000000
Gender               0.000000
Age_at_diagnosis     0.000000
Race                 0.000000
IDH1                 0.000000
TP53                 0.000000
ATRX                 0.000000
PTEN                 0.000000
EGFR                 0.000000
CIC                  0.000000
MUC16                0.000000
PIK3CA               0.000000
NF1                  0.000000
PIK3R1               0.000000
FUBP1                0.000000
RB1                  0.000000
NOTCH1               0.000000
BCOR                 0.000000
CSMD3                0.000000
SMARCA4              0.000000
GRIN2A               0.000000
IDH2                 0.000000
FAT4                 0.000000
PDGFRA               0.000000
ATRX_xNA            24.910608
IDH1_xNA            79.976162
dtype: float64
</pre></div>
</div>
</div>
</div>
</section>
<section id="keep-columns-with-at-least-95-non-missing-values">
<h6>Keep columns with at least 95% non-missing values<a class="headerlink" href="#keep-columns-with-at-least-95-non-missing-values" title="Link to this heading"></a></h6>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">threshold</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.95</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">gliomas</span><span class="p">))</span>
<span class="c1"># Keep columns with at least 95% non-missing values</span>
<span class="n">gliomas</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">thresh</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># % of missing values in each column</span>
<span class="n">gliomas</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">gliomas</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Grade               0.0
Gender              0.0
Age_at_diagnosis    0.0
Race                0.0
IDH1                0.0
TP53                0.0
ATRX                0.0
PTEN                0.0
EGFR                0.0
CIC                 0.0
MUC16               0.0
PIK3CA              0.0
NF1                 0.0
PIK3R1              0.0
FUBP1               0.0
RB1                 0.0
NOTCH1              0.0
BCOR                0.0
CSMD3               0.0
SMARCA4             0.0
GRIN2A              0.0
IDH2                0.0
FAT4                0.0
PDGFRA              0.0
dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot the distribution of data in all columns</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="c1"># Iterate over each column and plot the distribution</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">column</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">gliomas</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Grade&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span><span class="p">):</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">gliomas</span><span class="p">[</span><span class="n">column</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/f7a1df908b3695b7ec5796b2f486fb7ea39031816d717da42f46b9f7aa2258ec.png" src="_images/f7a1df908b3695b7ec5796b2f486fb7ea39031816d717da42f46b9f7aa2258ec.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Drop the &#39;Race&#39; column</span>
<span class="n">gliomas</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Race&quot;</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>When a category within a feature has very few samples (e.g., “Race”), a model might learn patterns from these specific few instances that are not generalizable to the wider population or new data. It essentially “memorizes” these rare cases and their associated outcomes, which can lead to poor performance on unseen data.</p>
</section>
</section>
</section>
<section id="split-original-dataset">
<h4>Split original dataset<a class="headerlink" href="#split-original-dataset" title="Link to this heading"></a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">gliomas</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;Grade&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">gliomas</span><span class="p">[</span><span class="s2">&quot;Grade&quot;</span><span class="p">],</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
    <span class="n">stratify</span><span class="o">=</span><span class="n">gliomas</span><span class="p">[</span><span class="s2">&quot;Grade&quot;</span><span class="p">],</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X_train:&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;X_test:&quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;y_train:&quot;</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;y_test:&quot;</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>X_train: (587, 22) X_test: (252, 22) y_train: (587,) y_test: (252,)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visulize the distribution of the target variable in the training and training set</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">X_train</span><span class="p">[[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Training Set&#39;</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">X_test</span><span class="p">[[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Test Set&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/f85c7c2f0895ef7983c865424ad1e2e289d724ad9028a60307b90f9dcf657710.png" src="_images/f85c7c2f0895ef7983c865424ad1e2e289d724ad9028a60307b90f9dcf657710.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit and transform the &#39;age&#39; column</span>
<span class="c1">## Apply simple transformation using the StandardScaler `scaler = StandardScaler()`</span>
<span class="c1">## directly on the &#39;Age_at_diagnosis&#39; column in train and test datasets</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">[[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]])</span>
<span class="n">X_test</span><span class="p">[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">[[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visulize the distribution of the target variable in the training and training set</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">X_train</span><span class="p">[[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Training Set&#39;</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">X_test</span><span class="p">[[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Test Set&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Age at Diagnosis Distribution after scaling&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/da094d0b6f7831a11fe8ba8928c8d6ba418f006b3617a3fbc31a13c3cfbb3c80.png" src="_images/da094d0b6f7831a11fe8ba8928c8d6ba418f006b3617a3fbc31a13c3cfbb3c80.png" />
</div>
</div>
</section>
<section id="logistic-regression-model">
<h4>Logistic regression model<a class="headerlink" href="#logistic-regression-model" title="Link to this heading"></a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>

<span class="c1"># Fit the model</span>
<span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: start;
  justify-content: space-between;
  gap: 0.5em;
}

#sk-container-id-1 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  display: none;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  display: block;
  width: 100%;
  overflow: visible;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}

.estimator-table summary {
    padding: .5rem;
    font-family: monospace;
    cursor: pointer;
}

.estimator-table details[open] {
    padding-left: 0.1rem;
    padding-right: 0.1rem;
    padding-bottom: 0.3rem;
}

.estimator-table .parameters-table {
    margin-left: auto !important;
    margin-right: auto !important;
}

.estimator-table .parameters-table tr:nth-child(odd) {
    background-color: #fff;
}

.estimator-table .parameters-table tr:nth-child(even) {
    background-color: #f6f6f6;
}

.estimator-table .parameters-table tr:hover {
    background-color: #e0e0e0;
}

.estimator-table table td {
    border: 1px solid rgba(106, 105, 104, 0.232);
}

.user-set td {
    color:rgb(255, 94, 0);
    text-align: left;
}

.user-set td.value pre {
    color:rgb(255, 94, 0) !important;
    background-color: transparent !important;
}

.default td {
    color: black;
    text-align: left;
}

.user-set td i,
.default td i {
    color: black;
}

.copy-paste-icon {
    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);
    background-repeat: no-repeat;
    background-size: 14px 14px;
    background-position: 0;
    display: inline-block;
    width: 14px;
    height: 14px;
    cursor: pointer;
}
</style><body><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>LogisticRegression</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html">?<span>Documentation for LogisticRegression</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></div></label><div class="sk-toggleable__content fitted" data-param-prefix="">
        <div class="estimator-table">
            <details>
                <summary>Parameters</summary>
                <table class="parameters-table">
                  <tbody>
                    
        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('penalty',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">penalty&nbsp;</td>
            <td class="value">&#x27;l2&#x27;</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('dual',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">dual&nbsp;</td>
            <td class="value">False</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('tol',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">tol&nbsp;</td>
            <td class="value">0.0001</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('C',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">C&nbsp;</td>
            <td class="value">1.0</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('fit_intercept',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">fit_intercept&nbsp;</td>
            <td class="value">True</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('intercept_scaling',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">intercept_scaling&nbsp;</td>
            <td class="value">1</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('class_weight',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">class_weight&nbsp;</td>
            <td class="value">None</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('random_state',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">random_state&nbsp;</td>
            <td class="value">None</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('solver',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">solver&nbsp;</td>
            <td class="value">&#x27;lbfgs&#x27;</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('max_iter',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">max_iter&nbsp;</td>
            <td class="value">100</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('multi_class',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">multi_class&nbsp;</td>
            <td class="value">&#x27;deprecated&#x27;</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('verbose',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">verbose&nbsp;</td>
            <td class="value">0</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('warm_start',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">warm_start&nbsp;</td>
            <td class="value">False</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('n_jobs',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">n_jobs&nbsp;</td>
            <td class="value">None</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('l1_ratio',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">l1_ratio&nbsp;</td>
            <td class="value">None</td>
        </tr>
    
                  </tbody>
                </table>
            </details>
        </div>
    </div></div></div></div></div><script>function copyToClipboard(text, element) {
    // Get the parameter prefix from the closest toggleable content
    const toggleableContent = element.closest('.sk-toggleable__content');
    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';
    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;

    const originalStyle = element.style;
    const computedStyle = window.getComputedStyle(element);
    const originalWidth = computedStyle.width;
    const originalHTML = element.innerHTML.replace('Copied!', '');

    navigator.clipboard.writeText(fullParamName)
        .then(() => {
            element.style.width = originalWidth;
            element.style.color = 'green';
            element.innerHTML = "Copied!";

            setTimeout(() => {
                element.innerHTML = originalHTML;
                element.style = originalStyle;
            }, 2000);
        })
        .catch(err => {
            console.error('Failed to copy:', err);
            element.style.color = 'red';
            element.innerHTML = "Failed!";
            setTimeout(() => {
                element.innerHTML = originalHTML;
                element.style = originalStyle;
            }, 2000);
        });
    return false;
}

document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {
    const toggleableContent = element.closest('.sk-toggleable__content');
    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';
    const paramName = element.parentElement.nextElementSibling.textContent.trim();
    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;

    element.setAttribute('title', fullParamName);
});
</script></body></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predict the Glioma type of the new dataset</span>
<span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.,
       1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.,
       1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
       0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.,
       1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,
       0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
       0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
       0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0.,
       1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
       0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,
       1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
       0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.,
       1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0.,
       0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Examine and understand the importance of features in predicting glioma type</span>
<span class="n">feature_list</span> <span class="o">=</span> <span class="n">gliomas</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of Features&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_list</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Features&quot;</span><span class="p">,</span> <span class="n">feature_list</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of Features 22
Features Index([&#39;Gender&#39;, &#39;Age_at_diagnosis&#39;, &#39;IDH1&#39;, &#39;TP53&#39;, &#39;ATRX&#39;, &#39;PTEN&#39;, &#39;EGFR&#39;,
       &#39;CIC&#39;, &#39;MUC16&#39;, &#39;PIK3CA&#39;, &#39;NF1&#39;, &#39;PIK3R1&#39;, &#39;FUBP1&#39;, &#39;RB1&#39;, &#39;NOTCH1&#39;,
       &#39;BCOR&#39;, &#39;CSMD3&#39;, &#39;SMARCA4&#39;, &#39;GRIN2A&#39;, &#39;IDH2&#39;, &#39;FAT4&#39;, &#39;PDGFRA&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a DataFrame of the coefficients an their corresponding features</span>
<span class="n">coefficients</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">feature_list</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Coefficient&#39;</span><span class="p">])</span>
<span class="n">coefficients</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;Coefficient&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Coefficient</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>GRIN2A</th>
      <td>1.056014</td>
    </tr>
    <tr>
      <th>PIK3R1</th>
      <td>0.946648</td>
    </tr>
    <tr>
      <th>TP53</th>
      <td>0.942277</td>
    </tr>
    <tr>
      <th>PTEN</th>
      <td>0.797627</td>
    </tr>
    <tr>
      <th>Age_at_diagnosis</th>
      <td>0.673566</td>
    </tr>
    <tr>
      <th>MUC16</th>
      <td>0.604058</td>
    </tr>
    <tr>
      <th>PDGFRA</th>
      <td>0.445156</td>
    </tr>
    <tr>
      <th>BCOR</th>
      <td>0.354251</td>
    </tr>
    <tr>
      <th>CSMD3</th>
      <td>0.273943</td>
    </tr>
    <tr>
      <th>RB1</th>
      <td>0.156225</td>
    </tr>
    <tr>
      <th>PIK3CA</th>
      <td>0.059625</td>
    </tr>
    <tr>
      <th>Gender</th>
      <td>0.033080</td>
    </tr>
    <tr>
      <th>FAT4</th>
      <td>-0.007242</td>
    </tr>
    <tr>
      <th>ATRX</th>
      <td>-0.192868</td>
    </tr>
    <tr>
      <th>FUBP1</th>
      <td>-0.409964</td>
    </tr>
    <tr>
      <th>SMARCA4</th>
      <td>-0.414214</td>
    </tr>
    <tr>
      <th>EGFR</th>
      <td>-0.537785</td>
    </tr>
    <tr>
      <th>CIC</th>
      <td>-0.780298</td>
    </tr>
    <tr>
      <th>NF1</th>
      <td>-0.836192</td>
    </tr>
    <tr>
      <th>NOTCH1</th>
      <td>-1.459100</td>
    </tr>
    <tr>
      <th>IDH2</th>
      <td>-1.733579</td>
    </tr>
    <tr>
      <th>IDH1</th>
      <td>-3.286614</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="evaluate-model-performance">
<h4>Evaluate model performance<a class="headerlink" href="#evaluate-model-performance" title="Link to this heading"></a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predict on test set</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Compute confusion matrix</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="c1"># Plot confusion matrix as heatmap</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted Label&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True Label&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Confusion Matrix&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/abe1db1c5083c4c0b0715f6022ba642888b28b607b0616824db11754af40113c.png" src="_images/abe1db1c5083c4c0b0715f6022ba642888b28b607b0616824db11754af40113c.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate classification report</span>
<span class="n">report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

         0.0       0.91      0.85      0.88       146
         1.0       0.81      0.89      0.85       106

    accuracy                           0.87       252
   macro avg       0.86      0.87      0.86       252
weighted avg       0.87      0.87      0.87       252
</pre></div>
</div>
</div>
</div>
<section id="the-problems-with-single-test-dataset-holdout-sets-in-model-validation">
<h5>The problems with single test dataset (holdout sets) in model validation<a class="headerlink" href="#the-problems-with-single-test-dataset-holdout-sets-in-model-validation" title="Link to this heading"></a></h5>
<ul class="simple">
<li><p>Using different random seeds can lead to different results even when using the same model and dataset</p></li>
<li><p>The variability in results makes it difficult to accurately assess the model’s true performance and generalizability</p></li>
<li><p>Cross-validation is proposed as the gold-standard solution to overcome the limitations of holdout sets in model validation</p></li>
</ul>
</section>
</section>
<section id="cross-validation">
<h4>Cross-validation<a class="headerlink" href="#cross-validation" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>Cross-validation is a method that involves running a single model on various training/validation combinations to get more confident final metrics</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Use KFold and create kf object</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1111</span><span class="p">)</span>

<span class="c1"># Create splits</span>
<span class="c1">## The `split` method of the KFold object will yield indices for training and validation sets</span>
<span class="n">splits</span> <span class="o">=</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">gliomas</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;Grade&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

<span class="c1"># Print the indices of the training and validation sets for each fold</span>
<span class="k">for</span> <span class="n">split</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">splits</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fold </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">k</span><span class="p">)</span>
    <span class="n">train_index</span><span class="p">,</span> <span class="n">val_index</span> <span class="o">=</span> <span class="n">split</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of training indices: </span><span class="si">%s</span><span class="s2">; First 10: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_index</span><span class="p">),</span> <span class="n">train_index</span><span class="p">[:</span><span class="mi">10</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of validation indices: </span><span class="si">%s</span><span class="s2">; First 10: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">val_index</span><span class="p">),</span> <span class="n">val_index</span><span class="p">[:</span><span class="mi">10</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fold 1
Number of training indices: 671; First 10: [ 2  3  5  6  8  9 10 11 12 13]
Number of validation indices: 168; First 10: [ 0  1  4  7 23 25 32 33 34 38]
Fold 2
Number of training indices: 671; First 10: [ 0  1  3  4  5  6  7  8  9 10]
Number of validation indices: 168; First 10: [ 2 12 16 24 35 39 45 49 57 61]
Fold 3
Number of training indices: 671; First 10: [ 0  1  2  3  4  6  7  8  9 10]
Number of validation indices: 168; First 10: [ 5 13 26 27 29 36 37 41 46 47]
Fold 4
Number of training indices: 671; First 10: [ 0  1  2  4  5  7  9 12 13 14]
Number of validation indices: 168; First 10: [ 3  6  8 10 11 19 22 31 40 43]
Fold 5
Number of training indices: 672; First 10: [ 0  1  2  3  4  5  6  7  8 10]
Number of validation indices: 167; First 10: [ 9 14 15 17 18 20 21 28 30 42]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">gliomas</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;Grade&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">gliomas</span><span class="p">[</span><span class="s2">&quot;Grade&quot;</span><span class="p">]</span>


<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1111</span><span class="p">)</span>
<span class="n">splits</span> <span class="o">=</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">gliomas</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;Grade&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

<span class="n">kf_cv_scores</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Fold&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;Precision_Class_0&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;Precision_Class_1&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;Recall_Class_0&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;Recall_Class_1&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;F1_Class_0&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;F1_Class_1&quot;</span><span class="p">:</span> <span class="p">[],</span>
<span class="p">}</span>

<span class="c1"># Initialize scaler</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">fold</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">val_index</span> <span class="ow">in</span> <span class="n">splits</span><span class="p">:</span>
    <span class="c1"># Setup the training and validation data</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
    <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">val_index</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">val_index</span><span class="p">]</span>

    <span class="c1"># Create copies to avoid modifying original data</span>
    <span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">X_val_scaled</span> <span class="o">=</span> <span class="n">X_val</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    
    <span class="c1"># Scale only the Age_at_diagnosis column</span>
    <span class="n">X_train_scaled</span><span class="p">[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">[[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">X_val_scaled</span><span class="p">[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_val</span><span class="p">[[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    
    <span class="c1"># Initialize the Logistic Regression model with cross-validation</span>
    <span class="n">lr_cv</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>

    <span class="c1"># Use the SCALED data for training and prediction</span>
    <span class="n">lr_cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>  <span class="c1"># ← Now using scaled data</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">lr_cv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_val_scaled</span><span class="p">)</span>  <span class="c1"># ← Now using scaled data</span>

    <span class="n">precision</span> <span class="o">=</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">recall</span> <span class="o">=</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="n">kf_cv_scores</span><span class="p">[</span><span class="s2">&quot;Fold&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fold</span><span class="p">)</span>
    <span class="n">kf_cv_scores</span><span class="p">[</span><span class="s2">&quot;Precision_Class_0&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">precision</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span><span class="mi">3</span><span class="p">))</span>
    <span class="n">kf_cv_scores</span><span class="p">[</span><span class="s2">&quot;Recall_Class_0&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">recall</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span><span class="mi">3</span><span class="p">))</span>
    <span class="n">kf_cv_scores</span><span class="p">[</span><span class="s2">&quot;Precision_Class_1&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">precision</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span><span class="mi">3</span><span class="p">))</span>
    <span class="n">kf_cv_scores</span><span class="p">[</span><span class="s2">&quot;Recall_Class_1&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">recall</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span><span class="mi">3</span><span class="p">))</span>
    <span class="n">kf_cv_scores</span><span class="p">[</span><span class="s2">&quot;F1_Class_0&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">f1</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span><span class="mi">3</span><span class="p">))</span>
    <span class="n">kf_cv_scores</span><span class="p">[</span><span class="s2">&quot;F1_Class_1&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">f1</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span><span class="mi">3</span><span class="p">))</span>
    <span class="n">fold</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">kf_cv_scores</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;Fold&#39;: [1, 2, 3, 4, 5],
 &#39;Precision_Class_0&#39;: [0.933, 0.948, 0.937, 0.862, 0.966],
 &#39;Precision_Class_1&#39;: [0.782, 0.78, 0.795, 0.824, 0.863],
 &#39;Recall_Class_0&#39;: [0.832, 0.785, 0.856, 0.862, 0.884],
 &#39;Recall_Class_1&#39;: [0.91, 0.947, 0.906, 0.824, 0.958],
 &#39;F1_Class_0&#39;: [0.88, 0.859, 0.894, 0.862, 0.923],
 &#39;F1_Class_1&#39;: [0.841, 0.855, 0.847, 0.824, 0.908]}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kf_cv_scores_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">kf_cv_scores</span><span class="p">)</span>
<span class="n">kf_cv_scores_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Fold</th>
      <th>Precision_Class_0</th>
      <th>Precision_Class_1</th>
      <th>Recall_Class_0</th>
      <th>Recall_Class_1</th>
      <th>F1_Class_0</th>
      <th>F1_Class_1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0.933</td>
      <td>0.782</td>
      <td>0.832</td>
      <td>0.910</td>
      <td>0.880</td>
      <td>0.841</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>0.948</td>
      <td>0.780</td>
      <td>0.785</td>
      <td>0.947</td>
      <td>0.859</td>
      <td>0.855</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>0.937</td>
      <td>0.795</td>
      <td>0.856</td>
      <td>0.906</td>
      <td>0.894</td>
      <td>0.847</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>0.862</td>
      <td>0.824</td>
      <td>0.862</td>
      <td>0.824</td>
      <td>0.862</td>
      <td>0.824</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0.966</td>
      <td>0.863</td>
      <td>0.884</td>
      <td>0.958</td>
      <td>0.923</td>
      <td>0.908</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># Line plot showing variation across folds</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kf_cv_scores</span><span class="p">[</span><span class="s1">&#39;Fold&#39;</span><span class="p">],</span> <span class="n">kf_cv_scores</span><span class="p">[</span><span class="s1">&#39;Precision_Class_0&#39;</span><span class="p">],</span> <span class="s1">&#39;-o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Precision_Class_0&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kf_cv_scores</span><span class="p">[</span><span class="s1">&#39;Fold&#39;</span><span class="p">],</span> <span class="n">kf_cv_scores</span><span class="p">[</span><span class="s1">&#39;Precision_Class_1&#39;</span><span class="p">],</span> <span class="s1">&#39;-*&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Precision_Class_1&#39;</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Fold&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">kf_cv_scores</span><span class="p">[</span><span class="s1">&#39;Fold&#39;</span><span class="p">])</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Precision Score&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kf_cv_scores</span><span class="p">[</span><span class="s1">&#39;Fold&#39;</span><span class="p">],</span> <span class="n">kf_cv_scores</span><span class="p">[</span><span class="s1">&#39;Recall_Class_0&#39;</span><span class="p">],</span> <span class="s1">&#39;-s&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Recall_Class_0&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kf_cv_scores</span><span class="p">[</span><span class="s1">&#39;Fold&#39;</span><span class="p">],</span> <span class="n">kf_cv_scores</span><span class="p">[</span><span class="s1">&#39;Recall_Class_1&#39;</span><span class="p">],</span> <span class="s1">&#39;-*&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Recall_Class_1&#39;</span><span class="p">)</span>

<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Fold&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">kf_cv_scores</span><span class="p">[</span><span class="s1">&#39;Fold&#39;</span><span class="p">])</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Recall Score&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7ff0a28e72dda8a14822486d032b623de7ace332b3d80ae33e233d7dbdaba71f.png" src="_images/7ff0a28e72dda8a14822486d032b623de7ace332b3d80ae33e233d7dbdaba71f.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cv_summary</span> <span class="o">=</span> <span class="n">kf_cv_scores_df</span><span class="o">.</span><span class="n">aggregate</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;Precision_Class_0&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;std&quot;</span><span class="p">],</span>
        <span class="s2">&quot;Precision_Class_1&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;std&quot;</span><span class="p">],</span>
        <span class="s2">&quot;Recall_Class_0&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;std&quot;</span><span class="p">],</span>
        <span class="s2">&quot;Recall_Class_1&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;std&quot;</span><span class="p">],</span>
        <span class="s2">&quot;F1_Class_0&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;std&quot;</span><span class="p">],</span>
        <span class="s2">&quot;F1_Class_1&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;std&quot;</span><span class="p">],</span>
    <span class="p">}</span>
<span class="p">)</span>
<span class="n">cv_summary</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Precision_Class_0</th>
      <th>Precision_Class_1</th>
      <th>Recall_Class_0</th>
      <th>Recall_Class_1</th>
      <th>F1_Class_0</th>
      <th>F1_Class_1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>min</th>
      <td>0.862000</td>
      <td>0.780000</td>
      <td>0.785000</td>
      <td>0.824000</td>
      <td>0.859000</td>
      <td>0.824000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>0.966000</td>
      <td>0.863000</td>
      <td>0.884000</td>
      <td>0.958000</td>
      <td>0.923000</td>
      <td>0.908000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.929200</td>
      <td>0.808800</td>
      <td>0.843800</td>
      <td>0.909000</td>
      <td>0.883600</td>
      <td>0.855000</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.039682</td>
      <td>0.035024</td>
      <td>0.037725</td>
      <td>0.052631</td>
      <td>0.026197</td>
      <td>0.031741</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cv_summary</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>min</th>
      <th>max</th>
      <th>mean</th>
      <th>std</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Precision_Class_0</th>
      <td>0.862</td>
      <td>0.966</td>
      <td>0.9292</td>
      <td>0.039682</td>
    </tr>
    <tr>
      <th>Precision_Class_1</th>
      <td>0.780</td>
      <td>0.863</td>
      <td>0.8088</td>
      <td>0.035024</td>
    </tr>
    <tr>
      <th>Recall_Class_0</th>
      <td>0.785</td>
      <td>0.884</td>
      <td>0.8438</td>
      <td>0.037725</td>
    </tr>
    <tr>
      <th>Recall_Class_1</th>
      <td>0.824</td>
      <td>0.958</td>
      <td>0.9090</td>
      <td>0.052631</td>
    </tr>
    <tr>
      <th>F1_Class_0</th>
      <td>0.859</td>
      <td>0.923</td>
      <td>0.8836</td>
      <td>0.026197</td>
    </tr>
    <tr>
      <th>F1_Class_1</th>
      <td>0.824</td>
      <td>0.908</td>
      <td>0.8550</td>
      <td>0.031741</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p><strong>Interpretation guidelines:</strong></p>
<ol class="arabic simple">
<li><p>Mean Performance:</p>
<ul class="simple">
<li><p>Higher mean = better overall performance</p></li>
<li><p>Compare to baseline or business requirements</p></li>
</ul>
</li>
<li><p>Standard Deviation:</p>
<ul class="simple">
<li><p>Low SD = consistent performance across folds (good generalization)</p></li>
<li><p>High SD = variable performance (potential overfitting or data issues)</p></li>
</ul>
</li>
<li><p>Range and Min/Max:</p>
<ul class="simple">
<li><p>Small range = consistent across different data subsets</p></li>
<li><p>Large range = sensitive to specific data characteristics</p></li>
</ul>
</li>
</ol>
</section>
<section id="hyperparameter-tuning">
<h4>Hyperparameter Tuning<a class="headerlink" href="#hyperparameter-tuning" title="Link to this heading"></a></h4>
<section id="hyperparameters">
<h5>Hyperparameters:<a class="headerlink" href="#hyperparameters" title="Link to this heading"></a></h5>
<ul class="simple">
<li><p>Set before training begins</p></li>
<li><p>Configure model architecture/behavior</p></li>
<li><p>Not learned; require manual tuning</p></li>
<li><p>Core hyperparameters in <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code>:</p>
<ul>
<li><p>Penalty (loss): ‘l1’, ‘l2’, ‘elasticnet’, None (Default: ‘l2’)</p></li>
<li><p>Regularization strength: smaller values mean stronger regularization (Default: 1.0)</p></li>
<li><p>Solver (Algorithm to use for optimization): <code class="docutils literal notranslate"><span class="pre">newton-cg</span></code>, <code class="docutils literal notranslate"><span class="pre">lbfgs</span></code>, <code class="docutils literal notranslate"><span class="pre">liblinear</span></code>, <code class="docutils literal notranslate"><span class="pre">sag</span></code>, <code class="docutils literal notranslate"><span class="pre">saga</span></code> (Default: <code class="docutils literal notranslate"><span class="pre">lbfgs</span></code>)</p></li>
</ul>
</li>
<li><p>Core Hyperparameters can</p>
<ul>
<li><p>Directly influence model’s learning process and capabilities</p></li>
<li><p>Control model complexity, learning behavior, and prevention of overfitting</p></li>
<li><p>Changes significantly impact accuracy, generalization, and prediction quality</p></li>
</ul>
</li>
</ul>
<p>Additional notes (regarding parameters used in following cell):</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">C</span></code> (Regularization Strength):</p>
<ul>
<li><p>Controls how much to penalize complex models</p></li>
<li><p>Smaller values = more regularization (simpler model)</p></li>
</ul>
</li>
<li><p>Loss function (penalty):</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">l2</span></code>: Ridge regularization (shrinks coefficients toward zero)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">l1</span></code>: Lasso regularization (can set coefficients exactly to zero, good for feature selection)</p></li>
</ul>
</li>
<li><p>solver:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">liblinear</span></code>: Good for small datasets, works with both L1 and L2</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">saga</span></code>: Good for large datasets, works with both L1 and L2</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ElasticNet</span></code>: Combines <code class="docutils literal notranslate"><span class="pre">L1</span></code> and <code class="docutils literal notranslate"><span class="pre">L2</span></code> benefits (address multicollinearity handle groups of correlated genes)</p></li>
<li></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_iter:</span></code></p>
<ul>
<li><p>Maximum number of iterations for the algorithm to converge</p></li>
<li><p>Increase if you get convergence warnings</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the features and target variable</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">gliomas</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;Grade&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">gliomas</span><span class="p">[</span><span class="s2">&quot;Grade&quot;</span><span class="p">],</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
    <span class="n">stratify</span><span class="o">=</span><span class="n">gliomas</span><span class="p">[</span><span class="s2">&quot;Grade&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="c1"># Create the base model</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>

<span class="c1"># Define the parameter grid</span>
<span class="c1"># Define a VALID parameter grid</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">[</span>
    <span class="c1"># For l2 penalty (works with all solvers)</span>
    <span class="p">{</span>
        <span class="s1">&#39;penalty&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;l2&#39;</span><span class="p">],</span>
        <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
        <span class="s1">&#39;solver&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span> <span class="s1">&#39;liblinear&#39;</span><span class="p">,</span> <span class="s1">&#39;newton-cg&#39;</span><span class="p">,</span> <span class="s1">&#39;sag&#39;</span><span class="p">,</span> <span class="s1">&#39;saga&#39;</span><span class="p">]</span>
    <span class="p">},</span>
    <span class="c1"># For l1 penalty (only works with liblinear and saga)</span>
    <span class="p">{</span>
        <span class="s1">&#39;penalty&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;l1&#39;</span><span class="p">],</span>
        <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
        <span class="s1">&#39;solver&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;liblinear&#39;</span><span class="p">,</span> <span class="s1">&#39;saga&#39;</span><span class="p">]</span>
    <span class="p">},</span>
    <span class="c1"># For elasticnet penalty (only works with saga)</span>
    <span class="c1"># Note: l1_ratio must be between 0 and 1</span>
    <span class="p">{</span>
        <span class="s1">&#39;penalty&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;elasticnet&#39;</span><span class="p">],</span>
        <span class="s1">&#39;l1_ratio&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span>
        <span class="s1">&#39;solver&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;saga&#39;</span><span class="p">],</span>
        <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>

    <span class="p">}</span>
<span class="p">]</span>

<span class="c1"># Create GridSearchCV object</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
    <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>  <span class="c1"># 5-fold cross-validation</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1_macro&#39;</span><span class="p">,</span>  <span class="c1"># Assessment metric</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># Print progress</span>
    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>  <span class="c1"># Use all CPU cores</span>
<span class="p">)</span>

<span class="c1"># Fit the grid search</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Access results for different metrics</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best parameters (based on f1):&quot;</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best f1 score:&quot;</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>

<span class="c1"># Make predictions with the best model</span>
<span class="n">best_model</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluate the best model</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Test set accuracy:&quot;</span><span class="p">,</span> <span class="n">best_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 51 candidates, totalling 255 fits
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best parameters (based on f1): {&#39;C&#39;: 1, &#39;penalty&#39;: &#39;l1&#39;, &#39;solver&#39;: &#39;liblinear&#39;}
Best f1 score: 0.8708974463864253

Test set accuracy: 0.8690476190476191

Classification Report:
              precision    recall  f1-score   support

         0.0       0.92      0.85      0.88       146
         1.0       0.81      0.90      0.85       106

    accuracy                           0.87       252
   macro avg       0.87      0.87      0.87       252
weighted avg       0.87      0.87      0.87       252
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute confusion matrix</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="c1"># Plot confusion matrix as heatmap</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted Label&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True Label&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Confusion Matrix&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/190dd114d6010ce52953da6ecadc3a5517d1f315588a7d74b2350fc4c81e9cf4.png" src="_images/190dd114d6010ce52953da6ecadc3a5517d1f315588a7d74b2350fc4c81e9cf4.png" />
</div>
</div>
</section>
</section>
</section>
</div>
<div class="toctree-wrapper compound">
<span id="document-1.PCA_n_clustering_QnA"></span><section id="unsupervised-learning">
<h3>Unsupervised Learning<a class="headerlink" href="#unsupervised-learning" title="Link to this heading"></a></h3>
<section id="q-a-session-principal-component-analysis-pca-and-k-means-clustering">
<h4>Q &amp; A session: Principal component analysis (PCA) and K-means clustering<a class="headerlink" href="#q-a-session-principal-component-analysis-pca-and-k-means-clustering" title="Link to this heading"></a></h4>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>Participants were given 45-60 minutes to</p>
<ul>
<li><p>go through the Jupter notebook and</p></li>
<li><p>select correct answers for the questions</p></li>
</ul>
</li>
<li><p>Instructor narrate the answers and reasoning after the self-study time</p>
<ul>
<li><p>time: 30 minutes</p></li>
</ul>
</li>
</ul>
</div>
<section id="dimensionality-of-the-datasets">
<h5>Dimensionality of the datasets<a class="headerlink" href="#dimensionality-of-the-datasets" title="Link to this heading"></a></h5>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<p><strong>Question 1:</strong></p>
<p>You have a dataset with 50 columns (drug compounds) and 25 rows (patients). Is this dataset considered high-dimensional?</p>
<ul class="simple">
<li><p>A) No, because 50 columns is not a large number</p></li>
<li><p>B) No, because the dataset is too small overall</p></li>
<li><p>C) Yes, because there are more features (50) than samples (25)</p></li>
<li><p>D) Yes, because 25 patients is insufficient for any analysis</p></li>
</ul>
<p><strong>Question 2:</strong></p>
<p>Why is your dataset with 50 drug compounds and 25 patients considered high-dimensional?</p>
<ul class="simple">
<li><p>A) Because 50 is the threshold for high-dimensionality</p></li>
<li><p>B) Because the number of features (50) significantly exceeds the number of samples (25)</p></li>
<li><p>C) Because drug compound data is inherently high-dimensional</p></li>
<li><p>D) Because 25 patients represent too many medical conditions</p></li>
</ul>
<p><strong>Question 3:</strong></p>
<p>In your dataset, the ratio of features to samples is 2:1 (50 features to 25 samples). This high-dimensional characteristic is most likely to cause:</p>
<ul class="simple">
<li><p>A) Faster model training due to more information per patient</p></li>
<li><p>B) Better generalization because of the rich feature space</p></li>
<li><p>C) The “curse of dimensionality” and potential overfitting issues</p></li>
<li><p>D) Automatic feature selection by machine learning algorithms</p></li>
</ul>
</div>
</section>
<section id="standardization">
<h5>Standardization<a class="headerlink" href="#standardization" title="Link to this heading"></a></h5>
<div class="admonition-questions questions admonition" id="questions-1">
<p class="admonition-title">Questions</p>
<p><strong>Before (A) / After standardization plots (B):</strong></p>
<p>A.
<img alt="alt text" src="_images/image-12.png" /></p>
<p>B.
<img alt="alt text" src="_images/image-13.png" /></p>
<p><strong>Question 1: Scale Uniformity After Standardization:</strong></p>
<p>Comparing the original drug sensitivity scores (A) with the standardized versions (B), what is the most important change for PCA analysis?</p>
<ul class="simple">
<li><p>A) The standardized data has fewer outliers than the original data</p></li>
<li><p>B) All drug compounds now have similar scales (roughly -3 to +3) instead of vastly different ranges</p></li>
<li><p>C) The standardized data shows stronger correlations between compounds</p></li>
<li><p>D) The standardized data has reduced the total number of features</p></li>
</ul>
<p><strong>Question 2: PCA Component Interpretation:</strong></p>
<p>After standardization, all drug compounds now have approximately the same variance. How will this affect your PCA results compared to using the original unstandardized data?</p>
<ul class="simple">
<li><p>A) PC1 will still be dominated by the originally high-variance compounds like leptoporin B</p></li>
<li><p>B) PCA components will now reflect actual biological/chemical relationships rather than just scale differences</p></li>
<li><p>C) PCA will find fewer meaningful components due to the uniform scaling</p></li>
<li><p>D) The explained variance percentages will be identical to the unstandardized analysis</p></li>
</ul>
<p><strong>Question 3: Practical PCA Decision:</strong></p>
<p>You’re about to perform PCA for drug discovery research. Based on your standardization comparison, which approach would give you more interpretable principal components for identifying drug response patterns?</p>
<ul class="simple">
<li><p>A) Use original data because it preserves the natural measurement scales of each drug</p></li>
<li><p>B) Use standardized data because it allows PCA to focus on underlying biological patterns rather than measurement scale artifacts</p></li>
<li><p>C) It doesn’t matter - PCA will automatically handle scale differences</p></li>
<li><p>D) Use original data because standardization removes important variance information</p></li>
</ul>
<p><strong>Question 4:  Variance Landscape:</strong></p>
<p>Looking at your standardized data plot where all compounds now have similar variance, what does this mean for PCA’s search for “maximum variance directions”?</p>
<ul class="simple">
<li><p>A) PCA will no longer work because there’s no variance to capture</p></li>
<li><p>B) PCA will now find directions based on correlations and biological patterns rather than being biased by high-variance features</p></li>
<li><p>C) PCA will randomly select components since all variances are equal</p></li>
<li><p>D) PCA will focus only on outlier detection</p></li>
</ul>
</div>
</section>
<section id="apply-pca-transformation">
<h5>Apply PCA transformation<a class="headerlink" href="#apply-pca-transformation" title="Link to this heading"></a></h5>
<div class="admonition-questions questions admonition" id="questions-2">
<p class="admonition-title">Questions</p>
<p><img alt="alt text" src="_images/image-14.png" /></p>
<p><strong>Question 1:</strong></p>
<p>Comparing the two heatmaps, what is the most significant difference between the correlation patterns of the original drug compounds (left) and the PCA components (right)?</p>
<ul class="simple">
<li><p>A) The PCA components show stronger correlations than the original compounds</p></li>
<li><p>B) The original compounds are uncorrelated while PCA components are highly correlated</p></li>
<li><p>C) The original compounds show various correlation patterns, while PCA components are essentially uncorrelated (orthogonal)</p></li>
<li><p>D) Both heatmaps show identical correlation structures</p></li>
</ul>
<p><strong>Question 2:</strong></p>
<p>In your PCA components heatmap (right), most correlations appear to be near zero (gray/white). This pattern demonstrates which fundamental property of PCA?</p>
<ul class="simple">
<li><p>A) PCA randomly shuffles the original correlations</p></li>
<li><p>B) PCA creates principal components that are orthogonal (perpendicular) to each other, eliminating correlation</p></li>
<li><p>C) PCA amplifies the strongest correlations from the original data</p></li>
<li><p>D) PCA preserves all original correlation relationships between features</p></li>
</ul>
<p><strong>Question 3:</strong></p>
<p>The original drug compounds heatmap shows clusters of correlated compounds (red blocks), while the PCA heatmap is predominantly gray. What does this tell you about what PCA has accomplished?</p>
<ul class="simple">
<li><p>A) PCA has lost important information about drug relationships</p></li>
<li><p>B) PCA has transformed the correlated original features into a new set of uncorrelated components that still capture the data’s variance</p></li>
<li><p>C) PCA has created random noise instead of meaningful components</p></li>
<li><p>D) PCA has made the data analysis more complicated</p></li>
</ul>
</div>
</section>
<section id="explained-variance-ratios">
<h5>Explained variance ratios<a class="headerlink" href="#explained-variance-ratios" title="Link to this heading"></a></h5>
<div class="admonition-questions questions admonition" id="questions-3">
<p class="admonition-title">Questions</p>
<p><img alt="alt text" src="_images/image-15.png" /></p>
<p><strong>Question 1:</strong></p>
<p>Your plot shows that 10 principal components explain 95% of the total variance (red dashed line). For a machine learning application, which approach would be most appropriate?</p>
<ul class="simple">
<li><p>A) Always use all 25 components to avoid losing any information</p></li>
<li><p>B) Use exactly 10 components because they reach the 95% threshold</p></li>
<li><p>C) Use only PC1 since it explains the most variance (40%)</p></li>
<li><p>D) Choose the number of components based on your specific analysis goals and computational constraints</p></li>
</ul>
<p><strong>Question 2:</strong></p>
<p>Examining the individual explained variance bars (blue), there’s a sharp drop after PC1 and PC2, then the contributions become much smaller. This pattern suggests:</p>
<ul class="simple">
<li><p>A) The first two components capture the main data structure, while next ffew components may represent minor patterns and last few components represent noise</p></li>
<li><p>B) Only PC1 and PC2 are mathematically valid</p></li>
<li><p>C) Components 3-25 contain no useful information</p></li>
<li><p>D) This indicates an error in the PCA calculation</p></li>
</ul>
<p><strong>Question 3:</strong></p>
<p>In the context of your drug sensitivity dataset, what does PC1’s 40% explained variance represent biologically?</p>
<ul class="simple">
<li><p>A) 40% of the drugs are important for the analysis</p></li>
<li><p>B) The first principal component captures a major pattern of drug response variation across patients that accounts for 40% of the total variability</p></li>
<li><p>C) 40% of the patients respond similarly to drugs</p></li>
<li><p>D) 60% of the data is noise and should be discarded</p></li>
</ul>
</div>
</section>
<section id="generate-scree-plot">
<h5>Generate scree plot<a class="headerlink" href="#generate-scree-plot" title="Link to this heading"></a></h5>
<div class="admonition-questions questions admonition" id="questions-4">
<p class="admonition-title">Questions</p>
<p><img alt="alt text" src="_images/image-16.png" /></p>
<p><strong>Question 1:</strong></p>
<p>In your scree plot, the eigenvalues drop sharply from PC1 (~21) to PC2 (~9) to PC3 (~6), then gradually flatten out after PC6-7. What is the logic behind choosing the number of components at the “elbow” point where the curve starts to flatten?</p>
<ul class="simple">
<li><p>A) Components after the elbow contain no mathematical information</p></li>
<li><p>B) Components before the elbow capture major data patterns, while those after the elbow likely represent noise or minor variations</p></li>
<li><p>C) The elbow point is randomly determined and has no statistical meaning</p></li>
<li><p>D) You should always choose exactly at the steepest drop point</p></li>
</ul>
<p><strong>Question 2:</strong></p>
<p>Looking at your scree plot, why do we typically avoid including principal components from the flat region (PC8 onwards, where eigenvalues are close to 0)?</p>
<ul class="simple">
<li><p>A) These components are mathematically incorrect and will cause errors</p></li>
<li><p>B) These components represent very small amounts of variance and may capture noise rather than meaningful signal</p></li>
<li><p>C) These components take too much computational time to calculate</p></li>
<li><p>D) These components are always highly correlated with the first few components</p></li>
</ul>
</div>
</section>
<section id="interpretation-and-analysis">
<h5>Interpretation and Analysis<a class="headerlink" href="#interpretation-and-analysis" title="Link to this heading"></a></h5>
<div class="admonition-questions questions admonition" id="questions-5">
<p class="admonition-title">Questions</p>
<p><img alt="alt text" src="_images/image-17.png" /></p>
<p><strong>Question 1:</strong></p>
<p>In this PCA loadings heatmap, some drug compounds show dark red or dark blue colors while others appear white/gray. What do these color intensities tell you about each compound’s contribution to the principal components?</p>
<ul class="simple">
<li><p>A) Dark colors indicate drugs that are more effective therapeutically</p></li>
<li><p>B) Dark red/blue indicate high absolute loading values, meaning these compounds strongly contribute to defining that principal component</p></li>
<li><p>C) White/gray areas indicate missing data for those drug compounds</p></li>
<li><p>D) Color intensity represents the correlation between different drugs</p></li>
</ul>
<p><strong>Question 2:</strong></p>
<p>Looking at PC1 (top row), you can see both red (positive) and blue (negative) loadings for different drug compounds. What does this pattern of positive and negative loadings indicate?</p>
<ul class="simple">
<li><p>A) Positive loadings are “good” drugs and negative loadings are “bad” drugs</p></li>
<li><p>B) This indicates an error in the PCA calculation since all loadings should be positive</p></li>
<li><p>C) Compounds with positive loadings move in the same direction as PC1, while those with negative loadings move in the opposite direction</p></li>
<li><p>D) Positive and negative loadings cancel each other out, making PC1 meaningless</p></li>
</ul>
<p><strong>Question 3:</strong></p>
<p>To understand what PC1 represents biologically in your drug sensitivity study, which compounds should you focus on for interpretation?</p>
<ul class="simple">
<li><p>A) Only the compounds with positive loadings (red colors)</p></li>
<li><p>B) Only the compounds with negative loadings (blue colors)</p></li>
<li><p>C) The compounds with the highest absolute loadings (darker shades of red and blue), regardless of sign</p></li>
<li><p>D) The compounds with near-zero loadings (white/gray) because they’re most stable</p></li>
</ul>
<p><strong>Question 4:</strong></p>
<p>If you wanted to name or characterize what biological pathway PC1 represents, how would you use the loading information?</p>
<ul class="simple">
<li><p>A) Look up the biological functions of compounds with the highest absolute loadings in PC1</p></li>
<li><p>B) Only consider the single compound with the highest positive loading</p></li>
<li><p>C) Average all the loading values to get a general interpretation</p></li>
<li><p>D) Focus on compounds that appear in multiple principal components</p></li>
</ul>
</div>
</section>
</section>
</section>
<span id="document-2.Logistic_regression_QnA"></span><section id="classification">
<h3>Classification<a class="headerlink" href="#classification" title="Link to this heading"></a></h3>
<section id="q-a-session-logistic-regression">
<h4>Q &amp; A session: Logistic regression<a class="headerlink" href="#q-a-session-logistic-regression" title="Link to this heading"></a></h4>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>Participants were given 30 minutes to</p>
<ul>
<li><p>go through the Jupter notebook and</p></li>
<li><p>select correct answers for the questions</p></li>
</ul>
</li>
<li><p>Instructor narrate the answers and reasoning after the self-study time</p>
<ul>
<li><p>time: 30 minutes</p></li>
</ul>
</li>
</ul>
</div>
<section id="understanding-biological-context-ml-use-case">
<h5>Understanding biological context (ML-use case)<a class="headerlink" href="#understanding-biological-context-ml-use-case" title="Link to this heading"></a></h5>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<p><strong>Question 1:</strong></p>
<p>What type of machine learning problem is glioma grading/classification as described in this tutorial?</p>
<ul class="simple">
<li><p>A) Unsupervised clustering problem</p></li>
<li><p>B) Binary classification problem</p></li>
<li><p>C) Multi-class classification problem</p></li>
<li><p>D) Regression problem</p></li>
</ul>
<p><strong>Question 2:</strong></p>
<p>In this study, how is the target variable encoded?</p>
<ul class="simple">
<li><p>A) LGG = 1, GBM = 0</p></li>
<li><p>B) LGG = 0, GBM = 1</p></li>
<li><p>C) Both are encoded as 1</p></li>
<li><p>D) Text labels are used without numeric encoding
Answer: - B) LGG = 0, GBM = 1
Explanation: The target variable encoding is explicitly stated as 0 = “LGG” and 1 = “GBM”.</p></li>
</ul>
<p><strong>Question 3:</strong></p>
<p>What types of features are being used in this logistic regression model?</p>
<ul class="simple">
<li><p>A) Only genetic mutation data</p></li>
<li><p>B) Only clinical features</p></li>
<li><p>C) 20 most frequently mutated genes plus 3 clinical features</p></li>
<li><p>D) All available genetic and clinical data</p></li>
</ul>
<p><strong>Question 4:</strong></p>
<p>Why is accurate glioma grading/classification clinically important?</p>
<ul class="simple">
<li><p>A) It determines the research funding allocation</p></li>
<li><p>B) Different grades require different treatment approaches and have different prognoses</p></li>
<li><p>C) It’s only important for statistical purposes</p></li>
<li><p>D) It helps organize hospital records</p></li>
</ul>
</div>
</section>
<section id="visualize-data-distributions">
<h5>Visualize data distributions<a class="headerlink" href="#visualize-data-distributions" title="Link to this heading"></a></h5>
<div class="admonition-questions questions admonition" id="questions-1">
<p class="admonition-title">Questions</p>
<p><img alt="alt text" src="_images/image-18.png" /></p>
<p><strong>Question 1:</strong></p>
<p>Binary features (keeping them as 0/1) while scaling Age_at_diagnosis. What is the primary reason why scaling binary features is generally NOT recommended in logistic regression?</p>
<ul class="simple">
<li><p>A) Binary features are too simple to benefit from scaling</p></li>
<li><p>B) Scaling binary features would destroy their natural interpretability - coefficients would no longer represent the change from “absent” (0) to “present” (1)</p></li>
<li><p>C) Binary features automatically have equal variance, so scaling is unnecessary</p></li>
<li><p>D) Logistic regression algorithms cannot handle scaled binary features</p></li>
</ul>
<p><strong>Question 2:</strong></p>
<p>Given the heavy imbalance in most binary features (with most values being 0 and small number of observations with 1s’), what potential issue might this create during logistic regression training?</p>
<ul class="simple">
<li><p>A) The model will converge faster due to the simplicity of the data</p></li>
<li><p>B) The model may have difficulty learning meaningful patterns from rare events (1s) and might be biased toward predicting the majority class</p></li>
<li><p>C) The imbalanced features will automatically be weighted equally by the algorithm</p></li>
</ul>
<p><strong>Question 3:</strong></p>
<p>When interpreting logistic regression coefficients for the heavily imbalanced binary features shown in these plots, what should you be particularly cautious about?</p>
<ul class="simple">
<li><p>A) Coefficients for rare events may be unstable and can lead to poor generalization</p></li>
<li><p>B) Coefficients will be automatically adjusted by the algorithm to account for imbalance</p></li>
<li><p>C) Imbalanced features always produce more reliable coefficient estimates</p></li>
<li><p>D) The scaling of Age_at_diagnosis will make other coefficients uninterpretable</p></li>
</ul>
</div>
</section>
<section id="split-original-dataset">
<h5>Split original dataset<a class="headerlink" href="#split-original-dataset" title="Link to this heading"></a></h5>
<div class="admonition-questions questions admonition" id="questions-2">
<p class="admonition-title">Questions</p>
<p><strong>Question 1:</strong></p>
<p>In the <code class="docutils literal notranslate"><span class="pre">train_test_split</span></code> code, <code class="docutils literal notranslate"><span class="pre">test_size=0.3</span></code> means 30% of data goes to testing. For a medical dataset like glioma classification, what is the primary consideration when choosing this split ratio?</p>
<p><img alt="alt text" src="_images/image-19.png" /></p>
<ul class="simple">
<li><p>A) Larger test sets always give better model performance</p></li>
<li><p>B) Balancing reliable performance evaluation with sufficient training data, especially important given limited medical data availability</p></li>
<li><p>C) Test size should always be exactly 30% regardless of dataset characteristics</p></li>
<li><p>D) Smaller test sets are always preferred to maximize training data</p></li>
</ul>
<p><strong>Question 2:</strong></p>
<p>In the <code class="docutils literal notranslate"><span class="pre">train_test_split</span></code> code, why is the <code class="docutils literal notranslate"><span class="pre">stratify=gliomas[&quot;Grade&quot;]</span></code> parameter crucial in this glioma classification problem?</p>
<ul class="simple">
<li><p>A) It randomly shuffles the data for better performance</p></li>
<li><p>B) It ensures both training and test sets have proportional representation of LGG and GBM cases</p></li>
<li><p>C) It sorts the data by grade for easier processing</p></li>
<li><p>D) It removes outliers from the dataset</p></li>
</ul>
</div>
</section>
<section id="the-model-output-probability">
<h5>The Model Output (Probability)<a class="headerlink" href="#the-model-output-probability" title="Link to this heading"></a></h5>
<div class="admonition-questions questions admonition" id="questions-3">
<p class="admonition-title">Questions</p>
<p><img alt="alt text" src="_images/image-20.png" /></p>
<p><strong>Question 1:</strong></p>
<p>The histogram shows a distinctive U-shaped distribution of predicted probabilities, with many predictions clustered near 0.0 and 1.0, and fewer predictions in the middle range (0.3-0.7). What does this pattern indicate about the model’s behavior?</p>
<ul class="simple">
<li><p>A) The model is making unreliable predictions</p></li>
<li><p>B) The model is well-calibrated and confident in most of its predictions, clearly separating the two classes</p></li>
<li><p>C) The model has failed to converge properly during training</p></li>
<li><p>D) The sigmoid transformation is not working correctly</p></li>
</ul>
<p><strong>Question 2:</strong>
What does lr.predict_proba(X_test) output, and why are probability predictions particularly valuable in medical diagnosis like glioma classification?</p>
<ul class="simple">
<li><p>A) It outputs only the predicted class labels (0 for LGG, 1 for GBM)</p></li>
<li><p>B) It outputs probability estimates for each class (P(LGG) and P(GBM)) for each patient, allowing clinicians to assess prediction confidence</p></li>
<li><p>C) It outputs the raw coefficient values for each gene and clinical feature</p></li>
<li><p>D) It outputs the training accuracy of the model</p></li>
</ul>
</div>
</section>
<section id="predict-test-datasaets">
<h5>Predict test-datasaets<a class="headerlink" href="#predict-test-datasaets" title="Link to this heading"></a></h5>
<div class="admonition-questions questions admonition" id="questions-4">
<p class="admonition-title">Questions</p>
<p><strong>Question 1:</strong></p>
<p>What is the key difference between <code class="docutils literal notranslate"><span class="pre">lr.predict(X_test)</span></code> and lr.predict_proba(X_test) in this glioma classification model?</p>
<ul class="simple">
<li><p>A) <code class="docutils literal notranslate"><span class="pre">predict()</span> </code>gives probabilities for each class, while <code class="docutils literal notranslate"><span class="pre">predict_proba()</span></code> gives final class labels</p></li>
<li><p>B) <code class="docutils literal notranslate"><span class="pre">predict()</span></code> gives final class decisions (0 for LGG, 1 for GBM) by applying a 0.5 threshold to probabilities, while <code class="docutils literal notranslate"><span class="pre">predict_proba()</span></code> gives the actual probability values</p></li>
<li><p>C) <code class="docutils literal notranslate"><span class="pre">predict()</span></code> is more accurate than <code class="docutils literal notranslate"><span class="pre">predict_proba()</span></code></p></li>
<li><p>D) There is no difference between the two methods</p></li>
</ul>
</div>
</section>
<section id="examine-and-understand-the-importance-of-features-in-predicting-classes">
<h5>Examine and understand the importance of features in predicting classes<a class="headerlink" href="#examine-and-understand-the-importance-of-features-in-predicting-classes" title="Link to this heading"></a></h5>
<div class="admonition-questions questions admonition" id="questions-5">
<p class="admonition-title">Questions</p>
<p><strong>Question 1 (Coefficient Sign Interpretation):</strong></p>
<p>In this glioma classification model, what does a positive coefficient in <code class="docutils literal notranslate"><span class="pre">lr.coef_</span></code> indicate for a specific gene or clinical feature?</p>
<ul class="simple">
<li><p>A) The feature has no effect on glioma classification</p></li>
<li><p>B) The feature increases the likelihood of predicting GBM (class 1) when present or higher in value</p></li>
<li><p>C) The feature increases the likelihood of predicting LGG (class 0) when present or higher in value</p></li>
<li><p>D) The feature should be removed from the model</p></li>
</ul>
<p><img alt="alt text" src="_images/image-21.png" /></p>
<p><strong>Question 2 (Coefficient Sign Interpretation):</strong></p>
<p>Looking at the feature importance plot, what can you conclude about the features GRIN2A (rightmost bar) and IDH1 (leftmost bar) in terms of their effect on the predicted outcome?</p>
<ul class="simple">
<li><p>A) GRIN2A decreases the probability of the positive class, while IDH1 increases it</p></li>
<li><p>B) GRIN2A increases the probability of the positive class, while IDH1 decreases it</p></li>
<li><p>C) Both features have the same effect but different magnitudes</p></li>
<li><p>D) The sign of the coefficient doesn’t matter, only the magnitude</p></li>
</ul>
</div>
</section>
<section id="evaluation-of-the-model-performance">
<h5>Evaluation of the model performance<a class="headerlink" href="#evaluation-of-the-model-performance" title="Link to this heading"></a></h5>
<div class="admonition-questions questions admonition" id="questions-6">
<p class="admonition-title">Questions</p>
<p><img alt="alt text" src="_images/image-22.png" /></p>
<p><strong>Question 1:</strong></p>
<p>Based on the confusion matrix shown, what are the True Positives, False Positives, True Negatives, and False Negatives for this glioma classification model?</p>
<ul class="simple">
<li><p>A) TP=124, FP=22, TN=94, FN=12</p></li>
<li><p>B) TP=94, FP=22, TN=124, FN=12</p></li>
<li><p>C) TP=22, FP=94, TN=12, FN=124</p></li>
<li><p>D) TP=94, FP=12, TN=124, FN=22</p></li>
</ul>
</div>
</section>
</section>
</section>
<span id="document-3.ML_workflow_QnA"></span><section id="complete-machine-learning-workflow">
<h3>Complete Machine Learning Workflow<a class="headerlink" href="#complete-machine-learning-workflow" title="Link to this heading"></a></h3>
<section id="machine-learning-workflow">
<h4>Machine Learning Workflow<a class="headerlink" href="#machine-learning-workflow" title="Link to this heading"></a></h4>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>Participants were given 60 minutes to</p>
<ul>
<li><p>go through the Jupter notebook and</p></li>
<li><p>select correct answers for the questions</p></li>
</ul>
</li>
<li><p>Instructor narrate the answers and reasoning after the self-study time</p>
<ul>
<li><p>time: 45 minutes</p></li>
</ul>
</li>
</ul>
</div>
<section id="data-exploration">
<h5>Data exploration<a class="headerlink" href="#data-exploration" title="Link to this heading"></a></h5>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<p><strong>Question 1:</strong></p>
<p>When dealing with gene mutation features where &gt;95% of samples are wild-type (0), what is the most important consideration?</p>
<ul class="simple">
<li><p>A) Apply standard scaling (z-score normalization) to make features comparable</p></li>
<li><p>B) Use log transformation to reduce skewness in the distribution</p></li>
<li><p>C) Consider the impact on model training - rare events may be difficult to learn</p></li>
<li><p>D) Convert to categorical variables using one-hot encoding</p></li>
</ul>
<p><strong>Question 2:</strong></p>
<p>Your dataset contains age (continuous, 20-80 range), gender (binary 0/1), and gene mutations (binary 0/1). What normalization strategy is most appropriate?</p>
<ul class="simple">
<li><p>A) Apply Min-Max scaling to all features to get 0-1 range</p></li>
<li><p>B) Apply Z-score normalization to all features for zero mean, unit variance</p></li>
<li><p>C) Scale only the continuous features (age), leave binary features unchanged</p></li>
<li><p>D) Apply log transformation to all features to handle skewness</p></li>
</ul>
<p><strong>Question 3:</strong></p>
<p>Why is feature scaling for <code class="docutils literal notranslate"><span class="pre">Age_at_diagnosis</span></code> is required?</p>
<ul class="simple">
<li><p>A) To convert the <code class="docutils literal notranslate"><span class="pre">Age_at_diagnosis</span></code> distribution into a perfect Gaussian (normal) distribution.</p></li>
<li><p>B) To reduce the number of unique values in <code class="docutils literal notranslate"><span class="pre">Age_at_diagnosis</span></code>, thereby simplifying the model.</p></li>
<li><p>C) To ensure that <code class="docutils literal notranslate"><span class="pre">Age_at_diagnosis</span></code> values are transformed to be either 0 or 1, matching the gene features.</p></li>
<li><p>D) To prevent <code class="docutils literal notranslate"><span class="pre">Age_at_diagnosis</span></code> from disproportionately influencing the model’s parameter estimation due to its larger numerical range compared to the binary (0/1) features.</p></li>
</ul>
<p><strong>Question 4:</strong></p>
<p>In this glioma classification dataset, what should be your primary concern regarding the rare gene mutations?</p>
<ul class="simple">
<li><p>A) The computational cost will be too high with so many zero values</p></li>
<li><p>B) Rare mutations might be the most clinically important but hardest to detect</p></li>
<li><p>C) Binary features don’t need any preprocessing in machine learning</p></li>
<li><p>D) The dataset is too small and needs data augmentation</p></li>
</ul>
<p><strong>Question 5:</strong></p>
<p>You’re analyzing a dataset with 10,000 patients where a particular gene mutation occurs in only 50 patients (0.5% prevalence). When should you be most concerned about this feature imbalance?</p>
<ul class="simple">
<li><p>A) Always - any feature with &lt;5% prevalence will bias the logistic regression model</p></li>
<li><p>B) Never - logistic regression inherently handles sparse features well</p></li>
<li><p>C) Only when the 50 mutation carriers don’t provide sufficient statistical power to reliably estimate the gene’s effect</p></li>
<li><p>D) Only when the mutation is randomly distributed and not associated with the outcome</p></li>
</ul>
<p><strong>Question 6:</strong></p>
<p>In disease genomics, why might completely removing very rare genetic variants (occurring in &lt;1% of
samples) be problematic from a biological perspective?</p>
<ul class="simple">
<li><p>A) Rare variants always have larger effect sizes than common variants</p></li>
<li><p>B) Some rare variants may be clinically actionable, even if statistically underpowered in current sample</p></li>
<li><p>C) Removing sparse features will always improve model generalization</p></li>
<li><p>D) Feature selection should only be based on statistical criteria, not biological knowledge</p></li>
</ul>
</div>
</section>
<section id="missing-data-handling">
<h5>Missing data handling<a class="headerlink" href="#missing-data-handling" title="Link to this heading"></a></h5>
<div class="admonition-questions questions admonition" id="questions-1">
<p class="admonition-title">Questions</p>
<p><strong>Question 1:</strong></p>
<p>Your target variable (Grade) has missing values in 0.119% of samples. What is the most appropriate approach?</p>
<ul class="simple">
<li><p>A) Impute the missing grades using the mode (most frequent class)</p></li>
<li><p>B) Use a sophisticated imputation method like KNN to predict missing grades</p></li>
<li><p>C) Remove these samples entirely from both training and testing datasets</p></li>
<li><p>D) Replace missing grades with a third category “Unknown” and make it a 3-class problem</p></li>
</ul>
<p><strong>Question 2:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="n">threshold</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.95</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">gliomas</span><span class="p">))</span>
<span class="c1"># Keep columns with at least 95% non-missing values</span>
<span class="n">gliomas</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">thresh</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>A) This code drops columns that have more than 5% missing values using a 95% completeness threshold (Drop ATRX_xNA - 25% missing and IDH1_xNA - 80% missing, while
Keeping All other features (0.119% or 0% missing)</p></li>
<li><p>B) Only Drop IDH1_xNA</p></li>
<li><p>C) Drop all columns with missing values</p></li>
<li><p>D) Keep columns with 0% missing values</p></li>
</ul>
<p><strong>Question 3:</strong></p>
<p>When should this column-dropping step be performed in your ML pipeline?</p>
<ul class="simple">
<li><p>A) Before removing samples (rows) with missing target variables</p></li>
<li><p>B) After removing samples with missing target variables but before train/test split</p></li>
<li><p>C) After train/test split but before feature scaling</p></li>
<li><p>D) After model training to remove unimportant features</p></li>
</ul>
</div>
</section>
<section id="train-test-and-standerdisation">
<h5>Train-test and Standerdisation<a class="headerlink" href="#train-test-and-standerdisation" title="Link to this heading"></a></h5>
<div class="admonition-questions questions admonition" id="questions-2">
<p class="admonition-title">Questions</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">gliomas</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;Grade&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">gliomas</span><span class="p">[</span><span class="s2">&quot;Grade&quot;</span><span class="p">],</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
    <span class="n">stratify</span><span class="o">=</span><span class="n">gliomas</span><span class="p">[</span><span class="s2">&quot;Grade&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">[[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]])</span>
<span class="n">X_test</span><span class="p">[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">[[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]])</span>

</pre></div>
</div>
<p><strong>Question 1:</strong></p>
<p>Why do we use <code class="docutils literal notranslate"><span class="pre">fit_transform()</span></code> on training data but only <code class="docutils literal notranslate"><span class="pre">transform()</span></code> on test data?</p>
<ul class="simple">
<li><p>A) <code class="docutils literal notranslate"><span class="pre">fit_transform()</span></code> is faster than <code class="docutils literal notranslate"><span class="pre">transform()</span></code> for larger datasets</p></li>
<li><p>B) To prevent data leakage by ensuring scaling parameters come only from training data</p></li>
<li><p>C) <code class="docutils literal notranslate"><span class="pre">transform()</span></code> automatically applies different scaling to test data for better performance</p></li>
<li><p>D) It’s a coding convention but doesn’t impact model performance</p></li>
</ul>
<p><strong>Question 2:</strong></p>
<p>What would happen if you calculated scaling parameters (mean and standard deviation) using the entire dataset before splitting?</p>
<ul class="simple">
<li><p>A) The model would perform better due to more stable scaling parameters</p></li>
<li><p>B) It would create data leakage because test set statistics influence training preprocessing</p></li>
<li><p>C) Nothing significant - the difference in scaling parameters would be minimal</p></li>
<li><p>D) The model would be more generalizable to new data</p></li>
</ul>
<p><strong>Question 3:</strong></p>
<p>If a new patient has age = 85 years (outside the training age range of 20-80), what should happen during prediction?</p>
<ul class="simple">
<li><p>A) Reject the prediction because the age is out of range</p></li>
<li><p>B) Retrain the scaler including this new data point</p></li>
<li><p>C) Apply the same training scaler transformation, even if it results in an extreme scaled value</p></li>
<li><p>D) Use a different scaling method specifically for this outlier</p></li>
</ul>
<p><strong>Question 4:</strong></p>
<p><img alt="alt text" src="_images/image-23.png" /></p>
<p>What is the most important reason for a machine learning practitioner to perform such a visual check after splitting the data?</p>
<ul class="simple">
<li><p>A) To ensure that no data points were lost during the train_test_split operation.</p></li>
<li><p>B) To confirm that the Age_at_diagnosis feature has been transformed to a normal distribution in both sets.</p></li>
<li><p>C) To verify that the feature distributions are reasonably similar between the training and test sets, which helps ensure that the test set provides a fair and representative evaluation of the model’s performance.</p></li>
<li><p>D) To decide if the Age_at_diagnosis feature should be used as the target variable instead of “Grade”.</p></li>
</ul>
</div>
</section>
<section id="corss-validation">
<h5>Corss-validation<a class="headerlink" href="#corss-validation" title="Link to this heading"></a></h5>
<div class="admonition-questions questions admonition" id="questions-3">
<p class="admonition-title">Questions</p>
<p><strong>Question 1:</strong></p>
<p>You split your dataset into 70% train/30% test, getting a test precison of 87% (recall 85%). What’s the main limitation of this single performance estimate?</p>
<ul class="simple">
<li><p>A) precison of 87% (recall 85%) is too low for medical applications</p></li>
<li><p>B) The estimate could vary with different random splits of the same data</p></li>
<li><p>C) 30% test size is too large and wastes training data</p></li>
<li><p>D) precison and recall are the wrong metric for binary classification problems</p></li>
</ul>
<p><strong>Question 2:</strong></p>
<p>Say that Your single test set has 252 samples (30% of 840). If you want to evaluate model performance on rare glioma subtypes that represent 5% of cases, how many samples would you have?</p>
<ul class="simple">
<li><p>A) About 42 samples - sufficient for reliable performance estimation</p></li>
<li><p>B) About 13 samples - too few for meaningful statistical conclusions</p></li>
<li><p>C) About 126 samples - more than adequate for analysis</p></li>
<li><p>D) The number doesn’t matter if the model is well-trained</p></li>
</ul>
<p><strong>Question 3:</strong></p>
<p>A hospital wants to deploy your glioma classifier but asks: “How confident are you that this precison of 87% (recall 85%) will hold for our patient population?” With only a single holdout test, what’s your most honest answer?</p>
<ul class="simple">
<li><p>A) “Very confident - precison of 87% (recall 85%) are true values since we used proper train/test split”</p></li>
<li><p>B) “Moderately confident - the precison and recall could realistically range from 80-94% based on this single test”</p></li>
<li><p>C) “Cannot provide confidence bounds - need cross-validation or multiple test sets for reliability estimates”</p></li>
<li><p>D) “Completely confident - precison and recall doesn’t vary between hospitals”</p></li>
</ul>
</div>
</section>
<section id="corss-validation-code">
<h5>Corss-validation: Code<a class="headerlink" href="#corss-validation-code" title="Link to this heading"></a></h5>
<div class="admonition-questions questions admonition" id="questions-4">
<p class="admonition-title">Questions</p>
<p><em><strong>Question 1:</strong></em></p>
<p>(A)</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1111</span><span class="p">)</span>
<span class="n">splits</span> <span class="o">=</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">gliomas</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;Grade&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

<span class="c1"># Initialize scaler</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">fold</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">lr_cv</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>

<span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">val_index</span> <span class="ow">in</span> <span class="n">splits</span><span class="p">:</span>
    <span class="o">...</span>
    <span class="c1"># Initialize the Logistic Regression model with cross-validation</span>

    <span class="n">X_train_scaled</span><span class="p">[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">[[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">X_val_scaled</span><span class="p">[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_val</span><span class="p">[[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    
    <span class="c1"># Use the SCALED data for training and prediction</span>
    <span class="n">lr_cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>  <span class="c1"># ← Now using scaled data</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">lr_cv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_val_scale</span><span class="o">-</span> <span class="n">D</span><span class="p">)</span>  <span class="c1"># ← Now using scaled data</span>
</pre></div>
</div>
<p>(B)</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1111</span><span class="p">)</span>
<span class="n">splits</span> <span class="o">=</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">gliomas</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;Grade&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

<span class="c1"># Initialize scaler</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">fold</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">val_index</span> <span class="ow">in</span> <span class="n">splits</span><span class="p">:</span>
    <span class="o">...</span>
    <span class="c1"># Initialize the Logistic Regression model with cross-validation</span>
    <span class="n">lr_cv</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>

    <span class="n">X_train_scaled</span><span class="p">[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">[[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">X_val_scaled</span><span class="p">[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_val</span><span class="p">[[</span><span class="s1">&#39;Age_at_diagnosis&#39;</span><span class="p">]])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

    <span class="c1"># Use the SCALED data for training and prediction</span>
    <span class="n">lr_cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>  <span class="c1"># ← Now using scaled data</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">lr_cv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_val_scale</span><span class="o">-</span> <span class="n">D</span><span class="p">)</span>  <span class="c1"># ← Now using scaled data</span>
</pre></div>
</div>
<p>In this A code-block, the same <code class="docutils literal notranslate"><span class="pre">lr_cv</span></code> object is used across all 5 folds. What potential issue could this create?</p>
<ul class="simple">
<li><p>A) Each fold builds upon the previous fold’s learned parameters, creating data leakage</p></li>
<li><p>B) The model’s internal state gets reset automatically, so there’s no issue</p></li>
<li><p>C) Memory usage increases exponentially with each fold</p></li>
<li><p>D) The model converges faster in later folds due to better initialization</p></li>
</ul>
<p><strong>Question 2:</strong></p>
<p>The code declares <code class="docutils literal notranslate"><span class="pre">scaler</span> <span class="pre">=</span> <span class="pre">StandardScaler()</span></code> before the loop and reuses it (above A &amp; B code-blocks). What happens when you call <code class="docutils literal notranslate"><span class="pre">fit_transform()</span></code> on the same scaler object multiple times?</p>
<ul class="simple">
<li><p>A) It accumulates statistics across all folds, causing data leakage</p></li>
<li><p>B) It overwrites previous statistics with new fold’s statistics - no leakage</p></li>
<li><p>C) It averages statistics across folds for more stable scaling</p></li>
<li><p>D) It causes an error because you can only fit once</p></li>
</ul>
<p><strong>Question 3:</strong></p>
<p>This code uses KFold instead of StratifiedKFold. In a medical dataset where GBM (aggressive cancer) represents 40% of cases, what could go wrong?</p>
<ul class="simple">
<li><p>A) Some folds might have 60% GBM while others have 20%, creating inconsistent evaluation conditions</p></li>
<li><p>B) The total number of samples evaluated will be different across folds</p></li>
<li><p>C) Cross-validation will take significantly longer to complete</p></li>
<li><p>D) The precision and recall calculations will become invalid</p></li>
</ul>
</div>
</section>
<section id="hyperparameter-tuning">
<h5>Hyperparameter tuning<a class="headerlink" href="#hyperparameter-tuning" title="Link to this heading"></a></h5>
<div class="admonition-questions questions admonition" id="questions-5">
<p class="admonition-title">Questions</p>
<p><strong>Question 1:</strong></p>
<p>You train a logistic regression model for glioma classification using default scikit-learn parameters and achieve 78% F1-score. After hyperparameter tuning with GridSearchCV, you achieve 85% F1-score. What does this improvement primarily demonstrate?</p>
<ul class="simple">
<li><p>A) Default parameters are intentionally set to poor values to encourage tuning</p></li>
<li><p>B) Machine learning algorithms need parameter optimization to match specific dataset characteristics</p></li>
<li><p>C) Hyperparameter tuning always guarantees at least 7% improvement in any metric</p></li>
<li><p>D) The original 78% score was due to a coding error in the implementation</p></li>
</ul>
<p><strong>Question 2:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># original grid in the notebook</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">[</span>
    <span class="c1"># For l2 penalty </span>
    <span class="p">{</span>
        <span class="s1">&#39;penalty&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;l2&#39;</span><span class="p">],</span>
        <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
        <span class="s1">&#39;solver&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span> <span class="s1">&#39;liblinear&#39;</span><span class="p">,</span> <span class="s1">&#39;newton-cg&#39;</span><span class="p">,</span> <span class="s1">&#39;sag&#39;</span><span class="p">,</span> <span class="s1">&#39;saga&#39;</span><span class="p">],</span>
        <span class="s1">&#39;max_iter&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">],</span>  <span class="c1"># Higher iterations for sparse data</span>
        <span class="s1">&#39;class_weight&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;balanced&#39;</span><span class="p">]</span>  <span class="c1"># Handle class imbalance if present</span>
    <span class="p">},</span>
    <span class="c1"># For l1 penalty (best for sparse features)</span>
    <span class="p">{</span>
        <span class="s1">&#39;penalty&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;l1&#39;</span><span class="p">],</span>
        <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0001</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>  <span class="c1"># Extended lower range</span>
        <span class="s1">&#39;solver&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;liblinear&#39;</span><span class="p">,</span> <span class="s1">&#39;saga&#39;</span><span class="p">],</span>
        <span class="s1">&#39;max_iter&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">],</span>
        <span class="s1">&#39;class_weight&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;balanced&#39;</span><span class="p">]</span>
    <span class="p">},</span>
    <span class="c1"># For elasticnet penalty</span>
    <span class="p">{</span>
        <span class="s1">&#39;penalty&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;elasticnet&#39;</span><span class="p">],</span>
        <span class="s1">&#39;l1_ratio&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span>  <span class="c1"># Finer granularity</span>
        <span class="s1">&#39;solver&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;saga&#39;</span><span class="p">],</span>
        <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>  <span class="c1"># Extended range</span>
        <span class="s1">&#39;max_iter&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">],</span>
        <span class="s1">&#39;class_weight&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;balanced&#39;</span><span class="p">]</span>
    <span class="p">}</span>
<span class="p">]</span>

<span class="c1"># Alternative: Focused grid for very sparse genomics data</span>
<span class="n">sparse_focused_grid</span> <span class="o">=</span> <span class="p">[</span>
    <span class="c1"># Emphasize L1 and ElasticNet for feature selection</span>
    <span class="p">{</span>
        <span class="s1">&#39;penalty&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;l1&#39;</span><span class="p">],</span>
        <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>  <span class="c1"># Focus on stronger regularization</span>
        <span class="s1">&#39;solver&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;liblinear&#39;</span><span class="p">],</span>
        <span class="s1">&#39;max_iter&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">5000</span><span class="p">]</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s1">&#39;penalty&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;elasticnet&#39;</span><span class="p">],</span>
        <span class="s1">&#39;l1_ratio&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span>  <span class="c1"># Favor L1 component</span>
        <span class="s1">&#39;solver&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;saga&#39;</span><span class="p">],</span>
        <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="s1">&#39;max_iter&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">5000</span><span class="p">]</span>
    <span class="p">}</span>
<span class="p">]</span>

</pre></div>
</div>
<p>The sparse_focused_grid excludes L2 regularization and only includes L1 and ElasticNet penalties. Why is this choice particularly effective for sparse genomics data?</p>
<ul class="simple">
<li><p>A) L2 regularization is computationally too expensive for high-dimensional sparse data</p></li>
<li><p>B) L1 and ElasticNet can set coefficients to exactly zero, performing automatic feature selection on irrelevant sparse features (while addressing multicollinearity)</p></li>
<li><p>C) L2 regularization requires balanced features and cannot handle any level of sparsity</p></li>
<li><p>D) L1 and ElasticNet converge faster than L2 when most features are sparse</p></li>
</ul>
</div>
</section>
</section>
</section>
</div>
</section>
<section id="python-dependencies">
<h2>Python dependencies<a class="headerlink" href="#python-dependencies" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p><a class="reference download internal" download="" href="_downloads/6e07c75c5056c3a45979cc281eab1202/requirements.txt"><span class="xref download myst">Download requirements file <code class="docutils literal notranslate"><span class="pre">requirements.txt</span></code></span></a></p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025 Norwegian Ai Cloud.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>